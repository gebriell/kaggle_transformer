{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":2415872,"sourceType":"datasetVersion","datasetId":1461623},{"sourceId":9801,"sourceType":"datasetVersion","datasetId":6763}],"dockerImageVersionId":30674,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# For viewing and manipulating data\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Importing the necessary libraries\nimport re\nimport math\nimport string\nimport nltk\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport gensim.downloader as api\nfrom gensim.models import KeyedVectors # >> alternative to gensim.downloader\nimport matplotlib.pyplot as plt\n\n# Getting particular functions from these libraries \nfrom torch import Tensor\nfrom sklearn.utils import resample\nfrom gensim.models import KeyedVectors\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom torch.utils.data import random_split, DataLoader, TensorDataset, Dataset\n\n# Using the NLTK to tokenize the text\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\n# Checks if a CUDA enabled GPU is available and prints out its information\nif torch.cuda.is_available():\n    print(\"CUDA is available!\")\n    for i in range(torch.cuda.device_count()):\n        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n        \n    device = torch.device(\"cuda:0\")\n\nelse:\n    print(\"CUDA is not available.\")\n    device = torch.device(\"cpu\")\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nreviews_file = ''\nw2v_file = ''\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        file_name = os.path.join(dirname, filename)\n        if file_name.endswith('.csv'): \n            reviews_file = file_name\n        elif file_name.endswith('.bin'):\n            w2v_file = file_name\n        else:\n            print(f'Found unexpected file: {file_name}')\n                \nprint(f'Amazon reviews file: {reviews_file}')\nprint(f'Google news word to vec file: {w2v_file}')\n            \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nVERBOSE = False\ndef printv(text):\n    if VERBOSE: print('VERBOSE:', text)\n    return\n\ndef showV(text):\n    '''unconditional verbose output'''\n    print('VERBOSE:', text)\n    return\n\nDEV = True\ndef printd(text):\n    if DEV: print('DEV:', text)\n    return\n\ndef showD(text):\n    '''unconditional DEV output'''\n    print('VERBOSE:', text)\n    return\n\nshowCellCompletion = False\ndef showC(text):\n    if showCellCompletion:\n        print('Cell complete:', text)\n    return\n\nimport subprocess\nshowNv = False\naccelerator = False\n\ndef printNv():\n    if not showNv or not accelerator: return\n    mem_usage = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE)\n    print(mem_usage.stdout.decode('utf-8'))\n\nshowMemoryAllocation = True\ndef printM():\n    if not showMemoryAllocation: return\n    print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-04-14T09:41:05.431446Z","iopub.execute_input":"2024-04-14T09:41:05.432046Z","iopub.status.idle":"2024-04-14T09:41:05.452421Z","shell.execute_reply.started":"2024-04-14T09:41:05.432012Z","shell.execute_reply":"2024-04-14T09:41:05.451246Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"CUDA is available!\nGPU 0: Tesla P100-PCIE-16GB\nFound unexpected file: /kaggle/input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin.gz\nAmazon reviews file: /kaggle/input/amazon-product-reviews/Reviews.csv\nGoogle news word to vec file: /kaggle/input/googlenewsvectorsnegative300/GoogleNews-vectors-negative300.bin\n","output_type":"stream"}]},{"cell_type":"code","source":"#!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:41:05.454385Z","iopub.execute_input":"2024-04-14T09:41:05.454766Z","iopub.status.idle":"2024-04-14T09:41:05.466768Z","shell.execute_reply.started":"2024-04-14T09:41:05.454730Z","shell.execute_reply":"2024-04-14T09:41:05.465626Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"# Load data from CSV\n#>>  3/13 needed to change the path as below\n# path ='/kaggle/input/Reviews.csv'#\"/kaggle/input/amazon-product-reviews/Reviews.csv\"\ndata = pd.read_csv(reviews_file) # Use pandas to analyze data\nshowD('Amazon reviews loaded into Panda')\n\n# print number of rows in our ratings column\nprintv(f'Number of reviews: {len(data[\"Score\"])}')\nprintv(f'Column names -\\n {data.columns}\\n') \nprintv(f'First five rows -\\n{data.head()}')\n\n# Check for empty entries or missing data in each column\nfor column in data.columns:\n    if data[column].isnull().values.any():\n        print(f\"Column '{column}' has empty entries or missing data.\")\n    else:\n        print(f\"Column '{column}' has no empty entries or missing data.\")\n\n# Get count of ratings \nrating_counts = data['Score'].value_counts()\n\n# Sort counts by index ascending\nrating_counts = rating_counts.sort_index()  \n\n# Create bar plot\nax = rating_counts.plot(kind = 'bar')\n\nax.set_title(\"Ratings Distribution\")\nax.set_xlabel(\"Rating\")\nax.set_ylabel(\"Number of Occurrences\")\n\n# Fix x-axis tick labels\nax.set_xticklabels(ax.get_xticklabels(), rotation = 0) \n\nfor rating, count in rating_counts.items():\n        print(f\"{count:,} samples from balanced data with rating {rating}\\n\")\n\nplt.show() #<< show the rating in each of the 5 categories\n\nbalanced_data_size = 5000 #25000<< number of reviews in each rating category, tailored for CPU capacity\n# Specify the column for sorting and balancing\nsort_column = 'Score'  # This is one the rating column\n\n# Sort the data by the rating values\nsorted_data = data.sort_values(by = sort_column)\n\n# Create a balanced dataset with 25,000 samples from each class\n#balanced_data = sorted_data.groupby(sort_column).apply(lambda x: x.sample(n=25000))\n\n#>> DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. \n#>> This behavior is deprecated, and in a future version of pandas the grouping \n#>> columns will be excluded from the operation. \n#>> Either pass `include_groups=False` to exclude the groupings or \n#>> explicitly select the grouping columns after groupby to silence this warning.\n#\nbalanced_data = sorted_data.groupby(sort_column).apply(lambda x: x.sample(n = balanced_data_size))\n\n#>> Does this mean to reset the row numbers?? ##Columns Numbers\nbalanced_data.reset_index(drop = True, inplace = True)\n\nprintv(f\"The number of reviews equally distributed across all ratings is {len(balanced_data['Score'])}\")\n\n# Get count of ratings\nrating_counts = balanced_data['Score'].value_counts()\n\n# Create bar plot\nax = rating_counts.plot(kind='bar')\n\nax.set_title(\"Ratings Distribution After Balancing\")\nax.set_xlabel(\"Rating\")\nax.set_ylabel(\"Number of Samples\")\n\n# Fix x-axis ticks  \nax.set_xticklabels(ax.get_xticklabels(), rotation = 0)\n\n# Print number of reviews per rating\n\nif DEV:\n    for rating, count in rating_counts.items():\n        print(f\"{count:,} samples from balanced data with rating {rating}\\n\")\n\nplt.show()\n\n\nimport spacy\nimport re\nimport pandas as pd\n\n# Load the English tokenizer model\nnlp = spacy.load(\"en_core_web_sm\")\n\n# Compile the regular expressions\nhtml_tags = re.compile(\"<.*?>\")\npunct_and_symbols = re.compile(r'[^\\w\\s\\']+')\n\ndef tokenizer(text, nlp):\n    \"\"\"\n    Tokenizes a text string and removes stop words.\n    \n    text (str): The text string to tokenize.\n    nlp: The Spacy language model.\n\n    Returns:\n        list: The tokenized text string.\n    \"\"\"\n    text = text.lower()  # Convert text to lowercase\n    text = html_tags.sub(\"\", text)  # Remove HTML tags\n    text = punct_and_symbols.sub(\"\", text)  # Remove punctuation and symbols\n\n    # Tokenize the text\n    doc = nlp(text)\n\n    # Remove stop words and punctuation tokens\n    # tokens = [token.text for token in doc if not token.is_punct]# and not token.is_stop]\n    tokens = [token.text for token in doc if not token.is_punct]# and not token.is_stop]\n\n    return tokens\n\n# Assuming balanced_data is a pandas DataFrame and 'Text' is a column containing the reviews\n# Apply the function to the Text column and store it in a new column\nbalanced_data['CleanedReview'] = balanced_data['Text'].apply(lambda x: tokenizer(x, nlp))\n\n# Show that cell has finished executing\nshowC(f'{tokenizer} defined, and then used to create CleanedReview column')\n\n# Store the Rating column\nrating = balanced_data['Score']  \n\n# Store the CleanedReview column\ntokenized_review = balanced_data['CleanedReview']\nshowD(f'specify the columns that will be used to train the classifier')\n\nprint(balanced_data['Text'][0],'\\n')\nprint(tokenized_review[0], '\\n')\nprint(len(tokenized_review[0]), '\\n')\nprint(tokenized_review.shape)\n\nfrom scipy import stats\n\ndef analyze_review_tokens(reviews):\n    token_counts = [len(review) for review in reviews]\n\n    mean = np.mean(token_counts)\n    median = np.median(token_counts)\n    mode = stats.mode(token_counts)\n\n    print(f\"Mean: {mean:.2f}\")\n    print(f\"Median: {median:.2f}\")\n    print(f\"Mode: {mode}\")\n\n    plt.figure(figsize=(8, 6))\n    plt.hist(token_counts, bins=20, edgecolor='black')\n    plt.xlabel('Number of Tokens')\n    plt.ylabel('Frequency')\n    plt.title('Histogram of Token Counts per Review')\n    plt.grid(True)\n    plt.show()\n\nanalyze_review_tokens(tokenized_review)\n\n# >> 3/29/24 Took less than a minute to run without the accelerator.\n# Load Word2Vec model\n#w2v = api.load('word2vec-google-news-300')\nw2v = KeyedVectors.load_word2vec_format (w2v_file, binary=True)\n\n# Define the aimum sequence length (adjust as needed)\n#>> Will increasing max_sequence_length impact performance?\nmax_sequence_length = 100\n\nshowD(f'{w2v} can map words onto vectors with 300 dimensions')\n\n\n#>> 3/29/24 Completed in less than 30 seconds using 1347 as max_sequence_length \n\n# Assume you have a list of tokenized review called tokenized_review\n# Each element in tokenized_review is a list of tokens for a single review\n\nlengths = []\nfor review_tokens in tokenized_review:\n    lengths.append(len(review_tokens))\n\nlengths = sorted(lengths)\nlengths = lengths[-1:0:-1]\nshowD(f'Lengths of 100 longest reviews: {lengths[0:100]}')        \n\nmax_sequence_length = 100 #<< 3/29/24 1347 was the longest review length in sample\n\n# Initialize an empty tensor for padded reviews on the GPU\npadded_reviews = torch.zeros((len(tokenized_review), max_sequence_length, 300))\n\n# Initialize a mask tensor of the same shape as padded_reviews\n# Set it to False (or 0) initially, representing that all positions are padding\n# mask = torch.zeros_like(padded_reviews, dtype=torch.bool)\n\n# Initialize a mask tensor of the same shape as padded_reviews but with only sequence length\nmask = torch.zeros((len(tokenized_review), max_sequence_length), dtype=torch.bool)\n\nout_words = {}\nwords_in = 0\nwords_out = 0\n\n# Now, during the padding and embedding conversion loop, update the mask as well\nfor i, review_tokens in enumerate(tokenized_review):\n    review_length = min(len(review_tokens), max_sequence_length)\n    for j in range(review_length):\n        word = review_tokens[j]\n        if word in w2v:\n            words_in += 1\n            # Use Word2Vec vector if available\n            padded_reviews[i, j, :] = torch.tensor(w2v[word])\n            mask[i, j] = True  # Update the mask to indicate the presence of a word\n        else:\n            words_out += 1\n            out_words[word] = out_words.get(word, 0) + 1\n        # Otherwise, the mask remains False (or 0) for padding\n\n# Now you have a mask tensor that you can use later in your processing to ignore padded values\n# For example, if you want to apply max pooling only on non-padded values, you could use:\n# review_embeddings = torch.max(padded_reviews * mask.unsqueeze(-1).float(), dim=1)[0]\n\n# Ensure the mask is treated as a float for any operations that require it\nmask = mask.float()\n\n# Now you can use this mask tensor to exclude the padding from any subsequent computations\n\nprintv(f'{words_in} words found with vector representations, {words_out} without')\nprintv(f'Number of unique words without vector representations: {len(out_words)}')\nprintd('Sample of words without vector representations')\nkwords = list(out_words.keys())\nfor idx in range(0,len(kwords)-1,100):\n    kword = kwords[idx]\n    printd(f'{kword} - {out_words[kword]}')\n# Apply max pooling to aggregate embeddings along the sequence dimension\n# review_embeddings = torch.max(padded_reviews, dim=1)[0]\n\n# Now,review_embeddings contains the aggregated Word2Vec \n# embeddings for each review on the GPU\n\nshowC(f\"Created zero-padded, standard length reviews\")\n\nprint(padded_reviews[1])\n\n#>> padded_reviews are 100 x 300 tensors, zero padded if necessary\n#>> to get the standard lenth\ntext_embeddings_tensors = padded_reviews.to(device)\n\n# Rating labels\nrating_labels_tensors = torch.tensor(rating.values).to(device)\n\n# Dataset\ndataset = TensorDataset(text_embeddings_tensors, rating_labels_tensors)\nshowC(f'{dataset} defined')\n\nprintM() # print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\nprintNv() #!nvidia-smi\nprint('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\nif accelerator and showNv:\n    print(torch.cuda.memory_summary())\n\n# #>> padded_reviews are 100 x 300 tensors, zero padded if necessary\n# #>> to get the standard lenth\n# text_embeddings_tensors = padded_reviews.to(device)\n\n# # Rating labels\n# rating_labels_tensors = torch.tensor(rating.values).to(device)\n\n# # Dataset\n# dataset = TensorDataset(text_embeddings_tensors, rating_labels_tensors)\n# showC(f'{dataset} defined')\n\n# print(text_embeddings_tensors.shape)\n# print(rating_labels_tensors.shape)\n# print(text_embeddings_tensors.device)\n# print(rating_labels_tensors.device)\n# print(dataset)\n\n# # Lengths \n# train_len = int(0.8 * len(dataset))\n# val_len = len(dataset) - train_len\n\n# # Random split\n# train_data, val_data = random_split(dataset, [train_len, val_len])\n\n# printv(f\"The amount of data we have to train with is {len(train_data)} revieww\") \n# printv(f\"The amount of data we have to validate with is {len(val_data)} reviews\")\n# #print(f\"The amount of data we have to validate with is on {train_data.device}\")\n# #print(f\"The amount of data we have to validate with is on {val_data.device}\")\n\n# # DataLoader for training data\n# train_loader = DataLoader(train_data, batch_size = 32, shuffle = True)  # Use shuffle for training\n\n# # DataLoader for validation data\n# val_loader = DataLoader(val_data, batch_size = 32, shuffle = False)  # No need to shuffle for validation","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:41:05.573488Z","iopub.execute_input":"2024-04-14T09:41:05.573853Z","iopub.status.idle":"2024-04-14T09:50:39.927535Z","shell.execute_reply.started":"2024-04-14T09:41:05.573826Z","shell.execute_reply":"2024-04-14T09:50:39.926463Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"VERBOSE: Amazon reviews loaded into Panda\nColumn 'Id' has no empty entries or missing data.\nColumn 'ProductId' has no empty entries or missing data.\nColumn 'UserId' has no empty entries or missing data.\nColumn 'ProfileName' has empty entries or missing data.\nColumn 'HelpfulnessNumerator' has no empty entries or missing data.\nColumn 'HelpfulnessDenominator' has no empty entries or missing data.\nColumn 'Score' has no empty entries or missing data.\nColumn 'Time' has no empty entries or missing data.\nColumn 'Summary' has empty entries or missing data.\nColumn 'Text' has no empty entries or missing data.\n52,268 samples from balanced data with rating 1\n\n29,769 samples from balanced data with rating 2\n\n42,640 samples from balanced data with rating 3\n\n80,655 samples from balanced data with rating 4\n\n363,122 samples from balanced data with rating 5\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"5,000 samples from balanced data with rating 1\n\n5,000 samples from balanced data with rating 2\n\n5,000 samples from balanced data with rating 3\n\n5,000 samples from balanced data with rating 4\n\n5,000 samples from balanced data with rating 5\n\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_76/3794905291.py:56: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  balanced_data = sorted_data.groupby(sort_column).apply(lambda x: x.sample(n = balanced_data_size))\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"VERBOSE: specify the columns that will be used to train the classifier\nI bought a box, waist'd my $$ but people love me that I could give them this!!!<br />AFTER having a bough of HAVING to rush to bathroom I re-read the posts! AND looked at ingredients closer!<br />Gluten Free Whole Grain Dextrins<br />IF you don't have a problem GREAT! If you do you may end up re-reading the 1's later -}<br />I like the idea of Bites had them before. going to try out Pamela's.<br />I Love the Nana's Cookies but IT's VERY hard Not to eat the Whole cookie! The  <a href=\"http://www.amazon.com/gp/product/B000FNEX8C\">Nana's No Gluten Lemon Cookie, 3.5-Ounce Cookies (Pack of 12)</a> & <a href=\"http://www.amazon.com/gp/product/B000FNB3BC\">Nana's No Gluten Ginger Cookie, 3.5-Ounce Packages (Pack of 12)</a> It's TWO servings!! Plus the texture is soooo smooth it go's down VERY easy! I don't have Coffee or Chocolate anymore! Have Green Tea Decaf.<br />NEED to go to the Nana's Banana Bars + modify or delete my post!<br />Only Bites I hope Pamela's ginger works out for me!<br />I Do LOVE this TOO <a href=\"http://www.amazon.com/gp/product/B000FVUM0C\">Lundberg Eco-Farmed Honey Nut Rice Cake, 9.5-Ounce Units  (Pack of 12)</a> +<a href=\"http://www.amazon.com/gp/product/B000FVUM02\">Lundberg Eco-Farmed Buttery Caramel Rice Cake, 9.5-Ounce Units  (Pack of 12)</a> + <a href=\"http://www.amazon.com/gp/product/B000FVZW7K\">Lundberg Eco-Farmed Brown Rice Cake, Salt Free, 8.5-Ounce Units  (Pack of 12)</a> \n\n['i', 'bought', 'a', 'box', \"waist'd\", 'my', ' ', 'but', 'people', 'love', 'me', 'that', 'i', 'could', 'give', 'them', 'thisafter', 'having', 'a', 'bough', 'of', 'having', 'to', 'rush', 'to', 'bathroom', 'i', 'reread', 'the', 'posts', 'and', 'looked', 'at', 'ingredients', 'closergluten', 'free', 'whole', 'grain', 'dextrinsif', 'you', 'do', \"n't\", 'have', 'a', 'problem', 'great', 'if', 'you', 'do', 'you', 'may', 'end', 'up', 'rereading', 'the', '1', \"'s\", 'later', 'i', 'like', 'the', 'idea', 'of', 'bites', 'had', 'them', 'before', 'going', 'to', 'try', 'out', \"pamela'si\", 'love', 'the', 'nana', \"'s\", 'cookies', 'but', 'it', \"'s\", 'very', 'hard', 'not', 'to', 'eat', 'the', 'whole', 'cookie', 'the', ' ', 'nana', \"'s\", 'no', 'gluten', 'lemon', 'cookie', '35ounce', 'cookies', 'pack', 'of', '12', ' ', 'nana', \"'s\", 'no', 'gluten', 'ginger', 'cookie', '35ounce', 'packages', 'pack', 'of', '12', 'it', \"'s\", 'two', 'servings', 'plus', 'the', 'texture', 'is', 'soooo', 'smooth', 'it', 'go', \"'s\", 'down', 'very', 'easy', 'i', 'do', \"n't\", 'have', 'coffee', 'or', 'chocolate', 'anymore', 'have', 'green', 'tea', 'decafneed', 'to', 'go', 'to', 'the', 'nana', \"'s\", 'banana', 'bars', ' ', 'modify', 'or', 'delete', 'my', 'postonly', 'bites', 'i', 'hope', 'pamela', \"'s\", 'ginger', 'works', 'out', 'for', 'mei', 'do', 'love', 'this', 'too', 'lundberg', 'ecofarmed', 'honey', 'nut', 'rice', 'cake', '95ounce', 'units', ' ', 'pack', 'of', '12', 'lundberg', 'ecofarmed', 'buttery', 'caramel', 'rice', 'cake', '95ounce', 'units', ' ', 'pack', 'of', '12', ' ', 'lundberg', 'ecofarmed', 'brown', 'rice', 'cake', 'salt', 'free', '85ounce', 'units', ' ', 'pack', 'of', '12'] \n\n207 \n\n(25000,)\nMean: 89.69\nMedian: 65.00\nMode: ModeResult(mode=25, count=374)\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 800x600 with 1 Axes>","image/png":"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"},"metadata":{}},{"name":"stdout","text":"VERBOSE: KeyedVectors<vector_size=300, 3000000 keys> can map words onto vectors with 300 dimensions\nVERBOSE: Lengths of 100 longest reviews: [1534, 1364, 1247, 1097, 1072, 1053, 1053, 1053, 958, 935, 908, 891, 875, 861, 861, 861, 861, 861, 861, 861, 861, 861, 861, 861, 861, 861, 861, 861, 861, 861, 861, 861, 861, 861, 861, 861, 861, 854, 837, 836, 828, 826, 820, 799, 793, 743, 742, 741, 718, 716, 713, 706, 705, 696, 693, 691, 679, 675, 674, 670, 670, 669, 667, 663, 663, 641, 633, 625, 624, 619, 619, 614, 613, 612, 608, 607, 602, 596, 595, 588, 588, 588, 588, 587, 584, 582, 579, 577, 571, 571, 571, 570, 570, 569, 567, 565, 564, 563, 561, 560]\nDEV: Sample of words without vector representations\nDEV: a - 40774\nDEV: 10bag - 1\nDEV: mealproduct - 1\nDEV: servicedon't - 1\nDEV: milka - 5\nDEV: 5070 - 2\nDEV: colie - 1\nDEV: cadbury - 17\nDEV: nitriteif - 2\nDEV: biteif - 1\nDEV: butterif - 1\nDEV: ozbo - 3\nDEV: mixturewhich - 1\nDEV: knowall - 1\nDEV: wowthis - 1\nDEV: elsewherethey - 1\nDEV: nutrisca - 2\nDEV: vomitinghad - 2\nDEV: againguess - 1\nDEV: decafit - 2\nDEV: prizei - 1\nDEV: thingnot - 1\nDEV: creamyish - 1\nDEV: paprikawhich - 1\nDEV: porcupinessquirrelswhatever - 1\nDEV: 370001069 - 1\nDEV: snaplock - 2\nDEV: experiencethere - 1\nDEV: kirland - 2\nDEV: coffeethis - 9\nDEV: disappointedone - 1\nDEV: dayseems - 1\nDEV: extremesalthough - 1\nDEV: kinnitoos - 1\nDEV: snikiddy - 1\nDEV: ecta - 1\nDEV: nonpeanut - 2\nDEV: boyardeeknowing - 1\nDEV: laxativeswhich - 1\nDEV: 4200 - 1\nDEV: 1700 - 1\nDEV: stemspartial - 1\nDEV: blendingjust - 1\nDEV: batteryacid - 1\nDEV: ozi - 3\nDEV: werther - 2\nDEV: bitesi - 1\nDEV: cupsworth - 1\nDEV: greatbut - 4\nDEV: organictype - 2\nDEV: steamingresultpros - 1\nDEV: amazingi - 2\nDEV: jtc - 1\nDEV: 565 - 1\nDEV: mleveni - 1\nDEV: guiltfree - 7\nDEV: diiference - 1\nDEV: leaki - 1\nDEV: barilla - 14\nDEV: acidicon - 1\nDEV: perspective1 - 4\nDEV: chickenflavored - 4\nDEV: delobas - 1\nDEV: 3579 - 1\nDEV: lhasopoo - 1\nDEV: o'dells - 1\nDEV: twostar - 1\nDEV: powderychalky - 1\nDEV: 3998 - 1\nDEV: hadwould - 1\nDEV: whimi - 3\nDEV: wrappingthe - 1\nDEV: itexcept - 2\nDEV: blueberryzi - 1\nDEV: tolerateit - 1\nDEV: sweettwo - 1\nDEV: vanillay - 2\nDEV: kavalactonesi - 1\nDEV: nonesuch - 1\nDEV: velveetaey - 1\nDEV: unpalatableand - 1\nDEV: everydayupdate - 1\nDEV: sipi - 1\nDEV: sodaaspartame - 1\nDEV: smooshedwhy - 1\nDEV: truthinadvertising - 1\nDEV: teakind - 1\nDEV: tastemuch - 3\nDEV: rebaked - 1\nDEV: compained - 2\nDEV: bruleacutee - 1\nDEV: surprisebiscoff - 1\nDEV: thistastewise - 1\nDEV: insideoutside - 2\nDEV: brisling - 6\nDEV: informationcalories5 - 1\nDEV: shippingwowforgetaboutitham - 1\nDEV: branholds - 1\nDEV: anythingusing - 2\nDEV: strongtart - 1\nDEV: oddat - 1\nDEV: lolanyway - 1\nDEV: tastestronger - 1\nDEV: minewhile - 1\nDEV: bevmo - 1\nDEV: storeand - 1\nDEV: catsize - 1\nDEV: lme - 2\nDEV: tequilamy - 1\nDEV: meltingthe - 1\nDEV: valuefor - 1\nDEV: 30amount - 1\nDEV: serviing - 1\nDEV: mentionedthe - 2\nDEV: 8090 - 1\nDEV: coffess - 2\nDEV: greatcuisinart - 1\nDEV: supermix - 2\nDEV: bonusas - 1\nDEV: gamehave - 1\nDEV: fauxlime - 1\nDEV: sweetness1 - 1\nDEV: odlums - 1\nDEV: bottlethere - 1\nDEV: officethese - 1\nDEV: shortgrowing - 1\nDEV: ingredientsannie - 1\nDEV: bananamilk - 1\nDEV: 4ds - 1\nDEV: sweetthey - 1\nDEV: satifyingly - 2\nDEV: awesomethe - 1\nDEV: texturethus - 1\nDEV: needdesire - 1\nDEV: amazoncomgeneral - 1\nDEV: bowlhe - 1\nDEV: versatilityfirst - 1\nDEV: somefor - 1\nDEV: pourthrough - 1\nDEV: cerealnext - 1\nDEV: twomillimeter - 1\nDEV: blandperhaps - 1\nDEV: breakablethe - 1\nDEV: childhoodi - 1\nDEV: wonderingingredients - 1\nDEV: tryyou - 1\nDEV: providedthank - 1\nDEV: useas - 1\nDEV: stuffhonestly - 1\nDEV: possibilitiesi've - 1\nDEV: yummypeppermint - 1\nDEV: bestin - 1\nDEV: fructosedextrose - 1\nDEV: prefiltered - 1\nDEV: combinationsweetness - 1\nDEV: tastyi'm - 1\nDEV: brewingsystem - 1\nDEV: overwhelmingbut - 1\nDEV: therea - 1\nDEV: sthsogo - 1\nDEV: crunchya - 1\nDEV: goodthanks - 1\nDEV: sweetenersseriously - 1\nDEV: cafestol - 2\nDEV: ithencemy - 1\nDEV: peperoni - 1\nDEV: impressedi - 1\nDEV: etcthis - 1\nDEV: tatsty - 1\nDEV: diabeticsit - 1\nDEV: kittyies - 1\nDEV: colorsno - 1\nDEV: themjust - 1\nDEV: problemkeeping - 1\nDEV: opinionlike - 1\nDEV: theydo - 1\nDEV: floridawhere - 1\nDEV: helpcw - 1\nDEV: moraes - 1\nDEV: youmy - 1\nDEV: virgini - 1\nDEV: paldo - 1\nDEV: coffeesshop - 1\nDEV: tassimoin - 1\nDEV: mmmmmblueberry - 1\nDEV: whoprescribed - 1\nDEV: 2boats - 1\nDEV: 14yearold - 1\nDEV: learnanyway - 1\nDEV: roasterie - 1\nDEV: pcc - 1\nDEV: drinkerdon't - 1\nDEV: i'lleatanykindoffood - 1\nDEV: nonnutty - 1\nDEV: vinegari've - 1\ntensor([[-0.2256, -0.0195,  0.0908,  ...,  0.0282, -0.1777, -0.0060],\n        [-0.1562,  0.0315, -0.1279,  ..., -0.1514, -0.1279, -0.0427],\n        [ 0.0239, -0.0461,  0.0039,  ..., -0.2695, -0.0688, -0.2754],\n        ...,\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000],\n        [ 0.0000,  0.0000,  0.0000,  ...,  0.0000,  0.0000,  0.0000]])\nTotal allocated memory: 3001224704 bytes\n\n\n\n\n\n\n\n\n\n\n\n","output_type":"stream"}]},{"cell_type":"code","source":"# HyperParameters for the module\nd_model = 300  # Should match the embedding dimension of your word embeddings\nseq_len = 100  # Maximum sequence length\ninput_size = d_model  # based on the output size of your feed-forward network\n\nnum_layers = 4 # Number of encoder layers\nh       = 10   # number of attention head\nd_ffn   = 1024 # dimension of the feedforward layer\n\ndropout = 0.0#0.1  # You can adjust the dropout if needed\neps     = 1e-6 # epsilon value to prevent the standard deviation from becoming zero\nepochs  = 10\nlearning_rate = 0.01\n\n\"\"\"\nTo ensure compatibility, it's important to choose the \nnumber of attention heads (h) such that d_model is \nevenly divisible by h in the multi-head attention \nmodule's self.d_k. This allows for a clean distribution \nof the model dimensionality across the attention heads.\n\"\"\"\n\n# d_model / attn.h = 300 / 10 = 30","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:50:39.929697Z","iopub.execute_input":"2024-04-14T09:50:39.930425Z","iopub.status.idle":"2024-04-14T09:50:39.938851Z","shell.execute_reply.started":"2024-04-14T09:50:39.930373Z","shell.execute_reply":"2024-04-14T09:50:39.937835Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"\"\\nTo ensure compatibility, it's important to choose the \\nnumber of attention heads (h) such that d_model is \\nevenly divisible by h in the multi-head attention \\nmodule's self.d_k. This allows for a clean distribution \\nof the model dimensionality across the attention heads.\\n\""},"metadata":{}}]},{"cell_type":"code","source":"class PositionalEncoding(nn.Module):\n    \n    def __init__(self, d_model: int, dropout: float, seq_len: int):\n        \"\"\"\n        Initialize the PositionalEncoding module.\n\n        Args:\n            d_model (int): The dimensionality of the model (embedding size).\n            dropout (float): The dropout rate to be applied.\n            seq_len (int): The maximum sequence length.\n        \"\"\"\n        super().__init__()\n        self.dropout = nn.Dropout(p=dropout)\n\n        # Create a tensor of shape (seq_len, 1) representing the positions\n        position = torch.arange(seq_len).unsqueeze(1)\n        \n        # Compute the denominator term for the sinusoidal positional encoding\n        # The denominator is 10000^(2i/d_model), where i is the position index\n        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n        \n        # Create a tensor of shape (seq_len, 1, d_model) to store the positional encodings\n        pe = torch.zeros(seq_len, 1, d_model)\n        \n        # Compute the sinusoidal positional encodings for even dimensions\n        # pe[:, 0, 0::2] selects the even dimensions (0, 2, 4, ...) of the positional encoding tensor\n        # position * div_term computes the angle for each position and even dimension\n        # torch.sin applies the sine function element-wise to compute the positional encoding values\n        pe[:, 0, 0::2] = torch.sin(position * div_term)\n        \n        # Compute the sinusoidal positional encodings for odd dimensions\n        # pe[:, 0, 1::2] selects the odd dimensions (1, 3, 5, ...) of the positional encoding tensor\n        # torch.cos applies the cosine function element-wise to compute the positional encoding values\n        pe[:, 0, 1::2] = torch.cos(position * div_term)\n        \n        # Register the positional encoding tensor as a buffer in the module\n        # This ensures that the positional encoding tensor is saved and loaded with the module\n        self.register_buffer('pe', pe)\n\n    def forward(self, x):\n        \"\"\"\n        Perform the forward pass of the PositionalEncoding module.\n\n        Args:\n            x (Tensor): The input tensor of shape (seq_len, batch_size, embedding_dim).\n\n        Returns:\n            Tensor: The input tensor with positional encodings added.\n        \"\"\"\n        # Add positional encodings to the input tensor\n        # x.size(0) returns the sequence length dimension of the input tensor\n        # self.pe[:x.size(0)] selects the positional encodings corresponding to the sequence length\n        x = x + self.pe[:x.size(0)]\n        \n        # Apply dropout to the tensor with positional encodings\n        return self.dropout(x)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:50:39.940253Z","iopub.execute_input":"2024-04-14T09:50:39.940635Z","iopub.status.idle":"2024-04-14T09:50:39.993683Z","shell.execute_reply.started":"2024-04-14T09:50:39.940601Z","shell.execute_reply":"2024-04-14T09:50:39.992696Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"class MultiHeadedAttention(nn.Module):\n    def __init__(self, h, d_model, dropout=dropout):\n        super().__init__()\n        \n        # Number of attention heads\n        self.h = h\n        \n        # Dimensionality of each attention head\n        self.d_k = d_model // h\n        \n        # Linear layers for query, key, value, and output projections\n        self.linears = nn.ModuleList([nn.Linear(d_model, d_model) for _ in range(4)])\n        \n        # Dropout layer\n        self.dropout = nn.Dropout(p=dropout)\n\n    @staticmethod\n    def scaled_dot_product_attention(query, key, value, mask=None, dropout=None):\n        # Compute the dimensionality of each attention head\n        d_k = query.size(-1)\n        \n        # Compute the attention scores using the dot product between query and key\n        scores = torch.matmul(query, key.transpose(-2, -1)) / math.sqrt(d_k)\n        \n        # Apply the mask to the attention scores (if provided)\n        if mask is not None:\n            scores = scores.masked_fill(mask == 0, float('-inf'))\n        \n        # Apply softmax to obtain the attention probabilities\n        p_attn = torch.softmax(scores, dim=-1)\n        \n        # Apply dropout to the attention probabilities (if specified)\n        if dropout is not None:\n            p_attn = dropout(p_attn)\n        \n        # Compute the weighted sum of values using the attention probabilities\n        # Return the attended values and attention probabilities\n        return torch.matmul(p_attn, value), p_attn\n\n    def forward(self, query, key, value, mask=None):\n        # Get the number of batches\n        nbatches = query.size(0)\n        \n        # Project and reshape the query, key, and value for multi-head attention\n        # The projections are done using the linear layers defined in __init__\n        query, key, value = [\n            l(x).view(nbatches, -1, self.h, self.d_k).transpose(1, 2)\n            for l, x in zip(self.linears, (query, key, value))\n        ]\n        \n        # Perform scaled dot-product attention on the projected query, key, and value\n        x, attn = self.scaled_dot_product_attention(query, key, value, mask=mask, dropout=self.dropout)\n        \n        # Reshape the attended output and concatenate the attention heads\n        x = x.transpose(1, 2).contiguous().view(nbatches, -1, self.h * self.d_k)\n        \n        # Apply a final linear projection to the concatenated output\n        return self.linears[-1](x)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:50:39.996685Z","iopub.execute_input":"2024-04-14T09:50:39.997081Z","iopub.status.idle":"2024-04-14T09:50:40.012838Z","shell.execute_reply.started":"2024-04-14T09:50:39.997043Z","shell.execute_reply":"2024-04-14T09:50:40.011844Z"},"trusted":true},"execution_count":9,"outputs":[]},{"cell_type":"code","source":"def add_layer(x, y):\n    \"\"\"Adds two tensors together.\n\n    Args:\n    x: A torch.Tensor of shape (batch_size, seq_len, hidden_size).\n    y: A torch.Tensor of the same shape as x.\n\n    Returns:\n    A torch.Tensor of the same shape as x and y, containing the sum of the two tensors.\n    \"\"\"\n\n    return torch.add(x, y)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:50:40.013995Z","iopub.execute_input":"2024-04-14T09:50:40.014343Z","iopub.status.idle":"2024-04-14T09:50:40.028300Z","shell.execute_reply.started":"2024-04-14T09:50:40.014294Z","shell.execute_reply":"2024-04-14T09:50:40.027365Z"},"trusted":true},"execution_count":10,"outputs":[]},{"cell_type":"code","source":"class LayerNorm(nn.Module):\n    \"\"\"\n    Construct a layernorm module (See citation for details).\n    \n    Layer normalization is a technique to normalize the activations of a layer.\n    It helps stabilize the training process and can lead to faster convergence.\n    \n    This implementation follows the original paper:\n    \"Layer Normalization\" by Jimmy Lei Ba, Jamie Ryan Kiros, and Geoffrey E. Hinton\n    https://arxiv.org/abs/1607.06450\n    \"\"\"\n    \n    def __init__(self, features, eps=1e-6):\n        \"\"\"\n        Initialize the LayerNorm module.\n        \n        Args:\n            features (int): The number of features (channels) in the input tensor.\n            eps (float): A small value added to the variance for numerical stability.\n                         Default is 1e-6.\n        \"\"\"\n        super(LayerNorm, self).__init__()\n        \n        # Create learnable parameters for scaling and shifting\n        self.a_2 = nn.Parameter(torch.ones(features))\n        self.b_2 = nn.Parameter(torch.zeros(features))\n        \n        self.eps = eps\n    \n    def forward(self, x):\n        \"\"\"\n        Perform layer normalization on the input tensor.\n        \n        Args:\n            x (torch.Tensor): Input tensor of shape (batch_size, ..., features).\n        \n        Returns:\n            torch.Tensor: Normalized tensor of the same shape as the input.\n        \"\"\"\n        # Compute the mean across the last dimension (features)\n        mean = x.mean(-1, keepdim=True)\n        \n        # Compute the standard deviation across the last dimension (features)\n        std = x.std(-1, keepdim=True)\n        \n        # Normalize the input tensor\n        x_normalized = (x - mean) / (std + self.eps)\n        \n        # Scale and shift the normalized tensor\n        out = self.a_2 * x_normalized + self.b_2\n        \n        return out","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:50:40.029628Z","iopub.execute_input":"2024-04-14T09:50:40.030007Z","iopub.status.idle":"2024-04-14T09:50:40.042876Z","shell.execute_reply.started":"2024-04-14T09:50:40.029976Z","shell.execute_reply":"2024-04-14T09:50:40.042016Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"class PositionwiseFeedForward(nn.Module):\n    def __init__(self, d_model: int, d_ffn: int, dropout: float):\n        \"\"\"\n        Initializes the PositionwiseFeedForward module.\n\n        Args:\n            d_model (int): The dimension of the input embeddings.\n            d_ffn (int): The dimension of the hidden layer in the feed-forward network.\n            dropout (float): The probability of dropout occurring.\n        \"\"\"\n        super().__init__()\n        \n        # Linear layer that maps from the input dimension (d_model) to the hidden dimension (d_ffn)\n        self.w_1 = nn.Linear(d_model, d_ffn)\n        \n        # Linear layer that maps from the hidden dimension (d_ffn) back to the input dimension (d_model)\n        self.w_2 = nn.Linear(d_ffn, d_model)\n        \n        # Dropout layer with the specified dropout probability\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        \"\"\"\n        Performs the forward pass of the PositionwiseFeedForward module.\n\n        Args:\n            x (torch.Tensor): The input tensor of shape (batch_size, seq_length, d_model),\n                              representing the output from the attention mechanism.\n\n        Returns:\n            torch.Tensor: The output tensor of shape (batch_size, seq_length, d_model),\n                          representing the expanded-and-contracted representation.\n        \"\"\"\n        \n        # Apply the first linear transformation (w_1) to the input tensor (x)\n        # This maps the input from the embedding dimension (d_model) to the hidden dimension (d_ffn)\n        hidden = self.w_1(x)\n        \n        # Apply the ReLU activation function to the hidden representation\n        activated = torch.relu(hidden)\n        \n        # Apply dropout to the activated hidden representation\n        dropped = self.dropout(activated)\n        \n        # Apply the second linear transformation (w_2) to the dropped representation\n        # This maps the hidden dimension (d_ffn) back to the embedding dimension (d_model)\n        output = self.w_2(dropped)\n        \n        # Return the final output tensor\n        return output","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:50:40.044370Z","iopub.execute_input":"2024-04-14T09:50:40.044703Z","iopub.status.idle":"2024-04-14T09:50:40.057985Z","shell.execute_reply.started":"2024-04-14T09:50:40.044672Z","shell.execute_reply":"2024-04-14T09:50:40.057155Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"class EncoderLayer(nn.Module):\n    def __init__(self, d_model, num_heads, d_ffn, dropout):\n        \"\"\"\n        Initialize an encoder layer.\n\n        Args:\n            d_model (int): The dimension of the input and output of the layer.\n            num_heads (int): The number of attention heads.\n            d_ffn (int): The dimension of the feedforward network.\n            dropout (float): The dropout probability.\n        \"\"\"\n        super().__init__()\n        self.self_attn = MultiHeadedAttention(num_heads, d_model, dropout)\n        self.feed_forward = PositionwiseFeedForward(d_model, d_ffn, dropout)\n        self.sublayer = nn.ModuleList([LayerNorm(d_model) for _ in range(2)])\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x, mask):\n        \"\"\"\n        Perform the forward pass of the encoder layer.\n\n        Args:\n            x (torch.Tensor): The input tensor of shape (batch_size, sequence_length, d_model).\n            mask (torch.Tensor): The attention mask tensor of shape (batch_size, 1, sequence_length, sequence_length).\n\n        Returns:\n            torch.Tensor: The output tensor of the encoder layer.\n        \"\"\"\n        sublayer_output = self.self_attn(x, x, x, mask)\n        x = x + self.dropout(sublayer_output)  # Apply dropout to the sublayer output before adding it to the input\n        x = self.sublayer[0](x)  # Apply normalization after the residual connection\n        sublayer_output = self.feed_forward(x)\n        x = x + self.dropout(sublayer_output)  # Again, apply dropout before the residual connection\n        x = self.sublayer[1](x)  # Apply normalization after the residual connection\n        return x\n\nclass StackedEncoder(nn.Module):\n    def __init__(self, num_layers, d_model, num_heads, d_ffn, dropout):\n        \"\"\"\n        Initialize a stacked encoder.\n\n        Args:\n            num_layers (int): The number of encoder layers.\n            d_model (int): The dimension of the input and output of each layer.\n            num_heads (int): The number of attention heads in each layer.\n            d_ffn (int): The dimension of the feedforward network in each layer.\n            dropout (float): The dropout probability.\n        \"\"\"\n        super().__init__()\n        self.layers = nn.ModuleList([\n            EncoderLayer(d_model, num_heads, d_ffn, dropout) for _ in range(num_layers)\n        ])\n        self.norm = LayerNorm(d_model)\n\n    def forward(self, x, mask):\n        \"\"\"\n        Perform the forward pass of the stacked encoder.\n\n        Args:\n            x (torch.Tensor): The input tensor of shape (batch_size, sequence_length, d_model).\n            mask (torch.Tensor): The attention mask tensor of shape (batch_size, 1, sequence_length, sequence_length).\n\n        Returns:\n            torch.Tensor: The output tensor of the stacked encoder.\n        \"\"\"\n        for layer in self.layers:\n            x = layer(x, mask)\n        return self.norm(x)  # Apply normalization to the output of the last layer","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:50:40.059216Z","iopub.execute_input":"2024-04-14T09:50:40.059524Z","iopub.status.idle":"2024-04-14T09:50:40.073714Z","shell.execute_reply.started":"2024-04-14T09:50:40.059496Z","shell.execute_reply":"2024-04-14T09:50:40.072784Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"stacked_encoder = StackedEncoder(num_layers, d_model, \n                                 h, d_ffn, dropout).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:50:40.074690Z","iopub.execute_input":"2024-04-14T09:50:40.074951Z","iopub.status.idle":"2024-04-14T09:50:40.180435Z","shell.execute_reply.started":"2024-04-14T09:50:40.074928Z","shell.execute_reply":"2024-04-14T09:50:40.179640Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"#>> padded_reviews are 100 x 300 tensors, zero padded if necessary\n#>> to get the standard lenth\ntext_embeddings_tensors = padded_reviews.to(device)\n\n# Rating labels\nrating_labels_tensors = torch.tensor(rating.values).to(device)\n\n# Dataset\ndataset = TensorDataset(text_embeddings_tensors, rating_labels_tensors)\nshowC(f'{dataset} defined')\n\nprint(text_embeddings_tensors.shape)\nprint(rating_labels_tensors.shape)\nprint(text_embeddings_tensors.device)\nprint(rating_labels_tensors.device)\nprint(dataset)\n\n# DataLoader for training data\ndata_loader = DataLoader(dataset, batch_size = 32, shuffle = True)  # Use shuffle for training\n\n!nvidia-smi","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:50:40.182912Z","iopub.execute_input":"2024-04-14T09:50:40.183210Z","iopub.status.idle":"2024-04-14T09:50:42.001508Z","shell.execute_reply.started":"2024-04-14T09:50:40.183185Z","shell.execute_reply":"2024-04-14T09:50:42.000455Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"torch.Size([25000, 100, 300])\ntorch.Size([25000])\ncuda:0\ncuda:0\n<torch.utils.data.dataset.TensorDataset object at 0x7a71284cf850>\nSun Apr 14 09:50:41 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n| N/A   34C    P0              32W / 250W |   6008MiB / 16384MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\n","output_type":"stream"}]},{"cell_type":"code","source":"total_encoded_batches = []  # List to store encoded batches\ntotal_y_batches = []        # List to store corresponding y batches\ni = 0\n\nfor x_batch, y_batch in data_loader:\n    print(f'Size of batch: {x_batch.shape}')\n    i += 1\n    print(i)\n    print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\n    \n    # Move the batch to the device\n    x_batch = x_batch.to(device)\n    y_batch = y_batch.to(device)\n    \n    # Create a mask of ones for each sequence in the batch\n    #mask = torch.ones(x_batch.size(0), seq_len, seq_len, device=device)\n    \n    # Encode the batch using the stacked_encoder\n    encoded_batch = stacked_encoder(x_batch, mask = None)\n    \n    # Append the encoded batch to the list\n    total_encoded_batches.append(encoded_batch.detach().cpu())\n    total_y_batches.append(y_batch.detach().cpu())\n    \n    print(f'Current Size of Reviews: {len(total_encoded_batches)} tensors')\n    print(f'Current Size of Ratings: {len(total_y_batches)} tensors')\n\n\n# Concatenate all the encoded batches into a single tensor\ntotal_encoded_batch = torch.cat(total_encoded_batches, dim = 0)\n\n# Concatenate all the corresponding y batches into a single tensor\ntotal_y_batch = torch.cat(total_y_batches, dim = 0)\n\nprint(f'Concatenated Reviews Size: {total_encoded_batch.shape}')\nprint(f'Concatenated Ratings Size: {total_y_batch.shape}')","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:50:42.003114Z","iopub.execute_input":"2024-04-14T09:50:42.003435Z","iopub.status.idle":"2024-04-14T09:50:52.452908Z","shell.execute_reply.started":"2024-04-14T09:50:42.003405Z","shell.execute_reply":"2024-04-14T09:50:52.451871Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Size of batch: torch.Size([32, 100, 300])\n1\nTotal allocated memory: 3020737536 bytes\nCurrent Size of Reviews: 1 tensors\nCurrent Size of Ratings: 1 tensors\nSize of batch: torch.Size([32, 100, 300])\n2\nTotal allocated memory: 3332796416 bytes\nCurrent Size of Reviews: 2 tensors\nCurrent Size of Ratings: 2 tensors\nSize of batch: torch.Size([32, 100, 300])\n3\nTotal allocated memory: 3332796416 bytes\nCurrent Size of Reviews: 3 tensors\nCurrent Size of Ratings: 3 tensors\nSize of batch: torch.Size([32, 100, 300])\n4\nTotal allocated memory: 3332796416 bytes\nCurrent Size of Reviews: 4 tensors\nCurrent Size of Ratings: 4 tensors\nSize of batch: torch.Size([32, 100, 300])\n5\nTotal allocated memory: 3332796416 bytes\nCurrent Size of Reviews: 5 tensors\nCurrent Size of Ratings: 5 tensors\nSize of batch: torch.Size([32, 100, 300])\n6\nTotal allocated memory: 3332796416 bytes\nCurrent Size of Reviews: 6 tensors\nCurrent Size of Ratings: 6 tensors\nSize of batch: torch.Size([32, 100, 300])\n7\nTotal allocated memory: 3332796416 bytes\nCurrent Size of Reviews: 7 tensors\nCurrent Size of Ratings: 7 tensors\nSize of batch: torch.Size([32, 100, 300])\n8\nTotal allocated memory: 3332796416 bytes\nCurrent Size of Reviews: 8 tensors\nCurrent Size of Ratings: 8 tensors\nSize of batch: torch.Size([32, 100, 300])\n9\nTotal allocated memory: 3332796416 bytes\nCurrent Size of Reviews: 9 tensors\nCurrent Size of Ratings: 9 tensors\nSize of batch: torch.Size([32, 100, 300])\n10\nTotal allocated memory: 3332796416 bytes\nCurrent Size of Reviews: 10 tensors\nCurrent Size of Ratings: 10 tensors\nSize of batch: torch.Size([32, 100, 300])\n11\nTotal allocated memory: 3332796416 bytes\nCurrent Size of Reviews: 11 tensors\nCurrent Size of Ratings: 11 tensors\nSize of batch: torch.Size([32, 100, 300])\n12\nTotal allocated memory: 3332796416 bytes\nCurrent Size of Reviews: 12 tensors\nCurrent Size of Ratings: 12 tensors\nSize of batch: torch.Size([32, 100, 300])\n13\nTotal allocated memory: 3332796416 bytes\nCurrent Size of Reviews: 13 tensors\nCurrent Size of Ratings: 13 tensors\nSize of batch: torch.Size([32, 100, 300])\n14\nTotal allocated memory: 3332796416 bytes\nCurrent Size of Reviews: 14 tensors\nCurrent Size of Ratings: 14 tensors\nSize of batch: torch.Size([32, 100, 300])\n15\nTotal allocated memory: 3332796416 bytes\nCurrent Size of Reviews: 15 tensors\nCurrent Size of Ratings: 15 tensors\nSize of batch: torch.Size([32, 100, 300])\n16\nTotal allocated memory: 3332796416 bytes\nCurrent Size of Reviews: 16 tensors\nCurrent Size of Ratings: 16 tensors\nSize of batch: torch.Size([32, 100, 300])\n17\nTotal allocated memory: 3332796416 bytes\nCurrent Size of Reviews: 17 tensors\nCurrent Size of Ratings: 17 tensors\nSize of batch: torch.Size([32, 100, 300])\n18\nTotal allocated memory: 3333462016 bytes\nCurrent Size of Reviews: 18 tensors\nCurrent Size of Ratings: 18 tensors\nSize of batch: torch.Size([32, 100, 300])\n19\nTotal allocated memory: 3332796416 bytes\nCurrent Size of Reviews: 19 tensors\nCurrent Size of Ratings: 19 tensors\nSize of batch: torch.Size([32, 100, 300])\n20\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 20 tensors\nCurrent Size of Ratings: 20 tensors\nSize of batch: torch.Size([32, 100, 300])\n21\nTotal allocated memory: 3332796416 bytes\nCurrent Size of Reviews: 21 tensors\nCurrent Size of Ratings: 21 tensors\nSize of batch: torch.Size([32, 100, 300])\n22\nTotal allocated memory: 3333462016 bytes\nCurrent Size of Reviews: 22 tensors\nCurrent Size of Ratings: 22 tensors\nSize of batch: torch.Size([32, 100, 300])\n23\nTotal allocated memory: 3332796416 bytes\nCurrent Size of Reviews: 23 tensors\nCurrent Size of Ratings: 23 tensors\nSize of batch: torch.Size([32, 100, 300])\n24\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 24 tensors\nCurrent Size of Ratings: 24 tensors\nSize of batch: torch.Size([32, 100, 300])\n25\nTotal allocated memory: 3334742016 bytes\nCurrent Size of Reviews: 25 tensors\nCurrent Size of Ratings: 25 tensors\nSize of batch: torch.Size([32, 100, 300])\n26\nTotal allocated memory: 3332847616 bytes\nCurrent Size of Reviews: 26 tensors\nCurrent Size of Ratings: 26 tensors\nSize of batch: torch.Size([32, 100, 300])\n27\nTotal allocated memory: 3332847616 bytes\nCurrent Size of Reviews: 27 tensors\nCurrent Size of Ratings: 27 tensors\nSize of batch: torch.Size([32, 100, 300])\n28\nTotal allocated memory: 3334434816 bytes\nCurrent Size of Reviews: 28 tensors\nCurrent Size of Ratings: 28 tensors\nSize of batch: torch.Size([32, 100, 300])\n29\nTotal allocated memory: 3333462016 bytes\nCurrent Size of Reviews: 29 tensors\nCurrent Size of Ratings: 29 tensors\nSize of batch: torch.Size([32, 100, 300])\n30\nTotal allocated memory: 3334434816 bytes\nCurrent Size of Reviews: 30 tensors\nCurrent Size of Ratings: 30 tensors\nSize of batch: torch.Size([32, 100, 300])\n31\nTotal allocated memory: 3333462016 bytes\nCurrent Size of Reviews: 31 tensors\nCurrent Size of Ratings: 31 tensors\nSize of batch: torch.Size([32, 100, 300])\n32\nTotal allocated memory: 3335049216 bytes\nCurrent Size of Reviews: 32 tensors\nCurrent Size of Ratings: 32 tensors\nSize of batch: torch.Size([32, 100, 300])\n33\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 33 tensors\nCurrent Size of Ratings: 33 tensors\nSize of batch: torch.Size([32, 100, 300])\n34\nTotal allocated memory: 3332847616 bytes\nCurrent Size of Reviews: 34 tensors\nCurrent Size of Ratings: 34 tensors\nSize of batch: torch.Size([32, 100, 300])\n35\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 35 tensors\nCurrent Size of Ratings: 35 tensors\nSize of batch: torch.Size([32, 100, 300])\n36\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 36 tensors\nCurrent Size of Ratings: 36 tensors\nSize of batch: torch.Size([32, 100, 300])\n37\nTotal allocated memory: 3332847616 bytes\nCurrent Size of Reviews: 37 tensors\nCurrent Size of Ratings: 37 tensors\nSize of batch: torch.Size([32, 100, 300])\n38\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 38 tensors\nCurrent Size of Ratings: 38 tensors\nSize of batch: torch.Size([32, 100, 300])\n39\nTotal allocated memory: 3334742016 bytes\nCurrent Size of Reviews: 39 tensors\nCurrent Size of Ratings: 39 tensors\nSize of batch: torch.Size([32, 100, 300])\n40\nTotal allocated memory: 3333462016 bytes\nCurrent Size of Reviews: 40 tensors\nCurrent Size of Ratings: 40 tensors\nSize of batch: torch.Size([32, 100, 300])\n41\nTotal allocated memory: 3334076416 bytes\nCurrent Size of Reviews: 41 tensors\nCurrent Size of Ratings: 41 tensors\nSize of batch: torch.Size([32, 100, 300])\n42\nTotal allocated memory: 3334076416 bytes\nCurrent Size of Reviews: 42 tensors\nCurrent Size of Ratings: 42 tensors\nSize of batch: torch.Size([32, 100, 300])\n43\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 43 tensors\nCurrent Size of Ratings: 43 tensors\nSize of batch: torch.Size([32, 100, 300])\n44\nTotal allocated memory: 3333769216 bytes\nCurrent Size of Reviews: 44 tensors\nCurrent Size of Ratings: 44 tensors\nSize of batch: torch.Size([32, 100, 300])\n45\nTotal allocated memory: 3334383616 bytes\nCurrent Size of Reviews: 45 tensors\nCurrent Size of Ratings: 45 tensors\nSize of batch: torch.Size([32, 100, 300])\n46\nTotal allocated memory: 3336022016 bytes\nCurrent Size of Reviews: 46 tensors\nCurrent Size of Ratings: 46 tensors\nSize of batch: torch.Size([32, 100, 300])\n47\nTotal allocated memory: 3335305216 bytes\nCurrent Size of Reviews: 47 tensors\nCurrent Size of Ratings: 47 tensors\nSize of batch: torch.Size([32, 100, 300])\n48\nTotal allocated memory: 3335049216 bytes\nCurrent Size of Reviews: 48 tensors\nCurrent Size of Ratings: 48 tensors\nSize of batch: torch.Size([32, 100, 300])\n49\nTotal allocated memory: 3334639616 bytes\nCurrent Size of Reviews: 49 tensors\nCurrent Size of Ratings: 49 tensors\nSize of batch: torch.Size([32, 100, 300])\n50\nTotal allocated memory: 3335714816 bytes\nCurrent Size of Reviews: 50 tensors\nCurrent Size of Ratings: 50 tensors\nSize of batch: torch.Size([32, 100, 300])\n51\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 51 tensors\nCurrent Size of Ratings: 51 tensors\nSize of batch: torch.Size([32, 100, 300])\n52\nTotal allocated memory: 3334076416 bytes\nCurrent Size of Reviews: 52 tensors\nCurrent Size of Ratings: 52 tensors\nSize of batch: torch.Size([32, 100, 300])\n53\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 53 tensors\nCurrent Size of Ratings: 53 tensors\nSize of batch: torch.Size([32, 100, 300])\n54\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 54 tensors\nCurrent Size of Ratings: 54 tensors\nSize of batch: torch.Size([32, 100, 300])\n55\nTotal allocated memory: 3334076416 bytes\nCurrent Size of Reviews: 55 tensors\nCurrent Size of Ratings: 55 tensors\nSize of batch: torch.Size([32, 100, 300])\n56\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 56 tensors\nCurrent Size of Ratings: 56 tensors\nSize of batch: torch.Size([32, 100, 300])\n57\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 57 tensors\nCurrent Size of Ratings: 57 tensors\nSize of batch: torch.Size([32, 100, 300])\n58\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 58 tensors\nCurrent Size of Ratings: 58 tensors\nSize of batch: torch.Size([32, 100, 300])\n59\nTotal allocated memory: 3334025216 bytes\nCurrent Size of Reviews: 59 tensors\nCurrent Size of Ratings: 59 tensors\nSize of batch: torch.Size([32, 100, 300])\n60\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 60 tensors\nCurrent Size of Ratings: 60 tensors\nSize of batch: torch.Size([32, 100, 300])\n61\nTotal allocated memory: 3334076416 bytes\nCurrent Size of Reviews: 61 tensors\nCurrent Size of Ratings: 61 tensors\nSize of batch: torch.Size([32, 100, 300])\n62\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 62 tensors\nCurrent Size of Ratings: 62 tensors\nSize of batch: torch.Size([32, 100, 300])\n63\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 63 tensors\nCurrent Size of Ratings: 63 tensors\nSize of batch: torch.Size([32, 100, 300])\n64\nTotal allocated memory: 3334690816 bytes\nCurrent Size of Reviews: 64 tensors\nCurrent Size of Ratings: 64 tensors\nSize of batch: torch.Size([32, 100, 300])\n65\nTotal allocated memory: 3334383616 bytes\nCurrent Size of Reviews: 65 tensors\nCurrent Size of Ratings: 65 tensors\nSize of batch: torch.Size([32, 100, 300])\n66\nTotal allocated memory: 3334690816 bytes\nCurrent Size of Reviews: 66 tensors\nCurrent Size of Ratings: 66 tensors\nSize of batch: torch.Size([32, 100, 300])\n67\nTotal allocated memory: 3334998016 bytes\nCurrent Size of Reviews: 67 tensors\nCurrent Size of Ratings: 67 tensors\nSize of batch: torch.Size([32, 100, 300])\n68\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 68 tensors\nCurrent Size of Ratings: 68 tensors\nSize of batch: torch.Size([32, 100, 300])\n69\nTotal allocated memory: 3334998016 bytes\nCurrent Size of Reviews: 69 tensors\nCurrent Size of Ratings: 69 tensors\nSize of batch: torch.Size([32, 100, 300])\n70\nTotal allocated memory: 3334690816 bytes\nCurrent Size of Reviews: 70 tensors\nCurrent Size of Ratings: 70 tensors\nSize of batch: torch.Size([32, 100, 300])\n71\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 71 tensors\nCurrent Size of Ratings: 71 tensors\nSize of batch: torch.Size([32, 100, 300])\n72\nTotal allocated memory: 3334025216 bytes\nCurrent Size of Reviews: 72 tensors\nCurrent Size of Ratings: 72 tensors\nSize of batch: torch.Size([32, 100, 300])\n73\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 73 tensors\nCurrent Size of Ratings: 73 tensors\nSize of batch: torch.Size([32, 100, 300])\n74\nTotal allocated memory: 3334998016 bytes\nCurrent Size of Reviews: 74 tensors\nCurrent Size of Ratings: 74 tensors\nSize of batch: torch.Size([32, 100, 300])\n75\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 75 tensors\nCurrent Size of Ratings: 75 tensors\nSize of batch: torch.Size([32, 100, 300])\n76\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 76 tensors\nCurrent Size of Ratings: 76 tensors\nSize of batch: torch.Size([32, 100, 300])\n77\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 77 tensors\nCurrent Size of Ratings: 77 tensors\nSize of batch: torch.Size([32, 100, 300])\n78\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 78 tensors\nCurrent Size of Ratings: 78 tensors\nSize of batch: torch.Size([32, 100, 300])\n79\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 79 tensors\nCurrent Size of Ratings: 79 tensors\nSize of batch: torch.Size([32, 100, 300])\n80\nTotal allocated memory: 3334025216 bytes\nCurrent Size of Reviews: 80 tensors\nCurrent Size of Ratings: 80 tensors\nSize of batch: torch.Size([32, 100, 300])\n81\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 81 tensors\nCurrent Size of Ratings: 81 tensors\nSize of batch: torch.Size([32, 100, 300])\n82\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 82 tensors\nCurrent Size of Ratings: 82 tensors\nSize of batch: torch.Size([32, 100, 300])\n83\nTotal allocated memory: 3334383616 bytes\nCurrent Size of Reviews: 83 tensors\nCurrent Size of Ratings: 83 tensors\nSize of batch: torch.Size([32, 100, 300])\n84\nTotal allocated memory: 3334025216 bytes\nCurrent Size of Reviews: 84 tensors\nCurrent Size of Ratings: 84 tensors\nSize of batch: torch.Size([32, 100, 300])\n85\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 85 tensors\nCurrent Size of Ratings: 85 tensors\nSize of batch: torch.Size([32, 100, 300])\n86\nTotal allocated memory: 3334076416 bytes\nCurrent Size of Reviews: 86 tensors\nCurrent Size of Ratings: 86 tensors\nSize of batch: torch.Size([32, 100, 300])\n87\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 87 tensors\nCurrent Size of Ratings: 87 tensors\nSize of batch: torch.Size([32, 100, 300])\n88\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 88 tensors\nCurrent Size of Ratings: 88 tensors\nSize of batch: torch.Size([32, 100, 300])\n89\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 89 tensors\nCurrent Size of Ratings: 89 tensors\nSize of batch: torch.Size([32, 100, 300])\n90\nTotal allocated memory: 3334383616 bytes\nCurrent Size of Reviews: 90 tensors\nCurrent Size of Ratings: 90 tensors\nSize of batch: torch.Size([32, 100, 300])\n91\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 91 tensors\nCurrent Size of Ratings: 91 tensors\nSize of batch: torch.Size([32, 100, 300])\n92\nTotal allocated memory: 3334434816 bytes\nCurrent Size of Reviews: 92 tensors\nCurrent Size of Ratings: 92 tensors\nSize of batch: torch.Size([32, 100, 300])\n93\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 93 tensors\nCurrent Size of Ratings: 93 tensors\nSize of batch: torch.Size([32, 100, 300])\n94\nTotal allocated memory: 3334434816 bytes\nCurrent Size of Reviews: 94 tensors\nCurrent Size of Ratings: 94 tensors\nSize of batch: torch.Size([32, 100, 300])\n95\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 95 tensors\nCurrent Size of Ratings: 95 tensors\nSize of batch: torch.Size([32, 100, 300])\n96\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 96 tensors\nCurrent Size of Ratings: 96 tensors\nSize of batch: torch.Size([32, 100, 300])\n97\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 97 tensors\nCurrent Size of Ratings: 97 tensors\nSize of batch: torch.Size([32, 100, 300])\n98\nTotal allocated memory: 3334434816 bytes\nCurrent Size of Reviews: 98 tensors\nCurrent Size of Ratings: 98 tensors\nSize of batch: torch.Size([32, 100, 300])\n99\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 99 tensors\nCurrent Size of Ratings: 99 tensors\nSize of batch: torch.Size([32, 100, 300])\n100\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 100 tensors\nCurrent Size of Ratings: 100 tensors\nSize of batch: torch.Size([32, 100, 300])\n101\nTotal allocated memory: 3334383616 bytes\nCurrent Size of Reviews: 101 tensors\nCurrent Size of Ratings: 101 tensors\nSize of batch: torch.Size([32, 100, 300])\n102\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 102 tensors\nCurrent Size of Ratings: 102 tensors\nSize of batch: torch.Size([32, 100, 300])\n103\nTotal allocated memory: 3334076416 bytes\nCurrent Size of Reviews: 103 tensors\nCurrent Size of Ratings: 103 tensors\nSize of batch: torch.Size([32, 100, 300])\n104\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 104 tensors\nCurrent Size of Ratings: 104 tensors\nSize of batch: torch.Size([32, 100, 300])\n105\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 105 tensors\nCurrent Size of Ratings: 105 tensors\nSize of batch: torch.Size([32, 100, 300])\n106\nTotal allocated memory: 3334998016 bytes\nCurrent Size of Reviews: 106 tensors\nCurrent Size of Ratings: 106 tensors\nSize of batch: torch.Size([32, 100, 300])\n107\nTotal allocated memory: 3334690816 bytes\nCurrent Size of Reviews: 107 tensors\nCurrent Size of Ratings: 107 tensors\nSize of batch: torch.Size([32, 100, 300])\n108\nTotal allocated memory: 3335305216 bytes\nCurrent Size of Reviews: 108 tensors\nCurrent Size of Ratings: 108 tensors\nSize of batch: torch.Size([32, 100, 300])\n109\nTotal allocated memory: 3334076416 bytes\nCurrent Size of Reviews: 109 tensors\nCurrent Size of Ratings: 109 tensors\nSize of batch: torch.Size([32, 100, 300])\n110\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 110 tensors\nCurrent Size of Ratings: 110 tensors\nSize of batch: torch.Size([32, 100, 300])\n111\nTotal allocated memory: 3334025216 bytes\nCurrent Size of Reviews: 111 tensors\nCurrent Size of Ratings: 111 tensors\nSize of batch: torch.Size([32, 100, 300])\n112\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 112 tensors\nCurrent Size of Ratings: 112 tensors\nSize of batch: torch.Size([32, 100, 300])\n113\nTotal allocated memory: 3334025216 bytes\nCurrent Size of Reviews: 113 tensors\nCurrent Size of Ratings: 113 tensors\nSize of batch: torch.Size([32, 100, 300])\n114\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 114 tensors\nCurrent Size of Ratings: 114 tensors\nSize of batch: torch.Size([32, 100, 300])\n115\nTotal allocated memory: 3334434816 bytes\nCurrent Size of Reviews: 115 tensors\nCurrent Size of Ratings: 115 tensors\nSize of batch: torch.Size([32, 100, 300])\n116\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 116 tensors\nCurrent Size of Ratings: 116 tensors\nSize of batch: torch.Size([32, 100, 300])\n117\nTotal allocated memory: 3334742016 bytes\nCurrent Size of Reviews: 117 tensors\nCurrent Size of Ratings: 117 tensors\nSize of batch: torch.Size([32, 100, 300])\n118\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 118 tensors\nCurrent Size of Ratings: 118 tensors\nSize of batch: torch.Size([32, 100, 300])\n119\nTotal allocated memory: 3334690816 bytes\nCurrent Size of Reviews: 119 tensors\nCurrent Size of Ratings: 119 tensors\nSize of batch: torch.Size([32, 100, 300])\n120\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 120 tensors\nCurrent Size of Ratings: 120 tensors\nSize of batch: torch.Size([32, 100, 300])\n121\nTotal allocated memory: 3334383616 bytes\nCurrent Size of Reviews: 121 tensors\nCurrent Size of Ratings: 121 tensors\nSize of batch: torch.Size([32, 100, 300])\n122\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 122 tensors\nCurrent Size of Ratings: 122 tensors\nSize of batch: torch.Size([32, 100, 300])\n123\nTotal allocated memory: 3334383616 bytes\nCurrent Size of Reviews: 123 tensors\nCurrent Size of Ratings: 123 tensors\nSize of batch: torch.Size([32, 100, 300])\n124\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 124 tensors\nCurrent Size of Ratings: 124 tensors\nSize of batch: torch.Size([32, 100, 300])\n125\nTotal allocated memory: 3334434816 bytes\nCurrent Size of Reviews: 125 tensors\nCurrent Size of Ratings: 125 tensors\nSize of batch: torch.Size([32, 100, 300])\n126\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 126 tensors\nCurrent Size of Ratings: 126 tensors\nSize of batch: torch.Size([32, 100, 300])\n127\nTotal allocated memory: 3334434816 bytes\nCurrent Size of Reviews: 127 tensors\nCurrent Size of Ratings: 127 tensors\nSize of batch: torch.Size([32, 100, 300])\n128\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 128 tensors\nCurrent Size of Ratings: 128 tensors\nSize of batch: torch.Size([32, 100, 300])\n129\nTotal allocated memory: 3334025216 bytes\nCurrent Size of Reviews: 129 tensors\nCurrent Size of Ratings: 129 tensors\nSize of batch: torch.Size([32, 100, 300])\n130\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 130 tensors\nCurrent Size of Ratings: 130 tensors\nSize of batch: torch.Size([32, 100, 300])\n131\nTotal allocated memory: 3333820416 bytes\nCurrent Size of Reviews: 131 tensors\nCurrent Size of Ratings: 131 tensors\nSize of batch: torch.Size([32, 100, 300])\n132\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 132 tensors\nCurrent Size of Ratings: 132 tensors\nSize of batch: torch.Size([32, 100, 300])\n133\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 133 tensors\nCurrent Size of Ratings: 133 tensors\nSize of batch: torch.Size([32, 100, 300])\n134\nTotal allocated memory: 3333513216 bytes\nCurrent Size of Reviews: 134 tensors\nCurrent Size of Ratings: 134 tensors\nSize of batch: torch.Size([32, 100, 300])\n135\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 135 tensors\nCurrent Size of Ratings: 135 tensors\nSize of batch: torch.Size([32, 100, 300])\n136\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 136 tensors\nCurrent Size of Ratings: 136 tensors\nSize of batch: torch.Size([32, 100, 300])\n137\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 137 tensors\nCurrent Size of Ratings: 137 tensors\nSize of batch: torch.Size([32, 100, 300])\n138\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 138 tensors\nCurrent Size of Ratings: 138 tensors\nSize of batch: torch.Size([32, 100, 300])\n139\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 139 tensors\nCurrent Size of Ratings: 139 tensors\nSize of batch: torch.Size([32, 100, 300])\n140\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 140 tensors\nCurrent Size of Ratings: 140 tensors\nSize of batch: torch.Size([32, 100, 300])\n141\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 141 tensors\nCurrent Size of Ratings: 141 tensors\nSize of batch: torch.Size([32, 100, 300])\n142\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 142 tensors\nCurrent Size of Ratings: 142 tensors\nSize of batch: torch.Size([32, 100, 300])\n143\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 143 tensors\nCurrent Size of Ratings: 143 tensors\nSize of batch: torch.Size([32, 100, 300])\n144\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 144 tensors\nCurrent Size of Ratings: 144 tensors\nSize of batch: torch.Size([32, 100, 300])\n145\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 145 tensors\nCurrent Size of Ratings: 145 tensors\nSize of batch: torch.Size([32, 100, 300])\n146\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 146 tensors\nCurrent Size of Ratings: 146 tensors\nSize of batch: torch.Size([32, 100, 300])\n147\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 147 tensors\nCurrent Size of Ratings: 147 tensors\nSize of batch: torch.Size([32, 100, 300])\n148\nTotal allocated memory: 3333820416 bytes\nCurrent Size of Reviews: 148 tensors\nCurrent Size of Ratings: 148 tensors\nSize of batch: torch.Size([32, 100, 300])\n149\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 149 tensors\nCurrent Size of Ratings: 149 tensors\nSize of batch: torch.Size([32, 100, 300])\n150\nTotal allocated memory: 3333820416 bytes\nCurrent Size of Reviews: 150 tensors\nCurrent Size of Ratings: 150 tensors\nSize of batch: torch.Size([32, 100, 300])\n151\nTotal allocated memory: 3334025216 bytes\nCurrent Size of Reviews: 151 tensors\nCurrent Size of Ratings: 151 tensors\nSize of batch: torch.Size([32, 100, 300])\n152\nTotal allocated memory: 3334127616 bytes\nCurrent Size of Reviews: 152 tensors\nCurrent Size of Ratings: 152 tensors\nSize of batch: torch.Size([32, 100, 300])\n153\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 153 tensors\nCurrent Size of Ratings: 153 tensors\nSize of batch: torch.Size([32, 100, 300])\n154\nTotal allocated memory: 3334025216 bytes\nCurrent Size of Reviews: 154 tensors\nCurrent Size of Ratings: 154 tensors\nSize of batch: torch.Size([32, 100, 300])\n155\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 155 tensors\nCurrent Size of Ratings: 155 tensors\nSize of batch: torch.Size([32, 100, 300])\n156\nTotal allocated memory: 3334025216 bytes\nCurrent Size of Reviews: 156 tensors\nCurrent Size of Ratings: 156 tensors\nSize of batch: torch.Size([32, 100, 300])\n157\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 157 tensors\nCurrent Size of Ratings: 157 tensors\nSize of batch: torch.Size([32, 100, 300])\n158\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 158 tensors\nCurrent Size of Ratings: 158 tensors\nSize of batch: torch.Size([32, 100, 300])\n159\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 159 tensors\nCurrent Size of Ratings: 159 tensors\nSize of batch: torch.Size([32, 100, 300])\n160\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 160 tensors\nCurrent Size of Ratings: 160 tensors\nSize of batch: torch.Size([32, 100, 300])\n161\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 161 tensors\nCurrent Size of Ratings: 161 tensors\nSize of batch: torch.Size([32, 100, 300])\n162\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 162 tensors\nCurrent Size of Ratings: 162 tensors\nSize of batch: torch.Size([32, 100, 300])\n163\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 163 tensors\nCurrent Size of Ratings: 163 tensors\nSize of batch: torch.Size([32, 100, 300])\n164\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 164 tensors\nCurrent Size of Ratings: 164 tensors\nSize of batch: torch.Size([32, 100, 300])\n165\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 165 tensors\nCurrent Size of Ratings: 165 tensors\nSize of batch: torch.Size([32, 100, 300])\n166\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 166 tensors\nCurrent Size of Ratings: 166 tensors\nSize of batch: torch.Size([32, 100, 300])\n167\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 167 tensors\nCurrent Size of Ratings: 167 tensors\nSize of batch: torch.Size([32, 100, 300])\n168\nTotal allocated memory: 3333410816 bytes\nCurrent Size of Reviews: 168 tensors\nCurrent Size of Ratings: 168 tensors\nSize of batch: torch.Size([32, 100, 300])\n169\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 169 tensors\nCurrent Size of Ratings: 169 tensors\nSize of batch: torch.Size([32, 100, 300])\n170\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 170 tensors\nCurrent Size of Ratings: 170 tensors\nSize of batch: torch.Size([32, 100, 300])\n171\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 171 tensors\nCurrent Size of Ratings: 171 tensors\nSize of batch: torch.Size([32, 100, 300])\n172\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 172 tensors\nCurrent Size of Ratings: 172 tensors\nSize of batch: torch.Size([32, 100, 300])\n173\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 173 tensors\nCurrent Size of Ratings: 173 tensors\nSize of batch: torch.Size([32, 100, 300])\n174\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 174 tensors\nCurrent Size of Ratings: 174 tensors\nSize of batch: torch.Size([32, 100, 300])\n175\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 175 tensors\nCurrent Size of Ratings: 175 tensors\nSize of batch: torch.Size([32, 100, 300])\n176\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 176 tensors\nCurrent Size of Ratings: 176 tensors\nSize of batch: torch.Size([32, 100, 300])\n177\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 177 tensors\nCurrent Size of Ratings: 177 tensors\nSize of batch: torch.Size([32, 100, 300])\n178\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 178 tensors\nCurrent Size of Ratings: 178 tensors\nSize of batch: torch.Size([32, 100, 300])\n179\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 179 tensors\nCurrent Size of Ratings: 179 tensors\nSize of batch: torch.Size([32, 100, 300])\n180\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 180 tensors\nCurrent Size of Ratings: 180 tensors\nSize of batch: torch.Size([32, 100, 300])\n181\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 181 tensors\nCurrent Size of Ratings: 181 tensors\nSize of batch: torch.Size([32, 100, 300])\n182\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 182 tensors\nCurrent Size of Ratings: 182 tensors\nSize of batch: torch.Size([32, 100, 300])\n183\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 183 tensors\nCurrent Size of Ratings: 183 tensors\nSize of batch: torch.Size([32, 100, 300])\n184\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 184 tensors\nCurrent Size of Ratings: 184 tensors\nSize of batch: torch.Size([32, 100, 300])\n185\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 185 tensors\nCurrent Size of Ratings: 185 tensors\nSize of batch: torch.Size([32, 100, 300])\n186\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 186 tensors\nCurrent Size of Ratings: 186 tensors\nSize of batch: torch.Size([32, 100, 300])\n187\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 187 tensors\nCurrent Size of Ratings: 187 tensors\nSize of batch: torch.Size([32, 100, 300])\n188\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 188 tensors\nCurrent Size of Ratings: 188 tensors\nSize of batch: torch.Size([32, 100, 300])\n189\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 189 tensors\nCurrent Size of Ratings: 189 tensors\nSize of batch: torch.Size([32, 100, 300])\n190\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 190 tensors\nCurrent Size of Ratings: 190 tensors\nSize of batch: torch.Size([32, 100, 300])\n191\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 191 tensors\nCurrent Size of Ratings: 191 tensors\nSize of batch: torch.Size([32, 100, 300])\n192\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 192 tensors\nCurrent Size of Ratings: 192 tensors\nSize of batch: torch.Size([32, 100, 300])\n193\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 193 tensors\nCurrent Size of Ratings: 193 tensors\nSize of batch: torch.Size([32, 100, 300])\n194\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 194 tensors\nCurrent Size of Ratings: 194 tensors\nSize of batch: torch.Size([32, 100, 300])\n195\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 195 tensors\nCurrent Size of Ratings: 195 tensors\nSize of batch: torch.Size([32, 100, 300])\n196\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 196 tensors\nCurrent Size of Ratings: 196 tensors\nSize of batch: torch.Size([32, 100, 300])\n197\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 197 tensors\nCurrent Size of Ratings: 197 tensors\nSize of batch: torch.Size([32, 100, 300])\n198\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 198 tensors\nCurrent Size of Ratings: 198 tensors\nSize of batch: torch.Size([32, 100, 300])\n199\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 199 tensors\nCurrent Size of Ratings: 199 tensors\nSize of batch: torch.Size([32, 100, 300])\n200\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 200 tensors\nCurrent Size of Ratings: 200 tensors\nSize of batch: torch.Size([32, 100, 300])\n201\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 201 tensors\nCurrent Size of Ratings: 201 tensors\nSize of batch: torch.Size([32, 100, 300])\n202\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 202 tensors\nCurrent Size of Ratings: 202 tensors\nSize of batch: torch.Size([32, 100, 300])\n203\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 203 tensors\nCurrent Size of Ratings: 203 tensors\nSize of batch: torch.Size([32, 100, 300])\n204\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 204 tensors\nCurrent Size of Ratings: 204 tensors\nSize of batch: torch.Size([32, 100, 300])\n205\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 205 tensors\nCurrent Size of Ratings: 205 tensors\nSize of batch: torch.Size([32, 100, 300])\n206\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 206 tensors\nCurrent Size of Ratings: 206 tensors\nSize of batch: torch.Size([32, 100, 300])\n207\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 207 tensors\nCurrent Size of Ratings: 207 tensors\nSize of batch: torch.Size([32, 100, 300])\n208\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 208 tensors\nCurrent Size of Ratings: 208 tensors\nSize of batch: torch.Size([32, 100, 300])\n209\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 209 tensors\nCurrent Size of Ratings: 209 tensors\nSize of batch: torch.Size([32, 100, 300])\n210\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 210 tensors\nCurrent Size of Ratings: 210 tensors\nSize of batch: torch.Size([32, 100, 300])\n211\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 211 tensors\nCurrent Size of Ratings: 211 tensors\nSize of batch: torch.Size([32, 100, 300])\n212\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 212 tensors\nCurrent Size of Ratings: 212 tensors\nSize of batch: torch.Size([32, 100, 300])\n213\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 213 tensors\nCurrent Size of Ratings: 213 tensors\nSize of batch: torch.Size([32, 100, 300])\n214\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 214 tensors\nCurrent Size of Ratings: 214 tensors\nSize of batch: torch.Size([32, 100, 300])\n215\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 215 tensors\nCurrent Size of Ratings: 215 tensors\nSize of batch: torch.Size([32, 100, 300])\n216\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 216 tensors\nCurrent Size of Ratings: 216 tensors\nSize of batch: torch.Size([32, 100, 300])\n217\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 217 tensors\nCurrent Size of Ratings: 217 tensors\nSize of batch: torch.Size([32, 100, 300])\n218\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 218 tensors\nCurrent Size of Ratings: 218 tensors\nSize of batch: torch.Size([32, 100, 300])\n219\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 219 tensors\nCurrent Size of Ratings: 219 tensors\nSize of batch: torch.Size([32, 100, 300])\n220\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 220 tensors\nCurrent Size of Ratings: 220 tensors\nSize of batch: torch.Size([32, 100, 300])\n221\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 221 tensors\nCurrent Size of Ratings: 221 tensors\nSize of batch: torch.Size([32, 100, 300])\n222\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 222 tensors\nCurrent Size of Ratings: 222 tensors\nSize of batch: torch.Size([32, 100, 300])\n223\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 223 tensors\nCurrent Size of Ratings: 223 tensors\nSize of batch: torch.Size([32, 100, 300])\n224\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 224 tensors\nCurrent Size of Ratings: 224 tensors\nSize of batch: torch.Size([32, 100, 300])\n225\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 225 tensors\nCurrent Size of Ratings: 225 tensors\nSize of batch: torch.Size([32, 100, 300])\n226\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 226 tensors\nCurrent Size of Ratings: 226 tensors\nSize of batch: torch.Size([32, 100, 300])\n227\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 227 tensors\nCurrent Size of Ratings: 227 tensors\nSize of batch: torch.Size([32, 100, 300])\n228\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 228 tensors\nCurrent Size of Ratings: 228 tensors\nSize of batch: torch.Size([32, 100, 300])\n229\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 229 tensors\nCurrent Size of Ratings: 229 tensors\nSize of batch: torch.Size([32, 100, 300])\n230\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 230 tensors\nCurrent Size of Ratings: 230 tensors\nSize of batch: torch.Size([32, 100, 300])\n231\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 231 tensors\nCurrent Size of Ratings: 231 tensors\nSize of batch: torch.Size([32, 100, 300])\n232\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 232 tensors\nCurrent Size of Ratings: 232 tensors\nSize of batch: torch.Size([32, 100, 300])\n233\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 233 tensors\nCurrent Size of Ratings: 233 tensors\nSize of batch: torch.Size([32, 100, 300])\n234\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 234 tensors\nCurrent Size of Ratings: 234 tensors\nSize of batch: torch.Size([32, 100, 300])\n235\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 235 tensors\nCurrent Size of Ratings: 235 tensors\nSize of batch: torch.Size([32, 100, 300])\n236\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 236 tensors\nCurrent Size of Ratings: 236 tensors\nSize of batch: torch.Size([32, 100, 300])\n237\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 237 tensors\nCurrent Size of Ratings: 237 tensors\nSize of batch: torch.Size([32, 100, 300])\n238\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 238 tensors\nCurrent Size of Ratings: 238 tensors\nSize of batch: torch.Size([32, 100, 300])\n239\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 239 tensors\nCurrent Size of Ratings: 239 tensors\nSize of batch: torch.Size([32, 100, 300])\n240\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 240 tensors\nCurrent Size of Ratings: 240 tensors\nSize of batch: torch.Size([32, 100, 300])\n241\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 241 tensors\nCurrent Size of Ratings: 241 tensors\nSize of batch: torch.Size([32, 100, 300])\n242\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 242 tensors\nCurrent Size of Ratings: 242 tensors\nSize of batch: torch.Size([32, 100, 300])\n243\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 243 tensors\nCurrent Size of Ratings: 243 tensors\nSize of batch: torch.Size([32, 100, 300])\n244\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 244 tensors\nCurrent Size of Ratings: 244 tensors\nSize of batch: torch.Size([32, 100, 300])\n245\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 245 tensors\nCurrent Size of Ratings: 245 tensors\nSize of batch: torch.Size([32, 100, 300])\n246\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 246 tensors\nCurrent Size of Ratings: 246 tensors\nSize of batch: torch.Size([32, 100, 300])\n247\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 247 tensors\nCurrent Size of Ratings: 247 tensors\nSize of batch: torch.Size([32, 100, 300])\n248\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 248 tensors\nCurrent Size of Ratings: 248 tensors\nSize of batch: torch.Size([32, 100, 300])\n249\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 249 tensors\nCurrent Size of Ratings: 249 tensors\nSize of batch: torch.Size([32, 100, 300])\n250\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 250 tensors\nCurrent Size of Ratings: 250 tensors\nSize of batch: torch.Size([32, 100, 300])\n251\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 251 tensors\nCurrent Size of Ratings: 251 tensors\nSize of batch: torch.Size([32, 100, 300])\n252\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 252 tensors\nCurrent Size of Ratings: 252 tensors\nSize of batch: torch.Size([32, 100, 300])\n253\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 253 tensors\nCurrent Size of Ratings: 253 tensors\nSize of batch: torch.Size([32, 100, 300])\n254\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 254 tensors\nCurrent Size of Ratings: 254 tensors\nSize of batch: torch.Size([32, 100, 300])\n255\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 255 tensors\nCurrent Size of Ratings: 255 tensors\nSize of batch: torch.Size([32, 100, 300])\n256\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 256 tensors\nCurrent Size of Ratings: 256 tensors\nSize of batch: torch.Size([32, 100, 300])\n257\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 257 tensors\nCurrent Size of Ratings: 257 tensors\nSize of batch: torch.Size([32, 100, 300])\n258\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 258 tensors\nCurrent Size of Ratings: 258 tensors\nSize of batch: torch.Size([32, 100, 300])\n259\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 259 tensors\nCurrent Size of Ratings: 259 tensors\nSize of batch: torch.Size([32, 100, 300])\n260\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 260 tensors\nCurrent Size of Ratings: 260 tensors\nSize of batch: torch.Size([32, 100, 300])\n261\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 261 tensors\nCurrent Size of Ratings: 261 tensors\nSize of batch: torch.Size([32, 100, 300])\n262\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 262 tensors\nCurrent Size of Ratings: 262 tensors\nSize of batch: torch.Size([32, 100, 300])\n263\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 263 tensors\nCurrent Size of Ratings: 263 tensors\nSize of batch: torch.Size([32, 100, 300])\n264\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 264 tensors\nCurrent Size of Ratings: 264 tensors\nSize of batch: torch.Size([32, 100, 300])\n265\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 265 tensors\nCurrent Size of Ratings: 265 tensors\nSize of batch: torch.Size([32, 100, 300])\n266\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 266 tensors\nCurrent Size of Ratings: 266 tensors\nSize of batch: torch.Size([32, 100, 300])\n267\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 267 tensors\nCurrent Size of Ratings: 267 tensors\nSize of batch: torch.Size([32, 100, 300])\n268\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 268 tensors\nCurrent Size of Ratings: 268 tensors\nSize of batch: torch.Size([32, 100, 300])\n269\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 269 tensors\nCurrent Size of Ratings: 269 tensors\nSize of batch: torch.Size([32, 100, 300])\n270\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 270 tensors\nCurrent Size of Ratings: 270 tensors\nSize of batch: torch.Size([32, 100, 300])\n271\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 271 tensors\nCurrent Size of Ratings: 271 tensors\nSize of batch: torch.Size([32, 100, 300])\n272\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 272 tensors\nCurrent Size of Ratings: 272 tensors\nSize of batch: torch.Size([32, 100, 300])\n273\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 273 tensors\nCurrent Size of Ratings: 273 tensors\nSize of batch: torch.Size([32, 100, 300])\n274\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 274 tensors\nCurrent Size of Ratings: 274 tensors\nSize of batch: torch.Size([32, 100, 300])\n275\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 275 tensors\nCurrent Size of Ratings: 275 tensors\nSize of batch: torch.Size([32, 100, 300])\n276\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 276 tensors\nCurrent Size of Ratings: 276 tensors\nSize of batch: torch.Size([32, 100, 300])\n277\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 277 tensors\nCurrent Size of Ratings: 277 tensors\nSize of batch: torch.Size([32, 100, 300])\n278\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 278 tensors\nCurrent Size of Ratings: 278 tensors\nSize of batch: torch.Size([32, 100, 300])\n279\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 279 tensors\nCurrent Size of Ratings: 279 tensors\nSize of batch: torch.Size([32, 100, 300])\n280\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 280 tensors\nCurrent Size of Ratings: 280 tensors\nSize of batch: torch.Size([32, 100, 300])\n281\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 281 tensors\nCurrent Size of Ratings: 281 tensors\nSize of batch: torch.Size([32, 100, 300])\n282\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 282 tensors\nCurrent Size of Ratings: 282 tensors\nSize of batch: torch.Size([32, 100, 300])\n283\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 283 tensors\nCurrent Size of Ratings: 283 tensors\nSize of batch: torch.Size([32, 100, 300])\n284\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 284 tensors\nCurrent Size of Ratings: 284 tensors\nSize of batch: torch.Size([32, 100, 300])\n285\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 285 tensors\nCurrent Size of Ratings: 285 tensors\nSize of batch: torch.Size([32, 100, 300])\n286\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 286 tensors\nCurrent Size of Ratings: 286 tensors\nSize of batch: torch.Size([32, 100, 300])\n287\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 287 tensors\nCurrent Size of Ratings: 287 tensors\nSize of batch: torch.Size([32, 100, 300])\n288\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 288 tensors\nCurrent Size of Ratings: 288 tensors\nSize of batch: torch.Size([32, 100, 300])\n289\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 289 tensors\nCurrent Size of Ratings: 289 tensors\nSize of batch: torch.Size([32, 100, 300])\n290\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 290 tensors\nCurrent Size of Ratings: 290 tensors\nSize of batch: torch.Size([32, 100, 300])\n291\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 291 tensors\nCurrent Size of Ratings: 291 tensors\nSize of batch: torch.Size([32, 100, 300])\n292\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 292 tensors\nCurrent Size of Ratings: 292 tensors\nSize of batch: torch.Size([32, 100, 300])\n293\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 293 tensors\nCurrent Size of Ratings: 293 tensors\nSize of batch: torch.Size([32, 100, 300])\n294\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 294 tensors\nCurrent Size of Ratings: 294 tensors\nSize of batch: torch.Size([32, 100, 300])\n295\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 295 tensors\nCurrent Size of Ratings: 295 tensors\nSize of batch: torch.Size([32, 100, 300])\n296\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 296 tensors\nCurrent Size of Ratings: 296 tensors\nSize of batch: torch.Size([32, 100, 300])\n297\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 297 tensors\nCurrent Size of Ratings: 297 tensors\nSize of batch: torch.Size([32, 100, 300])\n298\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 298 tensors\nCurrent Size of Ratings: 298 tensors\nSize of batch: torch.Size([32, 100, 300])\n299\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 299 tensors\nCurrent Size of Ratings: 299 tensors\nSize of batch: torch.Size([32, 100, 300])\n300\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 300 tensors\nCurrent Size of Ratings: 300 tensors\nSize of batch: torch.Size([32, 100, 300])\n301\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 301 tensors\nCurrent Size of Ratings: 301 tensors\nSize of batch: torch.Size([32, 100, 300])\n302\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 302 tensors\nCurrent Size of Ratings: 302 tensors\nSize of batch: torch.Size([32, 100, 300])\n303\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 303 tensors\nCurrent Size of Ratings: 303 tensors\nSize of batch: torch.Size([32, 100, 300])\n304\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 304 tensors\nCurrent Size of Ratings: 304 tensors\nSize of batch: torch.Size([32, 100, 300])\n305\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 305 tensors\nCurrent Size of Ratings: 305 tensors\nSize of batch: torch.Size([32, 100, 300])\n306\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 306 tensors\nCurrent Size of Ratings: 306 tensors\nSize of batch: torch.Size([32, 100, 300])\n307\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 307 tensors\nCurrent Size of Ratings: 307 tensors\nSize of batch: torch.Size([32, 100, 300])\n308\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 308 tensors\nCurrent Size of Ratings: 308 tensors\nSize of batch: torch.Size([32, 100, 300])\n309\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 309 tensors\nCurrent Size of Ratings: 309 tensors\nSize of batch: torch.Size([32, 100, 300])\n310\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 310 tensors\nCurrent Size of Ratings: 310 tensors\nSize of batch: torch.Size([32, 100, 300])\n311\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 311 tensors\nCurrent Size of Ratings: 311 tensors\nSize of batch: torch.Size([32, 100, 300])\n312\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 312 tensors\nCurrent Size of Ratings: 312 tensors\nSize of batch: torch.Size([32, 100, 300])\n313\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 313 tensors\nCurrent Size of Ratings: 313 tensors\nSize of batch: torch.Size([32, 100, 300])\n314\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 314 tensors\nCurrent Size of Ratings: 314 tensors\nSize of batch: torch.Size([32, 100, 300])\n315\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 315 tensors\nCurrent Size of Ratings: 315 tensors\nSize of batch: torch.Size([32, 100, 300])\n316\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 316 tensors\nCurrent Size of Ratings: 316 tensors\nSize of batch: torch.Size([32, 100, 300])\n317\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 317 tensors\nCurrent Size of Ratings: 317 tensors\nSize of batch: torch.Size([32, 100, 300])\n318\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 318 tensors\nCurrent Size of Ratings: 318 tensors\nSize of batch: torch.Size([32, 100, 300])\n319\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 319 tensors\nCurrent Size of Ratings: 319 tensors\nSize of batch: torch.Size([32, 100, 300])\n320\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 320 tensors\nCurrent Size of Ratings: 320 tensors\nSize of batch: torch.Size([32, 100, 300])\n321\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 321 tensors\nCurrent Size of Ratings: 321 tensors\nSize of batch: torch.Size([32, 100, 300])\n322\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 322 tensors\nCurrent Size of Ratings: 322 tensors\nSize of batch: torch.Size([32, 100, 300])\n323\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 323 tensors\nCurrent Size of Ratings: 323 tensors\nSize of batch: torch.Size([32, 100, 300])\n324\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 324 tensors\nCurrent Size of Ratings: 324 tensors\nSize of batch: torch.Size([32, 100, 300])\n325\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 325 tensors\nCurrent Size of Ratings: 325 tensors\nSize of batch: torch.Size([32, 100, 300])\n326\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 326 tensors\nCurrent Size of Ratings: 326 tensors\nSize of batch: torch.Size([32, 100, 300])\n327\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 327 tensors\nCurrent Size of Ratings: 327 tensors\nSize of batch: torch.Size([32, 100, 300])\n328\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 328 tensors\nCurrent Size of Ratings: 328 tensors\nSize of batch: torch.Size([32, 100, 300])\n329\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 329 tensors\nCurrent Size of Ratings: 329 tensors\nSize of batch: torch.Size([32, 100, 300])\n330\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 330 tensors\nCurrent Size of Ratings: 330 tensors\nSize of batch: torch.Size([32, 100, 300])\n331\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 331 tensors\nCurrent Size of Ratings: 331 tensors\nSize of batch: torch.Size([32, 100, 300])\n332\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 332 tensors\nCurrent Size of Ratings: 332 tensors\nSize of batch: torch.Size([32, 100, 300])\n333\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 333 tensors\nCurrent Size of Ratings: 333 tensors\nSize of batch: torch.Size([32, 100, 300])\n334\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 334 tensors\nCurrent Size of Ratings: 334 tensors\nSize of batch: torch.Size([32, 100, 300])\n335\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 335 tensors\nCurrent Size of Ratings: 335 tensors\nSize of batch: torch.Size([32, 100, 300])\n336\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 336 tensors\nCurrent Size of Ratings: 336 tensors\nSize of batch: torch.Size([32, 100, 300])\n337\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 337 tensors\nCurrent Size of Ratings: 337 tensors\nSize of batch: torch.Size([32, 100, 300])\n338\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 338 tensors\nCurrent Size of Ratings: 338 tensors\nSize of batch: torch.Size([32, 100, 300])\n339\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 339 tensors\nCurrent Size of Ratings: 339 tensors\nSize of batch: torch.Size([32, 100, 300])\n340\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 340 tensors\nCurrent Size of Ratings: 340 tensors\nSize of batch: torch.Size([32, 100, 300])\n341\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 341 tensors\nCurrent Size of Ratings: 341 tensors\nSize of batch: torch.Size([32, 100, 300])\n342\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 342 tensors\nCurrent Size of Ratings: 342 tensors\nSize of batch: torch.Size([32, 100, 300])\n343\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 343 tensors\nCurrent Size of Ratings: 343 tensors\nSize of batch: torch.Size([32, 100, 300])\n344\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 344 tensors\nCurrent Size of Ratings: 344 tensors\nSize of batch: torch.Size([32, 100, 300])\n345\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 345 tensors\nCurrent Size of Ratings: 345 tensors\nSize of batch: torch.Size([32, 100, 300])\n346\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 346 tensors\nCurrent Size of Ratings: 346 tensors\nSize of batch: torch.Size([32, 100, 300])\n347\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 347 tensors\nCurrent Size of Ratings: 347 tensors\nSize of batch: torch.Size([32, 100, 300])\n348\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 348 tensors\nCurrent Size of Ratings: 348 tensors\nSize of batch: torch.Size([32, 100, 300])\n349\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 349 tensors\nCurrent Size of Ratings: 349 tensors\nSize of batch: torch.Size([32, 100, 300])\n350\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 350 tensors\nCurrent Size of Ratings: 350 tensors\nSize of batch: torch.Size([32, 100, 300])\n351\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 351 tensors\nCurrent Size of Ratings: 351 tensors\nSize of batch: torch.Size([32, 100, 300])\n352\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 352 tensors\nCurrent Size of Ratings: 352 tensors\nSize of batch: torch.Size([32, 100, 300])\n353\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 353 tensors\nCurrent Size of Ratings: 353 tensors\nSize of batch: torch.Size([32, 100, 300])\n354\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 354 tensors\nCurrent Size of Ratings: 354 tensors\nSize of batch: torch.Size([32, 100, 300])\n355\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 355 tensors\nCurrent Size of Ratings: 355 tensors\nSize of batch: torch.Size([32, 100, 300])\n356\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 356 tensors\nCurrent Size of Ratings: 356 tensors\nSize of batch: torch.Size([32, 100, 300])\n357\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 357 tensors\nCurrent Size of Ratings: 357 tensors\nSize of batch: torch.Size([32, 100, 300])\n358\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 358 tensors\nCurrent Size of Ratings: 358 tensors\nSize of batch: torch.Size([32, 100, 300])\n359\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 359 tensors\nCurrent Size of Ratings: 359 tensors\nSize of batch: torch.Size([32, 100, 300])\n360\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 360 tensors\nCurrent Size of Ratings: 360 tensors\nSize of batch: torch.Size([32, 100, 300])\n361\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 361 tensors\nCurrent Size of Ratings: 361 tensors\nSize of batch: torch.Size([32, 100, 300])\n362\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 362 tensors\nCurrent Size of Ratings: 362 tensors\nSize of batch: torch.Size([32, 100, 300])\n363\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 363 tensors\nCurrent Size of Ratings: 363 tensors\nSize of batch: torch.Size([32, 100, 300])\n364\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 364 tensors\nCurrent Size of Ratings: 364 tensors\nSize of batch: torch.Size([32, 100, 300])\n365\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 365 tensors\nCurrent Size of Ratings: 365 tensors\nSize of batch: torch.Size([32, 100, 300])\n366\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 366 tensors\nCurrent Size of Ratings: 366 tensors\nSize of batch: torch.Size([32, 100, 300])\n367\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 367 tensors\nCurrent Size of Ratings: 367 tensors\nSize of batch: torch.Size([32, 100, 300])\n368\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 368 tensors\nCurrent Size of Ratings: 368 tensors\nSize of batch: torch.Size([32, 100, 300])\n369\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 369 tensors\nCurrent Size of Ratings: 369 tensors\nSize of batch: torch.Size([32, 100, 300])\n370\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 370 tensors\nCurrent Size of Ratings: 370 tensors\nSize of batch: torch.Size([32, 100, 300])\n371\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 371 tensors\nCurrent Size of Ratings: 371 tensors\nSize of batch: torch.Size([32, 100, 300])\n372\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 372 tensors\nCurrent Size of Ratings: 372 tensors\nSize of batch: torch.Size([32, 100, 300])\n373\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 373 tensors\nCurrent Size of Ratings: 373 tensors\nSize of batch: torch.Size([32, 100, 300])\n374\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 374 tensors\nCurrent Size of Ratings: 374 tensors\nSize of batch: torch.Size([32, 100, 300])\n375\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 375 tensors\nCurrent Size of Ratings: 375 tensors\nSize of batch: torch.Size([32, 100, 300])\n376\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 376 tensors\nCurrent Size of Ratings: 376 tensors\nSize of batch: torch.Size([32, 100, 300])\n377\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 377 tensors\nCurrent Size of Ratings: 377 tensors\nSize of batch: torch.Size([32, 100, 300])\n378\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 378 tensors\nCurrent Size of Ratings: 378 tensors\nSize of batch: torch.Size([32, 100, 300])\n379\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 379 tensors\nCurrent Size of Ratings: 379 tensors\nSize of batch: torch.Size([32, 100, 300])\n380\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 380 tensors\nCurrent Size of Ratings: 380 tensors\nSize of batch: torch.Size([32, 100, 300])\n381\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 381 tensors\nCurrent Size of Ratings: 381 tensors\nSize of batch: torch.Size([32, 100, 300])\n382\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 382 tensors\nCurrent Size of Ratings: 382 tensors\nSize of batch: torch.Size([32, 100, 300])\n383\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 383 tensors\nCurrent Size of Ratings: 383 tensors\nSize of batch: torch.Size([32, 100, 300])\n384\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 384 tensors\nCurrent Size of Ratings: 384 tensors\nSize of batch: torch.Size([32, 100, 300])\n385\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 385 tensors\nCurrent Size of Ratings: 385 tensors\nSize of batch: torch.Size([32, 100, 300])\n386\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 386 tensors\nCurrent Size of Ratings: 386 tensors\nSize of batch: torch.Size([32, 100, 300])\n387\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 387 tensors\nCurrent Size of Ratings: 387 tensors\nSize of batch: torch.Size([32, 100, 300])\n388\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 388 tensors\nCurrent Size of Ratings: 388 tensors\nSize of batch: torch.Size([32, 100, 300])\n389\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 389 tensors\nCurrent Size of Ratings: 389 tensors\nSize of batch: torch.Size([32, 100, 300])\n390\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 390 tensors\nCurrent Size of Ratings: 390 tensors\nSize of batch: torch.Size([32, 100, 300])\n391\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 391 tensors\nCurrent Size of Ratings: 391 tensors\nSize of batch: torch.Size([32, 100, 300])\n392\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 392 tensors\nCurrent Size of Ratings: 392 tensors\nSize of batch: torch.Size([32, 100, 300])\n393\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 393 tensors\nCurrent Size of Ratings: 393 tensors\nSize of batch: torch.Size([32, 100, 300])\n394\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 394 tensors\nCurrent Size of Ratings: 394 tensors\nSize of batch: torch.Size([32, 100, 300])\n395\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 395 tensors\nCurrent Size of Ratings: 395 tensors\nSize of batch: torch.Size([32, 100, 300])\n396\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 396 tensors\nCurrent Size of Ratings: 396 tensors\nSize of batch: torch.Size([32, 100, 300])\n397\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 397 tensors\nCurrent Size of Ratings: 397 tensors\nSize of batch: torch.Size([32, 100, 300])\n398\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 398 tensors\nCurrent Size of Ratings: 398 tensors\nSize of batch: torch.Size([32, 100, 300])\n399\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 399 tensors\nCurrent Size of Ratings: 399 tensors\nSize of batch: torch.Size([32, 100, 300])\n400\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 400 tensors\nCurrent Size of Ratings: 400 tensors\nSize of batch: torch.Size([32, 100, 300])\n401\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 401 tensors\nCurrent Size of Ratings: 401 tensors\nSize of batch: torch.Size([32, 100, 300])\n402\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 402 tensors\nCurrent Size of Ratings: 402 tensors\nSize of batch: torch.Size([32, 100, 300])\n403\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 403 tensors\nCurrent Size of Ratings: 403 tensors\nSize of batch: torch.Size([32, 100, 300])\n404\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 404 tensors\nCurrent Size of Ratings: 404 tensors\nSize of batch: torch.Size([32, 100, 300])\n405\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 405 tensors\nCurrent Size of Ratings: 405 tensors\nSize of batch: torch.Size([32, 100, 300])\n406\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 406 tensors\nCurrent Size of Ratings: 406 tensors\nSize of batch: torch.Size([32, 100, 300])\n407\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 407 tensors\nCurrent Size of Ratings: 407 tensors\nSize of batch: torch.Size([32, 100, 300])\n408\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 408 tensors\nCurrent Size of Ratings: 408 tensors\nSize of batch: torch.Size([32, 100, 300])\n409\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 409 tensors\nCurrent Size of Ratings: 409 tensors\nSize of batch: torch.Size([32, 100, 300])\n410\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 410 tensors\nCurrent Size of Ratings: 410 tensors\nSize of batch: torch.Size([32, 100, 300])\n411\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 411 tensors\nCurrent Size of Ratings: 411 tensors\nSize of batch: torch.Size([32, 100, 300])\n412\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 412 tensors\nCurrent Size of Ratings: 412 tensors\nSize of batch: torch.Size([32, 100, 300])\n413\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 413 tensors\nCurrent Size of Ratings: 413 tensors\nSize of batch: torch.Size([32, 100, 300])\n414\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 414 tensors\nCurrent Size of Ratings: 414 tensors\nSize of batch: torch.Size([32, 100, 300])\n415\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 415 tensors\nCurrent Size of Ratings: 415 tensors\nSize of batch: torch.Size([32, 100, 300])\n416\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 416 tensors\nCurrent Size of Ratings: 416 tensors\nSize of batch: torch.Size([32, 100, 300])\n417\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 417 tensors\nCurrent Size of Ratings: 417 tensors\nSize of batch: torch.Size([32, 100, 300])\n418\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 418 tensors\nCurrent Size of Ratings: 418 tensors\nSize of batch: torch.Size([32, 100, 300])\n419\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 419 tensors\nCurrent Size of Ratings: 419 tensors\nSize of batch: torch.Size([32, 100, 300])\n420\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 420 tensors\nCurrent Size of Ratings: 420 tensors\nSize of batch: torch.Size([32, 100, 300])\n421\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 421 tensors\nCurrent Size of Ratings: 421 tensors\nSize of batch: torch.Size([32, 100, 300])\n422\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 422 tensors\nCurrent Size of Ratings: 422 tensors\nSize of batch: torch.Size([32, 100, 300])\n423\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 423 tensors\nCurrent Size of Ratings: 423 tensors\nSize of batch: torch.Size([32, 100, 300])\n424\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 424 tensors\nCurrent Size of Ratings: 424 tensors\nSize of batch: torch.Size([32, 100, 300])\n425\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 425 tensors\nCurrent Size of Ratings: 425 tensors\nSize of batch: torch.Size([32, 100, 300])\n426\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 426 tensors\nCurrent Size of Ratings: 426 tensors\nSize of batch: torch.Size([32, 100, 300])\n427\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 427 tensors\nCurrent Size of Ratings: 427 tensors\nSize of batch: torch.Size([32, 100, 300])\n428\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 428 tensors\nCurrent Size of Ratings: 428 tensors\nSize of batch: torch.Size([32, 100, 300])\n429\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 429 tensors\nCurrent Size of Ratings: 429 tensors\nSize of batch: torch.Size([32, 100, 300])\n430\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 430 tensors\nCurrent Size of Ratings: 430 tensors\nSize of batch: torch.Size([32, 100, 300])\n431\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 431 tensors\nCurrent Size of Ratings: 431 tensors\nSize of batch: torch.Size([32, 100, 300])\n432\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 432 tensors\nCurrent Size of Ratings: 432 tensors\nSize of batch: torch.Size([32, 100, 300])\n433\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 433 tensors\nCurrent Size of Ratings: 433 tensors\nSize of batch: torch.Size([32, 100, 300])\n434\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 434 tensors\nCurrent Size of Ratings: 434 tensors\nSize of batch: torch.Size([32, 100, 300])\n435\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 435 tensors\nCurrent Size of Ratings: 435 tensors\nSize of batch: torch.Size([32, 100, 300])\n436\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 436 tensors\nCurrent Size of Ratings: 436 tensors\nSize of batch: torch.Size([32, 100, 300])\n437\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 437 tensors\nCurrent Size of Ratings: 437 tensors\nSize of batch: torch.Size([32, 100, 300])\n438\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 438 tensors\nCurrent Size of Ratings: 438 tensors\nSize of batch: torch.Size([32, 100, 300])\n439\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 439 tensors\nCurrent Size of Ratings: 439 tensors\nSize of batch: torch.Size([32, 100, 300])\n440\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 440 tensors\nCurrent Size of Ratings: 440 tensors\nSize of batch: torch.Size([32, 100, 300])\n441\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 441 tensors\nCurrent Size of Ratings: 441 tensors\nSize of batch: torch.Size([32, 100, 300])\n442\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 442 tensors\nCurrent Size of Ratings: 442 tensors\nSize of batch: torch.Size([32, 100, 300])\n443\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 443 tensors\nCurrent Size of Ratings: 443 tensors\nSize of batch: torch.Size([32, 100, 300])\n444\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 444 tensors\nCurrent Size of Ratings: 444 tensors\nSize of batch: torch.Size([32, 100, 300])\n445\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 445 tensors\nCurrent Size of Ratings: 445 tensors\nSize of batch: torch.Size([32, 100, 300])\n446\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 446 tensors\nCurrent Size of Ratings: 446 tensors\nSize of batch: torch.Size([32, 100, 300])\n447\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 447 tensors\nCurrent Size of Ratings: 447 tensors\nSize of batch: torch.Size([32, 100, 300])\n448\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 448 tensors\nCurrent Size of Ratings: 448 tensors\nSize of batch: torch.Size([32, 100, 300])\n449\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 449 tensors\nCurrent Size of Ratings: 449 tensors\nSize of batch: torch.Size([32, 100, 300])\n450\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 450 tensors\nCurrent Size of Ratings: 450 tensors\nSize of batch: torch.Size([32, 100, 300])\n451\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 451 tensors\nCurrent Size of Ratings: 451 tensors\nSize of batch: torch.Size([32, 100, 300])\n452\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 452 tensors\nCurrent Size of Ratings: 452 tensors\nSize of batch: torch.Size([32, 100, 300])\n453\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 453 tensors\nCurrent Size of Ratings: 453 tensors\nSize of batch: torch.Size([32, 100, 300])\n454\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 454 tensors\nCurrent Size of Ratings: 454 tensors\nSize of batch: torch.Size([32, 100, 300])\n455\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 455 tensors\nCurrent Size of Ratings: 455 tensors\nSize of batch: torch.Size([32, 100, 300])\n456\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 456 tensors\nCurrent Size of Ratings: 456 tensors\nSize of batch: torch.Size([32, 100, 300])\n457\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 457 tensors\nCurrent Size of Ratings: 457 tensors\nSize of batch: torch.Size([32, 100, 300])\n458\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 458 tensors\nCurrent Size of Ratings: 458 tensors\nSize of batch: torch.Size([32, 100, 300])\n459\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 459 tensors\nCurrent Size of Ratings: 459 tensors\nSize of batch: torch.Size([32, 100, 300])\n460\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 460 tensors\nCurrent Size of Ratings: 460 tensors\nSize of batch: torch.Size([32, 100, 300])\n461\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 461 tensors\nCurrent Size of Ratings: 461 tensors\nSize of batch: torch.Size([32, 100, 300])\n462\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 462 tensors\nCurrent Size of Ratings: 462 tensors\nSize of batch: torch.Size([32, 100, 300])\n463\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 463 tensors\nCurrent Size of Ratings: 463 tensors\nSize of batch: torch.Size([32, 100, 300])\n464\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 464 tensors\nCurrent Size of Ratings: 464 tensors\nSize of batch: torch.Size([32, 100, 300])\n465\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 465 tensors\nCurrent Size of Ratings: 465 tensors\nSize of batch: torch.Size([32, 100, 300])\n466\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 466 tensors\nCurrent Size of Ratings: 466 tensors\nSize of batch: torch.Size([32, 100, 300])\n467\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 467 tensors\nCurrent Size of Ratings: 467 tensors\nSize of batch: torch.Size([32, 100, 300])\n468\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 468 tensors\nCurrent Size of Ratings: 468 tensors\nSize of batch: torch.Size([32, 100, 300])\n469\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 469 tensors\nCurrent Size of Ratings: 469 tensors\nSize of batch: torch.Size([32, 100, 300])\n470\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 470 tensors\nCurrent Size of Ratings: 470 tensors\nSize of batch: torch.Size([32, 100, 300])\n471\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 471 tensors\nCurrent Size of Ratings: 471 tensors\nSize of batch: torch.Size([32, 100, 300])\n472\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 472 tensors\nCurrent Size of Ratings: 472 tensors\nSize of batch: torch.Size([32, 100, 300])\n473\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 473 tensors\nCurrent Size of Ratings: 473 tensors\nSize of batch: torch.Size([32, 100, 300])\n474\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 474 tensors\nCurrent Size of Ratings: 474 tensors\nSize of batch: torch.Size([32, 100, 300])\n475\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 475 tensors\nCurrent Size of Ratings: 475 tensors\nSize of batch: torch.Size([32, 100, 300])\n476\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 476 tensors\nCurrent Size of Ratings: 476 tensors\nSize of batch: torch.Size([32, 100, 300])\n477\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 477 tensors\nCurrent Size of Ratings: 477 tensors\nSize of batch: torch.Size([32, 100, 300])\n478\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 478 tensors\nCurrent Size of Ratings: 478 tensors\nSize of batch: torch.Size([32, 100, 300])\n479\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 479 tensors\nCurrent Size of Ratings: 479 tensors\nSize of batch: torch.Size([32, 100, 300])\n480\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 480 tensors\nCurrent Size of Ratings: 480 tensors\nSize of batch: torch.Size([32, 100, 300])\n481\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 481 tensors\nCurrent Size of Ratings: 481 tensors\nSize of batch: torch.Size([32, 100, 300])\n482\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 482 tensors\nCurrent Size of Ratings: 482 tensors\nSize of batch: torch.Size([32, 100, 300])\n483\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 483 tensors\nCurrent Size of Ratings: 483 tensors\nSize of batch: torch.Size([32, 100, 300])\n484\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 484 tensors\nCurrent Size of Ratings: 484 tensors\nSize of batch: torch.Size([32, 100, 300])\n485\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 485 tensors\nCurrent Size of Ratings: 485 tensors\nSize of batch: torch.Size([32, 100, 300])\n486\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 486 tensors\nCurrent Size of Ratings: 486 tensors\nSize of batch: torch.Size([32, 100, 300])\n487\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 487 tensors\nCurrent Size of Ratings: 487 tensors\nSize of batch: torch.Size([32, 100, 300])\n488\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 488 tensors\nCurrent Size of Ratings: 488 tensors\nSize of batch: torch.Size([32, 100, 300])\n489\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 489 tensors\nCurrent Size of Ratings: 489 tensors\nSize of batch: torch.Size([32, 100, 300])\n490\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 490 tensors\nCurrent Size of Ratings: 490 tensors\nSize of batch: torch.Size([32, 100, 300])\n491\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 491 tensors\nCurrent Size of Ratings: 491 tensors\nSize of batch: torch.Size([32, 100, 300])\n492\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 492 tensors\nCurrent Size of Ratings: 492 tensors\nSize of batch: torch.Size([32, 100, 300])\n493\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 493 tensors\nCurrent Size of Ratings: 493 tensors\nSize of batch: torch.Size([32, 100, 300])\n494\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 494 tensors\nCurrent Size of Ratings: 494 tensors\nSize of batch: torch.Size([32, 100, 300])\n495\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 495 tensors\nCurrent Size of Ratings: 495 tensors\nSize of batch: torch.Size([32, 100, 300])\n496\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 496 tensors\nCurrent Size of Ratings: 496 tensors\nSize of batch: torch.Size([32, 100, 300])\n497\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 497 tensors\nCurrent Size of Ratings: 497 tensors\nSize of batch: torch.Size([32, 100, 300])\n498\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 498 tensors\nCurrent Size of Ratings: 498 tensors\nSize of batch: torch.Size([32, 100, 300])\n499\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 499 tensors\nCurrent Size of Ratings: 499 tensors\nSize of batch: torch.Size([32, 100, 300])\n500\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 500 tensors\nCurrent Size of Ratings: 500 tensors\nSize of batch: torch.Size([32, 100, 300])\n501\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 501 tensors\nCurrent Size of Ratings: 501 tensors\nSize of batch: torch.Size([32, 100, 300])\n502\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 502 tensors\nCurrent Size of Ratings: 502 tensors\nSize of batch: torch.Size([32, 100, 300])\n503\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 503 tensors\nCurrent Size of Ratings: 503 tensors\nSize of batch: torch.Size([32, 100, 300])\n504\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 504 tensors\nCurrent Size of Ratings: 504 tensors\nSize of batch: torch.Size([32, 100, 300])\n505\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 505 tensors\nCurrent Size of Ratings: 505 tensors\nSize of batch: torch.Size([32, 100, 300])\n506\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 506 tensors\nCurrent Size of Ratings: 506 tensors\nSize of batch: torch.Size([32, 100, 300])\n507\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 507 tensors\nCurrent Size of Ratings: 507 tensors\nSize of batch: torch.Size([32, 100, 300])\n508\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 508 tensors\nCurrent Size of Ratings: 508 tensors\nSize of batch: torch.Size([32, 100, 300])\n509\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 509 tensors\nCurrent Size of Ratings: 509 tensors\nSize of batch: torch.Size([32, 100, 300])\n510\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 510 tensors\nCurrent Size of Ratings: 510 tensors\nSize of batch: torch.Size([32, 100, 300])\n511\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 511 tensors\nCurrent Size of Ratings: 511 tensors\nSize of batch: torch.Size([32, 100, 300])\n512\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 512 tensors\nCurrent Size of Ratings: 512 tensors\nSize of batch: torch.Size([32, 100, 300])\n513\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 513 tensors\nCurrent Size of Ratings: 513 tensors\nSize of batch: torch.Size([32, 100, 300])\n514\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 514 tensors\nCurrent Size of Ratings: 514 tensors\nSize of batch: torch.Size([32, 100, 300])\n515\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 515 tensors\nCurrent Size of Ratings: 515 tensors\nSize of batch: torch.Size([32, 100, 300])\n516\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 516 tensors\nCurrent Size of Ratings: 516 tensors\nSize of batch: torch.Size([32, 100, 300])\n517\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 517 tensors\nCurrent Size of Ratings: 517 tensors\nSize of batch: torch.Size([32, 100, 300])\n518\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 518 tensors\nCurrent Size of Ratings: 518 tensors\nSize of batch: torch.Size([32, 100, 300])\n519\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 519 tensors\nCurrent Size of Ratings: 519 tensors\nSize of batch: torch.Size([32, 100, 300])\n520\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 520 tensors\nCurrent Size of Ratings: 520 tensors\nSize of batch: torch.Size([32, 100, 300])\n521\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 521 tensors\nCurrent Size of Ratings: 521 tensors\nSize of batch: torch.Size([32, 100, 300])\n522\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 522 tensors\nCurrent Size of Ratings: 522 tensors\nSize of batch: torch.Size([32, 100, 300])\n523\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 523 tensors\nCurrent Size of Ratings: 523 tensors\nSize of batch: torch.Size([32, 100, 300])\n524\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 524 tensors\nCurrent Size of Ratings: 524 tensors\nSize of batch: torch.Size([32, 100, 300])\n525\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 525 tensors\nCurrent Size of Ratings: 525 tensors\nSize of batch: torch.Size([32, 100, 300])\n526\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 526 tensors\nCurrent Size of Ratings: 526 tensors\nSize of batch: torch.Size([32, 100, 300])\n527\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 527 tensors\nCurrent Size of Ratings: 527 tensors\nSize of batch: torch.Size([32, 100, 300])\n528\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 528 tensors\nCurrent Size of Ratings: 528 tensors\nSize of batch: torch.Size([32, 100, 300])\n529\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 529 tensors\nCurrent Size of Ratings: 529 tensors\nSize of batch: torch.Size([32, 100, 300])\n530\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 530 tensors\nCurrent Size of Ratings: 530 tensors\nSize of batch: torch.Size([32, 100, 300])\n531\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 531 tensors\nCurrent Size of Ratings: 531 tensors\nSize of batch: torch.Size([32, 100, 300])\n532\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 532 tensors\nCurrent Size of Ratings: 532 tensors\nSize of batch: torch.Size([32, 100, 300])\n533\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 533 tensors\nCurrent Size of Ratings: 533 tensors\nSize of batch: torch.Size([32, 100, 300])\n534\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 534 tensors\nCurrent Size of Ratings: 534 tensors\nSize of batch: torch.Size([32, 100, 300])\n535\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 535 tensors\nCurrent Size of Ratings: 535 tensors\nSize of batch: torch.Size([32, 100, 300])\n536\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 536 tensors\nCurrent Size of Ratings: 536 tensors\nSize of batch: torch.Size([32, 100, 300])\n537\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 537 tensors\nCurrent Size of Ratings: 537 tensors\nSize of batch: torch.Size([32, 100, 300])\n538\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 538 tensors\nCurrent Size of Ratings: 538 tensors\nSize of batch: torch.Size([32, 100, 300])\n539\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 539 tensors\nCurrent Size of Ratings: 539 tensors\nSize of batch: torch.Size([32, 100, 300])\n540\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 540 tensors\nCurrent Size of Ratings: 540 tensors\nSize of batch: torch.Size([32, 100, 300])\n541\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 541 tensors\nCurrent Size of Ratings: 541 tensors\nSize of batch: torch.Size([32, 100, 300])\n542\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 542 tensors\nCurrent Size of Ratings: 542 tensors\nSize of batch: torch.Size([32, 100, 300])\n543\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 543 tensors\nCurrent Size of Ratings: 543 tensors\nSize of batch: torch.Size([32, 100, 300])\n544\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 544 tensors\nCurrent Size of Ratings: 544 tensors\nSize of batch: torch.Size([32, 100, 300])\n545\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 545 tensors\nCurrent Size of Ratings: 545 tensors\nSize of batch: torch.Size([32, 100, 300])\n546\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 546 tensors\nCurrent Size of Ratings: 546 tensors\nSize of batch: torch.Size([32, 100, 300])\n547\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 547 tensors\nCurrent Size of Ratings: 547 tensors\nSize of batch: torch.Size([32, 100, 300])\n548\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 548 tensors\nCurrent Size of Ratings: 548 tensors\nSize of batch: torch.Size([32, 100, 300])\n549\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 549 tensors\nCurrent Size of Ratings: 549 tensors\nSize of batch: torch.Size([32, 100, 300])\n550\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 550 tensors\nCurrent Size of Ratings: 550 tensors\nSize of batch: torch.Size([32, 100, 300])\n551\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 551 tensors\nCurrent Size of Ratings: 551 tensors\nSize of batch: torch.Size([32, 100, 300])\n552\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 552 tensors\nCurrent Size of Ratings: 552 tensors\nSize of batch: torch.Size([32, 100, 300])\n553\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 553 tensors\nCurrent Size of Ratings: 553 tensors\nSize of batch: torch.Size([32, 100, 300])\n554\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 554 tensors\nCurrent Size of Ratings: 554 tensors\nSize of batch: torch.Size([32, 100, 300])\n555\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 555 tensors\nCurrent Size of Ratings: 555 tensors\nSize of batch: torch.Size([32, 100, 300])\n556\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 556 tensors\nCurrent Size of Ratings: 556 tensors\nSize of batch: torch.Size([32, 100, 300])\n557\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 557 tensors\nCurrent Size of Ratings: 557 tensors\nSize of batch: torch.Size([32, 100, 300])\n558\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 558 tensors\nCurrent Size of Ratings: 558 tensors\nSize of batch: torch.Size([32, 100, 300])\n559\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 559 tensors\nCurrent Size of Ratings: 559 tensors\nSize of batch: torch.Size([32, 100, 300])\n560\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 560 tensors\nCurrent Size of Ratings: 560 tensors\nSize of batch: torch.Size([32, 100, 300])\n561\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 561 tensors\nCurrent Size of Ratings: 561 tensors\nSize of batch: torch.Size([32, 100, 300])\n562\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 562 tensors\nCurrent Size of Ratings: 562 tensors\nSize of batch: torch.Size([32, 100, 300])\n563\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 563 tensors\nCurrent Size of Ratings: 563 tensors\nSize of batch: torch.Size([32, 100, 300])\n564\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 564 tensors\nCurrent Size of Ratings: 564 tensors\nSize of batch: torch.Size([32, 100, 300])\n565\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 565 tensors\nCurrent Size of Ratings: 565 tensors\nSize of batch: torch.Size([32, 100, 300])\n566\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 566 tensors\nCurrent Size of Ratings: 566 tensors\nSize of batch: torch.Size([32, 100, 300])\n567\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 567 tensors\nCurrent Size of Ratings: 567 tensors\nSize of batch: torch.Size([32, 100, 300])\n568\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 568 tensors\nCurrent Size of Ratings: 568 tensors\nSize of batch: torch.Size([32, 100, 300])\n569\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 569 tensors\nCurrent Size of Ratings: 569 tensors\nSize of batch: torch.Size([32, 100, 300])\n570\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 570 tensors\nCurrent Size of Ratings: 570 tensors\nSize of batch: torch.Size([32, 100, 300])\n571\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 571 tensors\nCurrent Size of Ratings: 571 tensors\nSize of batch: torch.Size([32, 100, 300])\n572\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 572 tensors\nCurrent Size of Ratings: 572 tensors\nSize of batch: torch.Size([32, 100, 300])\n573\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 573 tensors\nCurrent Size of Ratings: 573 tensors\nSize of batch: torch.Size([32, 100, 300])\n574\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 574 tensors\nCurrent Size of Ratings: 574 tensors\nSize of batch: torch.Size([32, 100, 300])\n575\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 575 tensors\nCurrent Size of Ratings: 575 tensors\nSize of batch: torch.Size([32, 100, 300])\n576\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 576 tensors\nCurrent Size of Ratings: 576 tensors\nSize of batch: torch.Size([32, 100, 300])\n577\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 577 tensors\nCurrent Size of Ratings: 577 tensors\nSize of batch: torch.Size([32, 100, 300])\n578\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 578 tensors\nCurrent Size of Ratings: 578 tensors\nSize of batch: torch.Size([32, 100, 300])\n579\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 579 tensors\nCurrent Size of Ratings: 579 tensors\nSize of batch: torch.Size([32, 100, 300])\n580\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 580 tensors\nCurrent Size of Ratings: 580 tensors\nSize of batch: torch.Size([32, 100, 300])\n581\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 581 tensors\nCurrent Size of Ratings: 581 tensors\nSize of batch: torch.Size([32, 100, 300])\n582\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 582 tensors\nCurrent Size of Ratings: 582 tensors\nSize of batch: torch.Size([32, 100, 300])\n583\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 583 tensors\nCurrent Size of Ratings: 583 tensors\nSize of batch: torch.Size([32, 100, 300])\n584\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 584 tensors\nCurrent Size of Ratings: 584 tensors\nSize of batch: torch.Size([32, 100, 300])\n585\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 585 tensors\nCurrent Size of Ratings: 585 tensors\nSize of batch: torch.Size([32, 100, 300])\n586\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 586 tensors\nCurrent Size of Ratings: 586 tensors\nSize of batch: torch.Size([32, 100, 300])\n587\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 587 tensors\nCurrent Size of Ratings: 587 tensors\nSize of batch: torch.Size([32, 100, 300])\n588\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 588 tensors\nCurrent Size of Ratings: 588 tensors\nSize of batch: torch.Size([32, 100, 300])\n589\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 589 tensors\nCurrent Size of Ratings: 589 tensors\nSize of batch: torch.Size([32, 100, 300])\n590\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 590 tensors\nCurrent Size of Ratings: 590 tensors\nSize of batch: torch.Size([32, 100, 300])\n591\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 591 tensors\nCurrent Size of Ratings: 591 tensors\nSize of batch: torch.Size([32, 100, 300])\n592\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 592 tensors\nCurrent Size of Ratings: 592 tensors\nSize of batch: torch.Size([32, 100, 300])\n593\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 593 tensors\nCurrent Size of Ratings: 593 tensors\nSize of batch: torch.Size([32, 100, 300])\n594\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 594 tensors\nCurrent Size of Ratings: 594 tensors\nSize of batch: torch.Size([32, 100, 300])\n595\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 595 tensors\nCurrent Size of Ratings: 595 tensors\nSize of batch: torch.Size([32, 100, 300])\n596\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 596 tensors\nCurrent Size of Ratings: 596 tensors\nSize of batch: torch.Size([32, 100, 300])\n597\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 597 tensors\nCurrent Size of Ratings: 597 tensors\nSize of batch: torch.Size([32, 100, 300])\n598\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 598 tensors\nCurrent Size of Ratings: 598 tensors\nSize of batch: torch.Size([32, 100, 300])\n599\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 599 tensors\nCurrent Size of Ratings: 599 tensors\nSize of batch: torch.Size([32, 100, 300])\n600\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 600 tensors\nCurrent Size of Ratings: 600 tensors\nSize of batch: torch.Size([32, 100, 300])\n601\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 601 tensors\nCurrent Size of Ratings: 601 tensors\nSize of batch: torch.Size([32, 100, 300])\n602\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 602 tensors\nCurrent Size of Ratings: 602 tensors\nSize of batch: torch.Size([32, 100, 300])\n603\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 603 tensors\nCurrent Size of Ratings: 603 tensors\nSize of batch: torch.Size([32, 100, 300])\n604\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 604 tensors\nCurrent Size of Ratings: 604 tensors\nSize of batch: torch.Size([32, 100, 300])\n605\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 605 tensors\nCurrent Size of Ratings: 605 tensors\nSize of batch: torch.Size([32, 100, 300])\n606\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 606 tensors\nCurrent Size of Ratings: 606 tensors\nSize of batch: torch.Size([32, 100, 300])\n607\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 607 tensors\nCurrent Size of Ratings: 607 tensors\nSize of batch: torch.Size([32, 100, 300])\n608\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 608 tensors\nCurrent Size of Ratings: 608 tensors\nSize of batch: torch.Size([32, 100, 300])\n609\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 609 tensors\nCurrent Size of Ratings: 609 tensors\nSize of batch: torch.Size([32, 100, 300])\n610\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 610 tensors\nCurrent Size of Ratings: 610 tensors\nSize of batch: torch.Size([32, 100, 300])\n611\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 611 tensors\nCurrent Size of Ratings: 611 tensors\nSize of batch: torch.Size([32, 100, 300])\n612\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 612 tensors\nCurrent Size of Ratings: 612 tensors\nSize of batch: torch.Size([32, 100, 300])\n613\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 613 tensors\nCurrent Size of Ratings: 613 tensors\nSize of batch: torch.Size([32, 100, 300])\n614\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 614 tensors\nCurrent Size of Ratings: 614 tensors\nSize of batch: torch.Size([32, 100, 300])\n615\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 615 tensors\nCurrent Size of Ratings: 615 tensors\nSize of batch: torch.Size([32, 100, 300])\n616\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 616 tensors\nCurrent Size of Ratings: 616 tensors\nSize of batch: torch.Size([32, 100, 300])\n617\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 617 tensors\nCurrent Size of Ratings: 617 tensors\nSize of batch: torch.Size([32, 100, 300])\n618\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 618 tensors\nCurrent Size of Ratings: 618 tensors\nSize of batch: torch.Size([32, 100, 300])\n619\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 619 tensors\nCurrent Size of Ratings: 619 tensors\nSize of batch: torch.Size([32, 100, 300])\n620\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 620 tensors\nCurrent Size of Ratings: 620 tensors\nSize of batch: torch.Size([32, 100, 300])\n621\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 621 tensors\nCurrent Size of Ratings: 621 tensors\nSize of batch: torch.Size([32, 100, 300])\n622\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 622 tensors\nCurrent Size of Ratings: 622 tensors\nSize of batch: torch.Size([32, 100, 300])\n623\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 623 tensors\nCurrent Size of Ratings: 623 tensors\nSize of batch: torch.Size([32, 100, 300])\n624\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 624 tensors\nCurrent Size of Ratings: 624 tensors\nSize of batch: torch.Size([32, 100, 300])\n625\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 625 tensors\nCurrent Size of Ratings: 625 tensors\nSize of batch: torch.Size([32, 100, 300])\n626\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 626 tensors\nCurrent Size of Ratings: 626 tensors\nSize of batch: torch.Size([32, 100, 300])\n627\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 627 tensors\nCurrent Size of Ratings: 627 tensors\nSize of batch: torch.Size([32, 100, 300])\n628\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 628 tensors\nCurrent Size of Ratings: 628 tensors\nSize of batch: torch.Size([32, 100, 300])\n629\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 629 tensors\nCurrent Size of Ratings: 629 tensors\nSize of batch: torch.Size([32, 100, 300])\n630\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 630 tensors\nCurrent Size of Ratings: 630 tensors\nSize of batch: torch.Size([32, 100, 300])\n631\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 631 tensors\nCurrent Size of Ratings: 631 tensors\nSize of batch: torch.Size([32, 100, 300])\n632\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 632 tensors\nCurrent Size of Ratings: 632 tensors\nSize of batch: torch.Size([32, 100, 300])\n633\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 633 tensors\nCurrent Size of Ratings: 633 tensors\nSize of batch: torch.Size([32, 100, 300])\n634\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 634 tensors\nCurrent Size of Ratings: 634 tensors\nSize of batch: torch.Size([32, 100, 300])\n635\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 635 tensors\nCurrent Size of Ratings: 635 tensors\nSize of batch: torch.Size([32, 100, 300])\n636\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 636 tensors\nCurrent Size of Ratings: 636 tensors\nSize of batch: torch.Size([32, 100, 300])\n637\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 637 tensors\nCurrent Size of Ratings: 637 tensors\nSize of batch: torch.Size([32, 100, 300])\n638\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 638 tensors\nCurrent Size of Ratings: 638 tensors\nSize of batch: torch.Size([32, 100, 300])\n639\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 639 tensors\nCurrent Size of Ratings: 639 tensors\nSize of batch: torch.Size([32, 100, 300])\n640\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 640 tensors\nCurrent Size of Ratings: 640 tensors\nSize of batch: torch.Size([32, 100, 300])\n641\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 641 tensors\nCurrent Size of Ratings: 641 tensors\nSize of batch: torch.Size([32, 100, 300])\n642\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 642 tensors\nCurrent Size of Ratings: 642 tensors\nSize of batch: torch.Size([32, 100, 300])\n643\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 643 tensors\nCurrent Size of Ratings: 643 tensors\nSize of batch: torch.Size([32, 100, 300])\n644\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 644 tensors\nCurrent Size of Ratings: 644 tensors\nSize of batch: torch.Size([32, 100, 300])\n645\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 645 tensors\nCurrent Size of Ratings: 645 tensors\nSize of batch: torch.Size([32, 100, 300])\n646\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 646 tensors\nCurrent Size of Ratings: 646 tensors\nSize of batch: torch.Size([32, 100, 300])\n647\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 647 tensors\nCurrent Size of Ratings: 647 tensors\nSize of batch: torch.Size([32, 100, 300])\n648\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 648 tensors\nCurrent Size of Ratings: 648 tensors\nSize of batch: torch.Size([32, 100, 300])\n649\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 649 tensors\nCurrent Size of Ratings: 649 tensors\nSize of batch: torch.Size([32, 100, 300])\n650\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 650 tensors\nCurrent Size of Ratings: 650 tensors\nSize of batch: torch.Size([32, 100, 300])\n651\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 651 tensors\nCurrent Size of Ratings: 651 tensors\nSize of batch: torch.Size([32, 100, 300])\n652\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 652 tensors\nCurrent Size of Ratings: 652 tensors\nSize of batch: torch.Size([32, 100, 300])\n653\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 653 tensors\nCurrent Size of Ratings: 653 tensors\nSize of batch: torch.Size([32, 100, 300])\n654\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 654 tensors\nCurrent Size of Ratings: 654 tensors\nSize of batch: torch.Size([32, 100, 300])\n655\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 655 tensors\nCurrent Size of Ratings: 655 tensors\nSize of batch: torch.Size([32, 100, 300])\n656\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 656 tensors\nCurrent Size of Ratings: 656 tensors\nSize of batch: torch.Size([32, 100, 300])\n657\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 657 tensors\nCurrent Size of Ratings: 657 tensors\nSize of batch: torch.Size([32, 100, 300])\n658\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 658 tensors\nCurrent Size of Ratings: 658 tensors\nSize of batch: torch.Size([32, 100, 300])\n659\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 659 tensors\nCurrent Size of Ratings: 659 tensors\nSize of batch: torch.Size([32, 100, 300])\n660\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 660 tensors\nCurrent Size of Ratings: 660 tensors\nSize of batch: torch.Size([32, 100, 300])\n661\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 661 tensors\nCurrent Size of Ratings: 661 tensors\nSize of batch: torch.Size([32, 100, 300])\n662\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 662 tensors\nCurrent Size of Ratings: 662 tensors\nSize of batch: torch.Size([32, 100, 300])\n663\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 663 tensors\nCurrent Size of Ratings: 663 tensors\nSize of batch: torch.Size([32, 100, 300])\n664\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 664 tensors\nCurrent Size of Ratings: 664 tensors\nSize of batch: torch.Size([32, 100, 300])\n665\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 665 tensors\nCurrent Size of Ratings: 665 tensors\nSize of batch: torch.Size([32, 100, 300])\n666\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 666 tensors\nCurrent Size of Ratings: 666 tensors\nSize of batch: torch.Size([32, 100, 300])\n667\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 667 tensors\nCurrent Size of Ratings: 667 tensors\nSize of batch: torch.Size([32, 100, 300])\n668\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 668 tensors\nCurrent Size of Ratings: 668 tensors\nSize of batch: torch.Size([32, 100, 300])\n669\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 669 tensors\nCurrent Size of Ratings: 669 tensors\nSize of batch: torch.Size([32, 100, 300])\n670\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 670 tensors\nCurrent Size of Ratings: 670 tensors\nSize of batch: torch.Size([32, 100, 300])\n671\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 671 tensors\nCurrent Size of Ratings: 671 tensors\nSize of batch: torch.Size([32, 100, 300])\n672\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 672 tensors\nCurrent Size of Ratings: 672 tensors\nSize of batch: torch.Size([32, 100, 300])\n673\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 673 tensors\nCurrent Size of Ratings: 673 tensors\nSize of batch: torch.Size([32, 100, 300])\n674\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 674 tensors\nCurrent Size of Ratings: 674 tensors\nSize of batch: torch.Size([32, 100, 300])\n675\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 675 tensors\nCurrent Size of Ratings: 675 tensors\nSize of batch: torch.Size([32, 100, 300])\n676\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 676 tensors\nCurrent Size of Ratings: 676 tensors\nSize of batch: torch.Size([32, 100, 300])\n677\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 677 tensors\nCurrent Size of Ratings: 677 tensors\nSize of batch: torch.Size([32, 100, 300])\n678\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 678 tensors\nCurrent Size of Ratings: 678 tensors\nSize of batch: torch.Size([32, 100, 300])\n679\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 679 tensors\nCurrent Size of Ratings: 679 tensors\nSize of batch: torch.Size([32, 100, 300])\n680\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 680 tensors\nCurrent Size of Ratings: 680 tensors\nSize of batch: torch.Size([32, 100, 300])\n681\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 681 tensors\nCurrent Size of Ratings: 681 tensors\nSize of batch: torch.Size([32, 100, 300])\n682\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 682 tensors\nCurrent Size of Ratings: 682 tensors\nSize of batch: torch.Size([32, 100, 300])\n683\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 683 tensors\nCurrent Size of Ratings: 683 tensors\nSize of batch: torch.Size([32, 100, 300])\n684\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 684 tensors\nCurrent Size of Ratings: 684 tensors\nSize of batch: torch.Size([32, 100, 300])\n685\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 685 tensors\nCurrent Size of Ratings: 685 tensors\nSize of batch: torch.Size([32, 100, 300])\n686\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 686 tensors\nCurrent Size of Ratings: 686 tensors\nSize of batch: torch.Size([32, 100, 300])\n687\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 687 tensors\nCurrent Size of Ratings: 687 tensors\nSize of batch: torch.Size([32, 100, 300])\n688\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 688 tensors\nCurrent Size of Ratings: 688 tensors\nSize of batch: torch.Size([32, 100, 300])\n689\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 689 tensors\nCurrent Size of Ratings: 689 tensors\nSize of batch: torch.Size([32, 100, 300])\n690\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 690 tensors\nCurrent Size of Ratings: 690 tensors\nSize of batch: torch.Size([32, 100, 300])\n691\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 691 tensors\nCurrent Size of Ratings: 691 tensors\nSize of batch: torch.Size([32, 100, 300])\n692\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 692 tensors\nCurrent Size of Ratings: 692 tensors\nSize of batch: torch.Size([32, 100, 300])\n693\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 693 tensors\nCurrent Size of Ratings: 693 tensors\nSize of batch: torch.Size([32, 100, 300])\n694\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 694 tensors\nCurrent Size of Ratings: 694 tensors\nSize of batch: torch.Size([32, 100, 300])\n695\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 695 tensors\nCurrent Size of Ratings: 695 tensors\nSize of batch: torch.Size([32, 100, 300])\n696\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 696 tensors\nCurrent Size of Ratings: 696 tensors\nSize of batch: torch.Size([32, 100, 300])\n697\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 697 tensors\nCurrent Size of Ratings: 697 tensors\nSize of batch: torch.Size([32, 100, 300])\n698\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 698 tensors\nCurrent Size of Ratings: 698 tensors\nSize of batch: torch.Size([32, 100, 300])\n699\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 699 tensors\nCurrent Size of Ratings: 699 tensors\nSize of batch: torch.Size([32, 100, 300])\n700\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 700 tensors\nCurrent Size of Ratings: 700 tensors\nSize of batch: torch.Size([32, 100, 300])\n701\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 701 tensors\nCurrent Size of Ratings: 701 tensors\nSize of batch: torch.Size([32, 100, 300])\n702\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 702 tensors\nCurrent Size of Ratings: 702 tensors\nSize of batch: torch.Size([32, 100, 300])\n703\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 703 tensors\nCurrent Size of Ratings: 703 tensors\nSize of batch: torch.Size([32, 100, 300])\n704\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 704 tensors\nCurrent Size of Ratings: 704 tensors\nSize of batch: torch.Size([32, 100, 300])\n705\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 705 tensors\nCurrent Size of Ratings: 705 tensors\nSize of batch: torch.Size([32, 100, 300])\n706\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 706 tensors\nCurrent Size of Ratings: 706 tensors\nSize of batch: torch.Size([32, 100, 300])\n707\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 707 tensors\nCurrent Size of Ratings: 707 tensors\nSize of batch: torch.Size([32, 100, 300])\n708\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 708 tensors\nCurrent Size of Ratings: 708 tensors\nSize of batch: torch.Size([32, 100, 300])\n709\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 709 tensors\nCurrent Size of Ratings: 709 tensors\nSize of batch: torch.Size([32, 100, 300])\n710\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 710 tensors\nCurrent Size of Ratings: 710 tensors\nSize of batch: torch.Size([32, 100, 300])\n711\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 711 tensors\nCurrent Size of Ratings: 711 tensors\nSize of batch: torch.Size([32, 100, 300])\n712\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 712 tensors\nCurrent Size of Ratings: 712 tensors\nSize of batch: torch.Size([32, 100, 300])\n713\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 713 tensors\nCurrent Size of Ratings: 713 tensors\nSize of batch: torch.Size([32, 100, 300])\n714\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 714 tensors\nCurrent Size of Ratings: 714 tensors\nSize of batch: torch.Size([32, 100, 300])\n715\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 715 tensors\nCurrent Size of Ratings: 715 tensors\nSize of batch: torch.Size([32, 100, 300])\n716\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 716 tensors\nCurrent Size of Ratings: 716 tensors\nSize of batch: torch.Size([32, 100, 300])\n717\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 717 tensors\nCurrent Size of Ratings: 717 tensors\nSize of batch: torch.Size([32, 100, 300])\n718\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 718 tensors\nCurrent Size of Ratings: 718 tensors\nSize of batch: torch.Size([32, 100, 300])\n719\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 719 tensors\nCurrent Size of Ratings: 719 tensors\nSize of batch: torch.Size([32, 100, 300])\n720\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 720 tensors\nCurrent Size of Ratings: 720 tensors\nSize of batch: torch.Size([32, 100, 300])\n721\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 721 tensors\nCurrent Size of Ratings: 721 tensors\nSize of batch: torch.Size([32, 100, 300])\n722\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 722 tensors\nCurrent Size of Ratings: 722 tensors\nSize of batch: torch.Size([32, 100, 300])\n723\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 723 tensors\nCurrent Size of Ratings: 723 tensors\nSize of batch: torch.Size([32, 100, 300])\n724\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 724 tensors\nCurrent Size of Ratings: 724 tensors\nSize of batch: torch.Size([32, 100, 300])\n725\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 725 tensors\nCurrent Size of Ratings: 725 tensors\nSize of batch: torch.Size([32, 100, 300])\n726\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 726 tensors\nCurrent Size of Ratings: 726 tensors\nSize of batch: torch.Size([32, 100, 300])\n727\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 727 tensors\nCurrent Size of Ratings: 727 tensors\nSize of batch: torch.Size([32, 100, 300])\n728\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 728 tensors\nCurrent Size of Ratings: 728 tensors\nSize of batch: torch.Size([32, 100, 300])\n729\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 729 tensors\nCurrent Size of Ratings: 729 tensors\nSize of batch: torch.Size([32, 100, 300])\n730\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 730 tensors\nCurrent Size of Ratings: 730 tensors\nSize of batch: torch.Size([32, 100, 300])\n731\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 731 tensors\nCurrent Size of Ratings: 731 tensors\nSize of batch: torch.Size([32, 100, 300])\n732\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 732 tensors\nCurrent Size of Ratings: 732 tensors\nSize of batch: torch.Size([32, 100, 300])\n733\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 733 tensors\nCurrent Size of Ratings: 733 tensors\nSize of batch: torch.Size([32, 100, 300])\n734\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 734 tensors\nCurrent Size of Ratings: 734 tensors\nSize of batch: torch.Size([32, 100, 300])\n735\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 735 tensors\nCurrent Size of Ratings: 735 tensors\nSize of batch: torch.Size([32, 100, 300])\n736\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 736 tensors\nCurrent Size of Ratings: 736 tensors\nSize of batch: torch.Size([32, 100, 300])\n737\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 737 tensors\nCurrent Size of Ratings: 737 tensors\nSize of batch: torch.Size([32, 100, 300])\n738\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 738 tensors\nCurrent Size of Ratings: 738 tensors\nSize of batch: torch.Size([32, 100, 300])\n739\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 739 tensors\nCurrent Size of Ratings: 739 tensors\nSize of batch: torch.Size([32, 100, 300])\n740\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 740 tensors\nCurrent Size of Ratings: 740 tensors\nSize of batch: torch.Size([32, 100, 300])\n741\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 741 tensors\nCurrent Size of Ratings: 741 tensors\nSize of batch: torch.Size([32, 100, 300])\n742\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 742 tensors\nCurrent Size of Ratings: 742 tensors\nSize of batch: torch.Size([32, 100, 300])\n743\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 743 tensors\nCurrent Size of Ratings: 743 tensors\nSize of batch: torch.Size([32, 100, 300])\n744\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 744 tensors\nCurrent Size of Ratings: 744 tensors\nSize of batch: torch.Size([32, 100, 300])\n745\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 745 tensors\nCurrent Size of Ratings: 745 tensors\nSize of batch: torch.Size([32, 100, 300])\n746\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 746 tensors\nCurrent Size of Ratings: 746 tensors\nSize of batch: torch.Size([32, 100, 300])\n747\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 747 tensors\nCurrent Size of Ratings: 747 tensors\nSize of batch: torch.Size([32, 100, 300])\n748\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 748 tensors\nCurrent Size of Ratings: 748 tensors\nSize of batch: torch.Size([32, 100, 300])\n749\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 749 tensors\nCurrent Size of Ratings: 749 tensors\nSize of batch: torch.Size([32, 100, 300])\n750\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 750 tensors\nCurrent Size of Ratings: 750 tensors\nSize of batch: torch.Size([32, 100, 300])\n751\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 751 tensors\nCurrent Size of Ratings: 751 tensors\nSize of batch: torch.Size([32, 100, 300])\n752\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 752 tensors\nCurrent Size of Ratings: 752 tensors\nSize of batch: torch.Size([32, 100, 300])\n753\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 753 tensors\nCurrent Size of Ratings: 753 tensors\nSize of batch: torch.Size([32, 100, 300])\n754\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 754 tensors\nCurrent Size of Ratings: 754 tensors\nSize of batch: torch.Size([32, 100, 300])\n755\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 755 tensors\nCurrent Size of Ratings: 755 tensors\nSize of batch: torch.Size([32, 100, 300])\n756\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 756 tensors\nCurrent Size of Ratings: 756 tensors\nSize of batch: torch.Size([32, 100, 300])\n757\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 757 tensors\nCurrent Size of Ratings: 757 tensors\nSize of batch: torch.Size([32, 100, 300])\n758\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 758 tensors\nCurrent Size of Ratings: 758 tensors\nSize of batch: torch.Size([32, 100, 300])\n759\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 759 tensors\nCurrent Size of Ratings: 759 tensors\nSize of batch: torch.Size([32, 100, 300])\n760\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 760 tensors\nCurrent Size of Ratings: 760 tensors\nSize of batch: torch.Size([32, 100, 300])\n761\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 761 tensors\nCurrent Size of Ratings: 761 tensors\nSize of batch: torch.Size([32, 100, 300])\n762\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 762 tensors\nCurrent Size of Ratings: 762 tensors\nSize of batch: torch.Size([32, 100, 300])\n763\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 763 tensors\nCurrent Size of Ratings: 763 tensors\nSize of batch: torch.Size([32, 100, 300])\n764\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 764 tensors\nCurrent Size of Ratings: 764 tensors\nSize of batch: torch.Size([32, 100, 300])\n765\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 765 tensors\nCurrent Size of Ratings: 765 tensors\nSize of batch: torch.Size([32, 100, 300])\n766\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 766 tensors\nCurrent Size of Ratings: 766 tensors\nSize of batch: torch.Size([32, 100, 300])\n767\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 767 tensors\nCurrent Size of Ratings: 767 tensors\nSize of batch: torch.Size([32, 100, 300])\n768\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 768 tensors\nCurrent Size of Ratings: 768 tensors\nSize of batch: torch.Size([32, 100, 300])\n769\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 769 tensors\nCurrent Size of Ratings: 769 tensors\nSize of batch: torch.Size([32, 100, 300])\n770\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 770 tensors\nCurrent Size of Ratings: 770 tensors\nSize of batch: torch.Size([32, 100, 300])\n771\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 771 tensors\nCurrent Size of Ratings: 771 tensors\nSize of batch: torch.Size([32, 100, 300])\n772\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 772 tensors\nCurrent Size of Ratings: 772 tensors\nSize of batch: torch.Size([32, 100, 300])\n773\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 773 tensors\nCurrent Size of Ratings: 773 tensors\nSize of batch: torch.Size([32, 100, 300])\n774\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 774 tensors\nCurrent Size of Ratings: 774 tensors\nSize of batch: torch.Size([32, 100, 300])\n775\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 775 tensors\nCurrent Size of Ratings: 775 tensors\nSize of batch: torch.Size([32, 100, 300])\n776\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 776 tensors\nCurrent Size of Ratings: 776 tensors\nSize of batch: torch.Size([32, 100, 300])\n777\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 777 tensors\nCurrent Size of Ratings: 777 tensors\nSize of batch: torch.Size([32, 100, 300])\n778\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 778 tensors\nCurrent Size of Ratings: 778 tensors\nSize of batch: torch.Size([32, 100, 300])\n779\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 779 tensors\nCurrent Size of Ratings: 779 tensors\nSize of batch: torch.Size([32, 100, 300])\n780\nTotal allocated memory: 3333718016 bytes\nCurrent Size of Reviews: 780 tensors\nCurrent Size of Ratings: 780 tensors\nSize of batch: torch.Size([32, 100, 300])\n781\nTotal allocated memory: 3333103616 bytes\nCurrent Size of Reviews: 781 tensors\nCurrent Size of Ratings: 781 tensors\nSize of batch: torch.Size([8, 100, 300])\n782\nTotal allocated memory: 3330838016 bytes\nCurrent Size of Reviews: 782 tensors\nCurrent Size of Ratings: 782 tensors\nConcatenated Reviews Size: torch.Size([25000, 100, 300])\nConcatenated Ratings Size: torch.Size([25000])\n","output_type":"stream"}]},{"cell_type":"code","source":"print(total_encoded_batch.shape)  # Check the shape of the combined encoded tensor\nprint(total_y_batch.shape)\nprint('\\n')\n\n# size in MB\nprint(f'total_encoded_batch in bytes: { total_encoded_batch.nelement() * total_encoded_batch.element_size() }')\nprint(f'total_y_batch in bytes: { total_y_batch.nelement() * total_y_batch.element_size() }')\nprint('\\n')\n\nprint(f\"The Encoded batch is on: {total_encoded_batch.device}\")\nprint(f\"The Y batch is on: {total_y_batch.device}\")\nprint('\\n')\nprint(stacked_encoder)\nprint('\\n')","metadata":{"execution":{"iopub.status.busy":"2024-04-14T09:50:52.454478Z","iopub.execute_input":"2024-04-14T09:50:52.454998Z","iopub.status.idle":"2024-04-14T09:50:52.463023Z","shell.execute_reply.started":"2024-04-14T09:50:52.454970Z","shell.execute_reply":"2024-04-14T09:50:52.462064Z"},"trusted":true},"execution_count":17,"outputs":[{"name":"stdout","text":"torch.Size([25000, 100, 300])\ntorch.Size([25000])\n\n\ntotal_encoded_batch in bytes: 3000000000\ntotal_y_batch in bytes: 200000\n\n\nThe Encoded batch is on: cpu\nThe Y batch is on: cpu\n\n\nStackedEncoder(\n  (layers): ModuleList(\n    (0-3): 4 x EncoderLayer(\n      (self_attn): MultiHeadedAttention(\n        (linears): ModuleList(\n          (0-3): 4 x Linear(in_features=300, out_features=300, bias=True)\n        )\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (feed_forward): PositionwiseFeedForward(\n        (w_1): Linear(in_features=300, out_features=1024, bias=True)\n        (w_2): Linear(in_features=1024, out_features=300, bias=True)\n        (dropout): Dropout(p=0.0, inplace=False)\n      )\n      (sublayer): ModuleList(\n        (0-1): 2 x LayerNorm()\n      )\n      (dropout): Dropout(p=0.0, inplace=False)\n    )\n  )\n  (norm): LayerNorm()\n)\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Training approaches like masked-language modeling next sentence prediction, permutative language modeling, contrastive learning\n\n1. Visualization: You can visualize the input and output tensors to see if there are any noticeable patterns or differences. Techniques like heatmaps, scatter plots, or dimensionality reduction methods (e.g., t-SNE, PCA) can help you visualize high-dimensional data in a more interpretable way.\n\n2. Comparing input and output: You can directly compare the input and output tensors element-wise to see how the values have changed. This can give you an idea of the magnitude and direction of the transformations applied by the encoder.\n\n3. Analyzing attention weights: If your transformer encoder uses attention mechanisms, you can examine the attention weights to understand which parts of the input the model is focusing on. Higher attention weights indicate that the model is paying more attention to those specific positions or features.\n\n4. Probing the learned representations: You can train a separate model (e.g., a classifier or regressor) on top of the encoded representations to see if they capture meaningful information for a downstream task. If the model performs well, it suggests that the encoder has learned useful representations.\n\n5. Ablation studies: You can systematically remove or modify certain components of the transformer encoder (e.g., attention layers, normalization) and observe how the output changes. This can help you understand the role and impact of each component on the encoding process.\n\n6. Analyzing the distribution of values: You can compute statistics like mean, variance, and range of the input and output tensors to see how the distribution of values has changed. This can provide insights into the overall effect of the encoder on the data.\n\n7. Gradient-based methods: If you have access to the gradients of the encoder, you can use techniques like saliency maps or gradient-based attribution methods to identify which input features have the most influence on the output.\n\nKeep in mind that interpreting the behavior of deep learning models can be challenging, especially for complex architectures like transformers. It often requires a combination of different analysis techniques and domain knowledge to gain meaningful insights.\n\nRemember to normalize or scale the input and output tensors appropriately before visualization or comparison, as the raw floating-point values may have different scales and ranges.","metadata":{}}]}