{"metadata":{"kaggle":{"accelerator":"gpu","dataSources":[{"sourceId":8182344,"sourceType":"datasetVersion","datasetId":4844516}],"dockerImageVersionId":30699,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.13"},"papermill":{"default_parameters":{},"duration":2372.211165,"end_time":"2024-04-07T06:44:42.316126","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2024-04-07T06:05:10.104961","version":"2.5.0"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# For viewing and manipulating data\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Importing the necessary libraries\nimport re\nimport math\nimport string\nimport nltk\nimport spacy\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport gensim.downloader as api\nfrom gensim.models import KeyedVectors # >> alternative to gensim.downloader\nimport matplotlib.pyplot as plt\n\n# Getting particular functions from these libraries \nfrom torch import Tensor\nfrom sklearn.utils import resample\nfrom gensim.models import KeyedVectors\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom torch.utils.data import random_split, DataLoader, TensorDataset, Dataset\nfrom sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, confusion_matrix\n\n\n# Using the NLTK to tokenize the text\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\ndataset_file_name = ''\nfor dirname, _, filenames in os.walk('/kaggle/input/'):\n    for filename in filenames:\n        file_name = os.path.join(dirname, filename)\n        if file_name.endswith('dataset'):\n            dataset_file_name = file_name\n        else:\n            print(f'Found unexpected file: {file_name}')\n                \nprint(f'Preprocessed data file: {dataset_file_name}')\n\n# Checks if a CUDA enabled GPU is available and prints out its information\nif torch.cuda.is_available():\n    print(\"CUDA is available!\")\n    for i in range(torch.cuda.device_count()):\n        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n        \n    device = torch.device(\"cuda:0\")\n    accelerator = True\n\nelse:\n    accelerator = False\n    print(\"CUDA is not available.\")\n    device = torch.device(\"cpu\")\n    print(device)\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nVERBOSE = True\ndef printv(text):\n    if VERBOSE: print('VERBOSE:', text)\n    return\n\ndef showV(text):\n    '''unconditional verbose output'''\n    print('VERBOSE:', text)\n    return\n\nDEV = False\ndef printd(text):\n    if DEV: print('DEV:', text)\n    return\n\ndef showD(text):\n    '''unconditional DEV output'''\n    print('DEV:', text)  #<< 4/12/24 changed \"VERBOSE\" to \"DEV\"\n    return\n\nshowCellCompletion = True  #<< 4/12/24 set default to True\ndef showC(text):\n    if showCellCompletion:\n        print('Cell complete:', text)\n    return\n\nimport subprocess\nshowNv = True\naccelerator = True\n\ndef printNv():\n    if not showNv or not accelerator: return\n    mem_usage = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE)\n    print(mem_usage.stdout.decode('utf-8'))\n\nshowMemoryAllocation = True\ndef printM():\n    if not showMemoryAllocation: return\n    print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")","metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","papermill":{"duration":18.682261,"end_time":"2024-04-07T06:05:31.518053","exception":false,"start_time":"2024-04-07T06:05:12.835792","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-28T09:27:50.892459Z","iopub.execute_input":"2024-04-28T09:27:50.893260Z","iopub.status.idle":"2024-04-28T09:28:10.523682Z","shell.execute_reply.started":"2024-04-28T09:27:50.893225Z","shell.execute_reply":"2024-04-28T09:28:10.522685Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Found unexpected file: /kaggle/input/preprocessed-dataset/preprocessed_dataset.json\nPreprocessed data file: /kaggle/input/preprocessed-dataset/preprocessed_dataset\nCUDA is available!\nGPU 0: Tesla P100-PCIE-16GB\n","output_type":"stream"}]},{"cell_type":"code","source":"# import h5py\n\n# file_path = '//kaggle/input/140000/review_data.hdf5'\n# with h5py.File(file_path, 'r') as hf:\n#     # Access the datasets within the HDF5 file\n#     text_reviews_dataset = hf['text_reviews']\n#     ratings_dataset = hf['ratings']\n\n#     # Convert the datasets to PyTorch tensors\n#     text_reviews = torch.from_numpy(text_reviews_dataset[:])\n#     ratings = torch.from_numpy(ratings_dataset[:])\n\n# # Use the loaded tensors as needed\n# print(text_reviews.shape)\n# print(ratings.shape)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Yes, you should be more careful when splitting your dataset into training and validation sets, especially considering that your data is currently organized with each rating class having an equal number of reviews in order.\n\nIf you perform a simple random split without considering the rating classes, there is a risk of introducing bias or creating an imbalanced distribution of rating classes in the training and validation sets. This can potentially affect the model's ability to learn and generalize effectively across all rating classes.\n\nTo ensure a more balanced and representative split, you can use a stratified sampling approach. Stratified sampling takes into account the distribution of classes or categories in the dataset and aims to maintain a similar distribution in the training and validation sets.\n\nHere's how you can perform a stratified split:\n\n1. Separate your dataset into different subsets based on the rating classes. In your case, you mentioned that each rating class has 28,000 reviews in order.\n\n2. For each rating class subset:\n   - Randomly shuffle the reviews within that subset to ensure randomness within the class.\n   - Split the shuffled subset into training and validation sets using the desired ratio (e.g., 80% for training and 20% for validation).\n   - Assign the split data to the respective training and validation sets.\n\n3. Combine the training subsets from all rating classes to form the final training set, and combine the validation subsets to form the final validation set.\n\nBy following this approach, you ensure that each rating class is proportionately represented in both the training and validation sets, maintaining the original distribution of the classes.\n\nHere's an example of how you can implement stratified splitting using Python and the `sklearn` library:\n\n```python\n# Assuming your data is stored in 'X' and the corresponding ratings are in 'y'\nX_train = []\nX_val = []\ny_train = []\ny_val = []\n\n# Perform stratified splitting for each rating class\nfor rating in unique_ratings:\n    X_rating = X[y == rating]\n    y_rating = y[y == rating]\n    \n    X_train_rating, X_val_rating, y_train_rating, y_val_rating = train_test_split(\n        X_rating, y_rating, test_size=0.2, random_state=42, stratify=y_rating)\n    \n    X_train.append(X_train_rating)\n    X_val.append(X_val_rating)\n    y_train.append(y_train_rating)\n    y_val.append(y_val_rating)\n\n# Combine the split data from all rating classes\nX_train = np.concatenate(X_train)\nX_val = np.concatenate(X_val)\ny_train = np.concatenate(y_train)\ny_val = np.concatenate(y_val)\n```\n\nIn this example, `X` represents your dataset of shape (140000, 100, 300), and `y` represents the corresponding ratings for each review. The code iterates over each unique rating class, performs stratified splitting using `train_test_split` with the `stratify` parameter set to ensure the same distribution of ratings in the training and validation sets, and then combines the split data from all rating classes.\n\nBy using stratified splitting, you maintain the balance of rating classes in both the training and validation sets, ensuring a more representative evaluation of your model's performance across all classes.\n\nRemember to adjust the code based on your specific data format and requirements, but the general approach of stratified splitting remains the same.","metadata":{"jupyter":{"source_hidden":true}}},{"cell_type":"code","source":"import pickle\nwith open(dataset_file_name, 'rb') as dataset_file:\n    dataset = pickle.load(dataset_file)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T09:28:17.802239Z","iopub.execute_input":"2024-04-28T09:28:17.803462Z","iopub.status.idle":"2024-04-28T09:28:18.683929Z","shell.execute_reply.started":"2024-04-28T09:28:17.803423Z","shell.execute_reply":"2024-04-28T09:28:18.683091Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"# Assuming your data is stored in 'dataset' as a PyTorch dataset object\nX = dataset.tensors[0]  # Assuming the reviews are stored at index 1 in the dataset tensors\ny = dataset.tensors[1]  # Assuming the ratings are stored at index 0 in the dataset tensors\n\nprint(\"Shape of X (reviews):\", X.shape)\nprint(\"Shape of y (ratings):\", y.shape)\n\nX_train = []\nX_val = []\ny_train = []\ny_val = []\n\n# Perform stratified splitting for each rating class\nfor rating in torch.unique(y):\n    X_rating = X[y == rating]\n    y_rating = y[y == rating]\n\n    X_train_rating, X_val_rating, y_train_rating, y_val_rating = train_test_split(\n        X_rating, y_rating, test_size = 0.2, random_state = 42, stratify = y_rating)\n\n    X_train.append(X_train_rating)\n    X_val.append(X_val_rating)\n    y_train.append(y_train_rating)\n    y_val.append(y_val_rating)\n\n# Combine the split data from all rating classes\nX_train = torch.cat(X_train)\nX_val = torch.cat(X_val)\ny_train = torch.cat(y_train)\ny_val = torch.cat(y_val)\n\n# Create new datasets using the split data\ntrain_data = TensorDataset(X_train, y_train)\nval_data = TensorDataset(X_val, y_val)\n\nprint(\"Training Set:\")\nprint(\"Number of ratings:\", len(y_train))\nprint(\"Number of reviews:\", len(X_train))\nprint(\"Number of reviews per rating:\")\nfor rating in torch.unique(y_train):\n    count = torch.sum(y_train == rating).item()\n    print(f\"Rating {rating}: {count} reviews\")\n\nprint(\"\\nValidation Set:\")\nprint(\"Number of ratings:\", len(y_val))\nprint(\"Number of reviews:\", len(X_val))\nprint(\"Number of reviews per rating:\")\nfor rating in torch.unique(y_val):\n    count = torch.sum(y_val == rating).item()\n    print(f\"Rating {rating}: {count} reviews\")\n\nprintv(f\"The amount of data we have to train with is {len(train_data)} reviews\") \nprintv(f\"The amount of data we have to validate with is {len(val_data)} reviews\")\n\n# DataLoader for training data\ntrain_loader = DataLoader(train_data, batch_size = 32, shuffle = True)  # Use shuffle for training\n\n# DataLoader for validation data\nval_loader = DataLoader(val_data, batch_size = 32, shuffle = False)  # No need to shuffle for validation","metadata":{"papermill":{"duration":0.025623,"end_time":"2024-04-07T06:22:13.305100","exception":false,"start_time":"2024-04-07T06:22:13.279477","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-28T09:28:24.259613Z","iopub.execute_input":"2024-04-28T09:28:24.260463Z","iopub.status.idle":"2024-04-28T09:28:25.057484Z","shell.execute_reply.started":"2024-04-28T09:28:24.260429Z","shell.execute_reply":"2024-04-28T09:28:25.056534Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"Shape of X (reviews): torch.Size([5000, 100, 300])\nShape of y (ratings): torch.Size([5000])\nTraining Set:\nNumber of ratings: 4000\nNumber of reviews: 4000\nNumber of reviews per rating:\nRating 1: 800 reviews\nRating 2: 800 reviews\nRating 3: 800 reviews\nRating 4: 800 reviews\nRating 5: 800 reviews\n\nValidation Set:\nNumber of ratings: 1000\nNumber of reviews: 1000\nNumber of reviews per rating:\nRating 1: 200 reviews\nRating 2: 200 reviews\nRating 3: 200 reviews\nRating 4: 200 reviews\nRating 5: 200 reviews\nVERBOSE: The amount of data we have to train with is 4000 reviews\nVERBOSE: The amount of data we have to validate with is 1000 reviews\n","output_type":"stream"}]},{"cell_type":"code","source":"# HyperParameters for the model\nd_model = 300  # Should match the embedding dimension of your word embeddings\nseq_len = 100 #<< 4/13/24 100  # Maximum sequence length\ndropout = 0.1  # Adjust the dropout if needed\n\nnum_layers = 5 # depth of our network\ninput_size = d_model  # match the output dim of your ff_net\nnum_classes = 5  # our ratings (1 - 5)\nhidden_size = 1024 # 2^n\n\neps    = 1e-05 # epsilon value to prevent the standard deviation from becoming zero\nepochs = 100 #<< 1000\nlearning_rate = 0.001\nweight_decay  = 0.01\n\nshowC('Hyperparameters defined')","metadata":{"papermill":{"duration":0.018663,"end_time":"2024-04-07T06:22:13.334973","exception":false,"start_time":"2024-04-07T06:22:13.316310","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-28T09:28:31.399614Z","iopub.execute_input":"2024-04-28T09:28:31.400269Z","iopub.status.idle":"2024-04-28T09:28:31.406290Z","shell.execute_reply.started":"2024-04-28T09:28:31.400236Z","shell.execute_reply":"2024-04-28T09:28:31.405341Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"Cell complete: Hyperparameters defined\n","output_type":"stream"}]},{"cell_type":"code","source":"class NeuralNetClassifier(nn.Module):\n    def __init__(self, r_size, v_size, num_classes, hidden_size = hidden_size, num_layers = num_layers, dropout = dropout):\n        super(NeuralNetClassifier, self).__init__()\n        \n        self.hidden_layers = nn.ModuleList()\n        self.hidden_layers.append(nn.Linear(r_size * v_size, hidden_size))\n        self.hidden_layers.append(nn.BatchNorm1d(hidden_size))\n        \n        for _ in range(num_layers - 1):\n            self.hidden_layers.append(nn.Linear(hidden_size, hidden_size))\n            self.hidden_layers.append(nn.BatchNorm1d(hidden_size))\n        \n        self.output_layer = nn.Linear(hidden_size, num_classes)\n        self.relu = nn.LeakyReLU()\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        for layer in self.hidden_layers:\n            x = layer(x)\n            x = self.relu(x)\n            x = self.dropout(x)\n        \n        x = self.output_layer(x)\n        return x","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"classifier = NeuralNetClassifier(seq_len, d_model, num_classes, hidden_size, num_layers, dropout)\nclassifier = classifier.to(device)\n\nprint(classifier)","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# neural net with rnn","metadata":{}},{"cell_type":"code","source":"class RecurrentNeuralNetClassifier(nn.Module):\n    def __init__(self, r_size, v_size, num_classes, hidden_size = hidden_size, \n                 num_layers = num_layers, dropout = dropout, rnn_hidden_size = 256, rnn_num_layers = 1):\n        super(RecurrentNeuralNetClassifier, self).__init__()\n\n        self.rnn = nn.RNN(r_size * v_size, rnn_hidden_size, rnn_num_layers, batch_first=True)\n        \n        self.hidden_layers = nn.ModuleList()\n        self.hidden_layers.append(nn.Linear(rnn_hidden_size, hidden_size))\n        self.hidden_layers.append(nn.BatchNorm1d(hidden_size))\n        \n        for _ in range(num_layers - 1):\n            self.hidden_layers.append(nn.Linear(hidden_size, hidden_size))\n            self.hidden_layers.append(nn.BatchNorm1d(hidden_size))\n        \n        self.output_layer = nn.Linear(hidden_size, num_classes)\n        self.relu = nn.LeakyReLU()\n        self.dropout = nn.Dropout(dropout)\n        \n    def forward(self, x):\n        # Reshape the input to match the expected shape for RNN\n        x = x.view(x.size(0), -1, x.size(-1))\n        \n        # Pass the input through the RNN layer\n        x, _ = self.rnn(x)\n        \n        # Take the last output of the RNN\n        x = x[:, -1, :]\n        \n        for layer in self.hidden_layers:\n            x = layer(x)\n            x = self.relu(x)\n            x = self.dropout(x)\n        \n        x = self.output_layer(x)\n        return x","metadata":{"execution":{"iopub.status.busy":"2024-04-28T09:28:45.194638Z","iopub.execute_input":"2024-04-28T09:28:45.195285Z","iopub.status.idle":"2024-04-28T09:28:45.205690Z","shell.execute_reply.started":"2024-04-28T09:28:45.195247Z","shell.execute_reply":"2024-04-28T09:28:45.204717Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"classifier = RecurrentNeuralNetClassifier(seq_len, d_model, num_classes, hidden_size, num_layers, dropout)\nclassifier = classifier.to(device)\n\nprint(classifier)","metadata":{"execution":{"iopub.status.busy":"2024-04-28T09:29:03.752377Z","iopub.execute_input":"2024-04-28T09:29:03.752792Z","iopub.status.idle":"2024-04-28T09:29:04.009528Z","shell.execute_reply.started":"2024-04-28T09:29:03.752760Z","shell.execute_reply":"2024-04-28T09:29:04.008509Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"RecurrentNeuralNetClassifier(\n  (rnn): RNN(30000, 256, batch_first=True)\n  (hidden_layers): ModuleList(\n    (0): Linear(in_features=256, out_features=1024, bias=True)\n    (1): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (2): Linear(in_features=1024, out_features=1024, bias=True)\n    (3): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (4): Linear(in_features=1024, out_features=1024, bias=True)\n    (5): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (6): Linear(in_features=1024, out_features=1024, bias=True)\n    (7): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n    (8): Linear(in_features=1024, out_features=1024, bias=True)\n    (9): BatchNorm1d(1024, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n  )\n  (output_layer): Linear(in_features=1024, out_features=5, bias=True)\n  (relu): LeakyReLU(negative_slope=0.01)\n  (dropout): Dropout(p=0.1, inplace=False)\n)\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# early neural nets","metadata":{}},{"cell_type":"code","source":"# class NeuralNetClassifier(nn.Module):\n#     def __init__(self, r_size, v_size, num_classes):\n#         # r_size is the number of tokens in a review, 100.\n#         # v_size is the number of values in an embedding vector, 300.\n#         super(NeuralNetClassifier, self).__init__()\n        \n#         # The input to fc will be a 2D tensor with with n rows and\n#         # r_size * v_size columns, where n >= 1; and the output will be a 2D tensor\n#         # with n rows and num_classes columns.\n#         self.hidden_layer1 = nn.Linear(r_size * v_size, hidden_size)\n#         self.hidden_layer2 = nn.Linear(hidden_size, hidden_size)\n#         self.hidden_layer3 = nn.Linear(hidden_size, num_classes)\n#         self.relu = nn.ReLU()\n#         self.dropout = nn.Dropout(dropout) #>> 0.2 seems to work OK\n#         #self.softmax = nn.Softmax(dim=1)  # Softmax with dim=1 for class probabilities\n\n#     def forward(self, x):\n#         x = self.hidden_layer1(x)\n#         x = self.relu(x)\n#         x = self.dropout(x)\n#         x = self.hidden_layer2(x)\n#         x = self.relu(x)\n#         x = self.dropout(x) #>> dropout rate 0.1 may result in underfitting?\n#         #x = self.softmax(x)  # Apply softmax after the output layer\n#         x = self.hidden_layer3(x)\n#         return x\n    \n# classifier = NeuralNetClassifier(seq_len, d_model, num_classes + 1).to(device)\n# showC(f'{classifier} defined')\n\n'''\nclass Classifier(nn.Module):\n    def __init__(self, r_size,v_size, num_classes):\n        # r_size is the number of tokens in a review, 100.\n        # v_size is the number of values in an embedding vector, 300.\n        super(Classifier, self).__init__()\n        \n        # The input to fc will be a 2D tensor with with n rows and\n        # r_size * v_size columns, where n >= 1; and the output will be a 2D tensor\n        # with n rows and num_classes columns.\n        self.fc = nn.Linear(r_size * v_size, num_classes)\n\n    def forward(self, x1):\n        # Pass input through the linear layer\n        return self.fc(x1)\n\n# Create the classifier\nclassifier = Classifier(seq_len, d_model, num_classes + 1).to(device)\n\nshowC(f'{Classifier} defined')\n'''","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# stoppage","metadata":{}},{"cell_type":"code","source":"# class EarlyStopping():\n#     \"\"\"\n#     Early stopping to stop the training when the loss does not improve after\n#     certain epochs.\n#     Credit:\n#     https://debuggercafe.com/using-learning-rate-scheduler-and-early-stopping-with-pytorch/\n#     \"\"\"\n#     def __init__(self, patience=5, min_delta=0):\n#         \"\"\"\n#         :param patience: how many epochs to wait before stopping when loss is\n#                not improving\n#         :param min_delta: minimum difference between new loss and old loss for\n#                new loss to be considered as an improvement\n#         \"\"\"\n#         self.patience = patience\n#         self.min_delta = min_delta\n#         self.counter = 0\n#         self.best_loss = None\n#         self.early_stop = False\n        \n#     def __call__(self, val_loss):\n#         if self.best_loss == None:\n#             self.best_loss = val_loss\n#         elif self.best_loss - val_loss > self.min_delta:\n#             self.best_loss = val_loss\n#             # reset counter if validation loss improves\n#             self.counter = 0\n#         elif self.best_loss - val_loss < self.min_delta:\n#             self.counter += 1\n#             #printd(f\"INFO: Early stopping counter {self.counter} of {self.patience}\")\n#             if self.counter >= self.patience:\n#                 printv(f'Early stopping: counter={self.counter}; patience={self.patience}')\n#                 self.early_stop = True\n# early_stopping = EarlyStopping(patience=20) #patience=30, min_delta=.01) \n# showC(f'{EarlyStopping} object defined')","metadata":{"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Define loss function\ncriterion = nn.CrossEntropyLoss()\n\n# Define optimizer\n# Is Adam better? Didn't seem so based on 4/23 heuristics\n# optimizer = optim.SGD(classifier.parameters(), lr = learning_rate)\noptimizer = optim.AdamW(classifier.parameters(), \n                        lr = learning_rate, weight_decay = weight_decay)\n\nDEV = True\n\n# Training loop\nlosses = {} #<< track losses\nfor epoch in range(epochs):\n    for inputs, targets in train_loader : \n\n        optimizer.zero_grad()\n\n        # keep nn.linear happy by combining the last two dimensions of inputs.\n        inputs.to(device)\n        targets = targets.to(device) - 1  # Convert ratings from [1, 5] to [0, 4]\n        inputs = torch.reshape(inputs, (inputs.size(0), -1)).to(device) # get current batch size\n\n        outputs = classifier(inputs).to(device)\n\n        # output is a 32 x 6 tensor of floats,\n        # targets will be a 32 x 1 tensor of ints\n        loss = criterion(outputs.to(device), targets.to(device))\n        loss.backward(retain_graph = True)\n\n        optimizer.step()\n\n    losses[loss.item()] = epoch + 1\n#    early_stopping(loss)\n\n#     if early_stopping.early_stop:\n#         printv(f'Stopping early at epoch [{epoch + 1} / {epochs}] Loss: {loss.item()}')\n#         break    \n\n    if epoch % 50 == 0:\n        printv(f'Epoch [{epoch + 1} / {epochs}] Loss: {loss.item()}')\n\nif VERBOSE:\n    printv(f'Last loss: Epoch [{epoch + 1} / {epochs}] Loss: {loss.item()}')\n    smallest_losses = sorted(list(losses.keys()))\n    printv('Smallest losses')\n    for idx in range(3):\n        l = smallest_losses[idx]\n        printv(f'    Loss: {l}, epoch = {losses[l]}')\nshowC(f'training complete')","metadata":{"papermill":{"duration":1344.87285,"end_time":"2024-04-07T06:44:38.254791","exception":false,"start_time":"2024-04-07T06:22:13.381941","status":"completed"},"tags":[],"execution":{"iopub.status.busy":"2024-04-28T09:29:09.711118Z","iopub.execute_input":"2024-04-28T09:29:09.711573Z","iopub.status.idle":"2024-04-28T09:30:41.417961Z","shell.execute_reply.started":"2024-04-28T09:29:09.711534Z","shell.execute_reply":"2024-04-28T09:30:41.416956Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"VERBOSE: Epoch [1 / 100] Loss: 1.6175645589828491\nVERBOSE: Epoch [51 / 100] Loss: 0.0974288135766983\nVERBOSE: Last loss: Epoch [100 / 100] Loss: 0.008013246580958366\nVERBOSE: Smallest losses\nVERBOSE:     Loss: 0.0004332157550379634, epoch = 70\nVERBOSE:     Loss: 0.00043714820640161633, epoch = 81\nVERBOSE:     Loss: 0.0006316070212051272, epoch = 97\nCell complete: training complete\n","output_type":"stream"}]},{"cell_type":"code","source":"# Put model in evaluation mode\nclassifier.eval() \n\n# Tracking variables\npredictions = []\nactuals = []\n\n# Evaluate on validation set\nwith torch.no_grad():\n    for inputs, targets in val_loader:\n        inputs = inputs.reshape(inputs.shape[0], -1).to(device)\n        targets = targets.to(device) - 1  # Convert ratings from [1, 5] to [0, 4]\n\n        outputs = classifier(inputs)\n        _, predicted = torch.max(outputs, 1)\n\n        predictions.extend(predicted.tolist())\n        actuals.extend(targets.tolist())\n\n# Calculate evaluation metrics\naccuracy = accuracy_score(actuals, predictions)\nprecision = precision_score(actuals, predictions, average='weighted')\nrecall = recall_score(actuals, predictions, average='weighted')\nf1 = f1_score(actuals, predictions, average='weighted')\n\n# Print evaluation metrics\nprint(f\"Validation Accuracy: {accuracy:.4f}\")\nprint(f\"Validation Precision: {precision:.4f}\")\nprint(f\"Validation Recall: {recall:.4f}\")\nprint(f\"Validation F1-score: {f1:.4f}\")\n\n# Calculate confusion matrix\ncm = confusion_matrix(actuals, predictions)\nprint(\"Confusion Matrix:\")\nprint(cm)\n\n# # Analyze predictions by category\n# num_categories = len(cm)\n# for idx in range(num_categories):\n#     print(f\"Category {idx+1} predictions actual results:\")\n#     for j in range(num_categories):\n#         print(f\"{j+1}. {cm[idx][j]}\")\n\n# Assess bias and variance\nif accuracy < 0.7:  # Adjust the threshold as per your requirements\n    print(\"The model may have high bias (underfitting). Consider increasing model complexity.\")\nelif accuracy > 0.95:  # Adjust the threshold as per your requirements\n    print(\"The model may have high variance (overfitting). Consider regularization techniques.\")\nelse:\n    print(\"The model seems to have a good balance between bias and variance.\")\n    \n# r_by_category = [0,0,0,0,0]\n# r = list('12345')\n\n# for idx in range(5):\n#     r[idx] = r_by_category[:]\n\n# for p,a in zip(predictions, actuals):\n#     r[p-1][a-1] += 1 # Record the actual results for each category prediction\n\n# num_correct = 0\n# for idx in range (5):\n#     printv(f'Categrory {idx+1} predictions actual results: ' +\\\n#            f'1. {r[idx][0]}; 2. {r[idx][1]}; 3. {r[idx][2]}; 4. {r[idx][3]}; 5. {r[idx][4]}')\n#     num_correct += r[idx][idx]\n\n# # num_correct = sum([p == a for p, a in zip(predictions, actuals)]) \n# val_accuracy = num_correct / len(predictions)\n# print(f'Validation Accuracy: {val_accuracy:.2f}')","metadata":{"execution":{"iopub.status.busy":"2024-04-28T09:31:07.239154Z","iopub.execute_input":"2024-04-28T09:31:07.240137Z","iopub.status.idle":"2024-04-28T09:31:07.372998Z","shell.execute_reply.started":"2024-04-28T09:31:07.240100Z","shell.execute_reply":"2024-04-28T09:31:07.371927Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"Validation Accuracy: 0.3080\nValidation Precision: 0.3083\nValidation Recall: 0.3080\nValidation F1-score: 0.3067\nConfusion Matrix:\n[[59 56 24 36 25]\n [40 62 29 48 21]\n [33 46 46 49 26]\n [22 31 29 54 64]\n [21 18 32 42 87]]\nThe model may have high bias (underfitting). Consider increasing model complexity.\n","output_type":"stream"}]},{"cell_type":"code","source":"# # Put model in evaluation mode\n# classifier.eval() \n\n# # Tracking variables\n# predictions = []\n# actuals = []\n\n# # Evaluate on validation set\n# with torch.no_grad():\n#     for inputs, targets in val_loader:\n#         inputs = inputs.reshape(inputs.shape[0], -1).to(device)\n\n#         outputs = classifier(inputs)\n#         _, predicted = torch.max(outputs, 1)\n\n#         predictions.extend(predicted.tolist())\n#         actuals.extend(targets.tolist())\n\n# # Print predicted and actual values for all samples\n# #>> print(\"Predicted | Actual\")\n# #>>for pred, actual in zip(predictions, actuals):\n# #>>    pass #printd(f\"{pred} | {actual}\")\n\n# # Calculate validation accuracy\n# #>> 4/12/24 Maybe it would help to see how close we came in each category?\n# #>> For example, for category 5 predictions, show the actual results in each \n# #>> category. And where's there's a large disrepancy, show  the reviews.\n# r_by_category = [0,0,0,0,0]\n# r = list('12345')\n\n# for idx in range(5):\n#     r[idx] = r_by_category[:]\n\n# for p,a in zip(predictions, actuals):\n#     r[p-1][a-1] += 1 # Record the actual results for each category prediction\n\n# num_correct = 0\n# for idx in range (5):\n#     printv(f'Categrory {idx+1} predictions actual results: ' +\\\n#            f'1. {r[idx][0]}; 2. {r[idx][1]}; 3. {r[idx][2]}; 4. {r[idx][3]}; 5. {r[idx][4]}')\n#     num_correct += r[idx][idx]\n\n# # num_correct = sum([p == a for p, a in zip(predictions, actuals)]) \n# val_accuracy = num_correct / len(predictions)\n# print(f'Validation Accuracy: {val_accuracy:.2f}')","metadata":{"papermill":{"duration":0.381905,"end_time":"2024-04-07T06:44:38.725263","exception":false,"start_time":"2024-04-07T06:44:38.343358","status":"completed"},"tags":[],"jupyter":{"source_hidden":true},"trusted":true},"execution_count":null,"outputs":[]}]}