{
 "metadata": {
  "kernelspec": {
   "language": "python",
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.13",
   "mimetype": "text/x-python",
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "pygments_lexer": "ipython3",
   "nbconvert_exporter": "python",
   "file_extension": ".py"
  },
  "kaggle": {
   "accelerator": "gpu",
   "dataSources": [
    {
     "sourceId": 2415872,
     "sourceType": "datasetVersion",
     "datasetId": 1461623
    }
   ],
   "dockerImageVersionId": 30665,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook",
   "isGpuEnabled": true
  }
 },
 "nbformat_minor": 4,
 "nbformat": 4,
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "<h1 align=\"center\" style=\"color:blue;font-size: 3em;\" >Sentiment Analysis of Amazon Reviews using Transformers</h1>\n",
    "\n",
    "## This program is broken down into 3 sections:\n",
    "\n",
    "**1. We will work on data cleaning and preprocessing.**\n",
    "\n",
    "**2. We will then work on creating the sentiment analyzer and train it on the data we have preprocessed.**\n",
    "\n",
    "**3. Finally, we will evauate our model and visualize the results.**\n",
    "\n",
    "***Heads Up: Some of the cells might not have an output after they finish running. This is completely normal. You can always hover over the play button you click to run them and it will let you know if the cell has been executed and how long the process took. If there ever is an error, the cell will print out the stack trace and the issue it encountered.***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Let us begin by importing the necessary libraries\n",
    "\n",
    "***Heads Up: You might see a warning when importing the packages, but you may ignore this, as it won't cause any issues for our needs.***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# For viewing and manipulating data\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "\n",
    "# Importing the necessary libraries\n",
    "import re\n",
    "import math\n",
    "import string\n",
    "import nltk\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import gensim.downloader as api\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Getting particular functions from these libraries \n",
    "from torch import Tensor\n",
    "from sklearn.utils import resample\n",
    "from gensim.models import KeyedVectors\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from torch.utils.data import random_split, DataLoader, TensorDataset, Dataset\n",
    "\n",
    "# Using the NLTK to tokenize the text\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "\n",
    "# This Python 3 environment comes with many helpful analytics libraries installed\n",
    "# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n",
    "# For example, here's several helpful packages to load\n",
    "\n",
    "# Input data files are available in the read-only \"../input/\" directory\n",
    "# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n",
    "\n",
    "import os\n",
    "for dirname, _, filenames in os.walk('/kaggle/input'):\n",
    "    for filename in filenames:\n",
    "        print(os.path.join(dirname, filename))\n",
    "\n",
    "# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n",
    "# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\n",
    "VERBOSE = True\n",
    "def printv(text):\n",
    "    if VERBOSE: print('VERBOSE:', text)\n",
    "    return\n",
    "\n",
    "def showV(text):\n",
    "    '''unconditional verbose output'''\n",
    "    print('VERBOSE:', text)\n",
    "    return\n",
    "\n",
    "DEV = False # do not pring dev output\n",
    "def printd(text):\n",
    "    if DEV: print('DEV:', text)\n",
    "    return\n",
    "\n",
    "def showD(text):\n",
    "    #unconditional dev output#\n",
    "    print('DEV:', text)\n",
    "    return"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T19:32:17.467136Z",
     "iopub.execute_input": "2024-03-14T19:32:17.468087Z",
     "iopub.status.idle": "2024-03-14T19:32:35.126011Z",
     "shell.execute_reply.started": "2024-03-14T19:32:17.468045Z",
     "shell.execute_reply": "2024-03-14T19:32:35.124805Z"
    },
    "trusted": true
   },
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "text": "/kaggle/input/Reviews.csv\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**This magic command we are running below gives the notebook access to parts of the NLTK library. When ran correctly, it should unzip the wordnet file and copy over its contents.**\n",
    "\n",
    "**Please only run this command once when you start the notebook. If you run it again, it will prompt you to replace the existing files. After you run it once, you may comment it out. If you happen to run it again, and you are prompted for a response, simply stop the cell and move on to the next section.** \n"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "## Only run once\n",
    "#>> Seems to need to be rerun after every Kaggle timeout.\n",
    "!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T19:32:47.958250Z",
     "iopub.execute_input": "2024-03-14T19:32:47.958941Z",
     "iopub.status.idle": "2024-03-14T19:32:49.265632Z",
     "shell.execute_reply.started": "2024-03-14T19:32:47.958907Z",
     "shell.execute_reply": "2024-03-14T19:32:49.264651Z"
    },
    "trusted": true
   },
   "execution_count": 4,
   "outputs": [
    {
     "name": "stdout",
     "text": "Archive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Section 1: Data Cleaning and Preprocessing\n",
    "\n",
    "**One thing you will hear often when working with data is that preprocessing is the most important part. If the data is not cleaned and prepared for the model, you will always get sub-par results.**\n",
    "\n",
    "**The image below illustrate our goals for this section. It may look confusing now, but things will be clearer as we go through the section.**\n",
    "\n",
    "**For this project, we will be using over 568,000 reviews collected from Amazon. The cell below the image contains the code that will give us access to the dataset. You can also find the dataset linked here.**\n",
    "\n",
    "(Note that a word embedding is a representation of a word in an n-dimensonal vector space, n â‰¥ 2)\n",
    "\n",
    "[Amazon Reviews](https://www.kaggle.com/datasets/arhamrumi/amazon-product-reviews)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Example of Embeddings](https://www.researchgate.net/publication/340825443/figure/fig6/AS:882927785238529@1587517796128/Word-embeddings-map-words-in-a-corpus-of-text-to-vector-space-Linear-combinations-of.png)\n",
    "\n",
    "* Source: [Word embeddings map words in a corpus of text to vector space](https://figshare.com/articles/figure/Word_embeddings_map_words_in_a_corpus_of_text_to_vector_space_/12169047/1)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Let's access the dataset and see how many reviews we actually have.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Load data from CSV\n",
    "#>>  3/13 needed to change the path as below\n",
    "path ='/kaggle/input/Reviews.csv'#\"/kaggle/input/amazon-product-reviews/Reviews.csv\"\n",
    "data = pd.read_csv(path) # Use pandas to analyze data\n",
    "showD('Amazon reviews loaded into Panda')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T19:32:55.691347Z",
     "iopub.execute_input": "2024-03-14T19:32:55.692242Z",
     "iopub.status.idle": "2024-03-14T19:33:03.912540Z",
     "shell.execute_reply.started": "2024-03-14T19:32:55.692205Z",
     "shell.execute_reply": "2024-03-14T19:33:03.911574Z"
    },
    "trusted": true
   },
   "execution_count": 5,
   "outputs": [
    {
     "name": "stdout",
     "text": "DEV: Amazon reviews loaded into Panda\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**We can use the pandas object methods and fields to explore the Amazon reviews.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# print number of rows in our ratings column\n",
    "printv(f'Number of reviews: {len(data[\"Score\"])}')\n",
    "printv(f'Column names -\\n {data.columns}\\n') \n",
    "printv(f'First five rows -\\n{data.head()}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T19:33:23.859500Z",
     "iopub.execute_input": "2024-03-14T19:33:23.859893Z",
     "iopub.status.idle": "2024-03-14T19:33:23.869585Z",
     "shell.execute_reply.started": "2024-03-14T19:33:23.859862Z",
     "shell.execute_reply": "2024-03-14T19:33:23.868423Z"
    },
    "trusted": true
   },
   "execution_count": 7,
   "outputs": [
    {
     "name": "stdout",
     "text": "VERBOSE: Number of reviews: 568454\nVERBOSE: Column names -\n Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n      dtype='object')\n\nVERBOSE: First five rows -\n   Id   ProductId          UserId                      ProfileName  \\\n0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n\n   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n0                     1                       1      5  1303862400   \n1                     0                       0      1  1346976000   \n2                     1                       1      4  1219017600   \n3                     3                       3      2  1307923200   \n4                     0                       0      5  1350777600   \n\n                 Summary                                               Text  \n0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n2  \"Delight\" says it all  This is a confection that has been around a fe...  \n3         Cough Medicine  If you are looking for the secret ingredient i...  \n4            Great taffy  Great taffy at a great price.  There was a wid...  \n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**The data has 1O columns, including \"Score,\" indicating the review's sentiment, and \"Text,\" the product review the score is based on. In Machine Learning, Text would be called the FEATURE, the term for the column(s) used for inference.**\n",
    "\n",
    "\n",
    "**There is far too much data to print, but we can print the total number of reviews per rating and use the functions provided to us by matplotlib to visualize the distribution as a bar graph.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Get count of ratings \n",
    "rating_counts = data['Score'].value_counts()\n",
    "\n",
    "# Sort counts by index ascending\n",
    "rating_counts = rating_counts.sort_index()  \n",
    "\n",
    "# Print number of reviews per rating\n",
    "#for rating, count in rating_counts.items():\n",
    "#    print(f\"{count:,} reviews with a rating score of {rating}\", \"\\n\")\n",
    "\n",
    "# Get count of ratings\n",
    "#>> Seems to work even if we do not redefine rating_count\n",
    "#>> rating_counts = data['Score'].value_counts().sort_index() \n",
    "\n",
    "# Create bar plot\n",
    "ax = rating_counts.plot(kind = 'bar')\n",
    "\n",
    "ax.set_title(\"Ratings Distribution\")\n",
    "ax.set_xlabel(\"Rating\")\n",
    "ax.set_ylabel(\"Number of Occurrences\")\n",
    "\n",
    "# Fix x-axis tick labels\n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation = 0) \n",
    "\n",
    "for rating, count in rating_counts.items():\n",
    "        print(f\"{count:,} samples from balanced data with rating {rating}\\n\")\n",
    "\n",
    "plt.show() #<< show the rating in each of the 5 categories"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T19:33:36.706298Z",
     "iopub.execute_input": "2024-03-14T19:33:36.707006Z",
     "iopub.status.idle": "2024-03-14T19:33:37.064256Z",
     "shell.execute_reply.started": "2024-03-14T19:33:36.706974Z",
     "shell.execute_reply": "2024-03-14T19:33:37.063286Z"
    },
    "trusted": true
   },
   "execution_count": 8,
   "outputs": [
    {
     "name": "stdout",
     "text": "52,268 samples from balanced data with rating 1\n\n29,769 samples from balanced data with rating 2\n\n42,640 samples from balanced data with rating 3\n\n80,655 samples from balanced data with rating 4\n\n363,122 samples from balanced data with rating 5\n\n",
     "output_type": "stream"
    },
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**The distribution is heavily skewed to the positive side, with 5 star reviews making up more than half of our dataset. While that's great for Amazon and its customers, it could bias our model and starve it of adequate negative and neutral reviews to train on.**\n",
    "\n",
    "**To work around this we balance the data. 29,769 reviewers gave products a 2, the fewest for any rating, so that is the maximum numbers of reviews we can use in each category.  Fret not, that is still a vast amount of data to work with, but we may need to reduce it even futher during development to reduce the processing load.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "balanced_data_size = 1000 #<< number of reviews in each rating category\n",
    "# Specify the column for sorting and balancing\n",
    "sort_column = 'Score'  # This is one the rating column\n",
    "\n",
    "# Sort the data by the rating values\n",
    "sorted_data = data.sort_values(by = sort_column)\n",
    "\n",
    "# Create a balanced dataset with 25,000 samples from each class\n",
    "#balanced_data = sorted_data.groupby(sort_column).apply(lambda x: x.sample(n=25000))\n",
    "\n",
    "#>> DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. \n",
    "#>> This behavior is deprecated, and in a future version of pandas the grouping \n",
    "#>> columns will be excluded from the operation. \n",
    "#>> Either pass `include_groups=False` to exclude the groupings or \n",
    "#>> explicitly select the grouping columns after groupby to silence this warning.\n",
    "#\n",
    "balanced_data = sorted_data.groupby(sort_column).apply(lambda x: x.sample(n = balanced_data_size))\n",
    "\n",
    "#>> Does this mean to reset the row numbers?? ##Columns Numbers\n",
    "balanced_data.reset_index(drop = True, inplace = True)\n",
    "\n",
    "printv(f\"The number of reviews equally distributed across all ratings is {len(balanced_data['Score'])}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T19:33:51.828478Z",
     "iopub.execute_input": "2024-03-14T19:33:51.829142Z",
     "iopub.status.idle": "2024-03-14T19:33:52.104613Z",
     "shell.execute_reply.started": "2024-03-14T19:33:51.829110Z",
     "shell.execute_reply": "2024-03-14T19:33:52.103555Z"
    },
    "trusted": true
   },
   "execution_count": 9,
   "outputs": [
    {
     "name": "stdout",
     "text": "VERBOSE: The number of reviews equally distributed across all ratings is 5000\n",
     "output_type": "stream"
    },
    {
     "name": "stderr",
     "text": "/tmp/ipykernel_34/3150970972.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  balanced_data = sorted_data.groupby(sort_column).apply(lambda x: x.sample(n = balanced_data_size))\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**We can use matplotlib to see that reviews are equally distributed across all rating categories in the balanced data.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Get count of ratings\n",
    "rating_counts = balanced_data['Score'].value_counts()\n",
    "\n",
    "# Create bar plot\n",
    "ax = rating_counts.plot(kind='bar')\n",
    "\n",
    "ax.set_title(\"Ratings Distribution After Balancing\")\n",
    "ax.set_xlabel(\"Rating\")\n",
    "ax.set_ylabel(\"Number of Samples\")\n",
    "\n",
    "# Fix x-axis ticks  \n",
    "ax.set_xticklabels(ax.get_xticklabels(), rotation = 0)\n",
    "\n",
    "# Print number of reviews per rating\n",
    "\n",
    "if DEV:\n",
    "    for rating, count in rating_counts.items():\n",
    "        print(f\"{count:,} samples from balanced data with rating {rating}\\n\")\n",
    "\n",
    "plt.show()"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T19:34:02.027376Z",
     "iopub.execute_input": "2024-03-14T19:34:02.028222Z",
     "iopub.status.idle": "2024-03-14T19:34:02.292155Z",
     "shell.execute_reply.started": "2024-03-14T19:34:02.028185Z",
     "shell.execute_reply": "2024-03-14T19:34:02.291146Z"
    },
    "trusted": true
   },
   "execution_count": 10,
   "outputs": [
    {
     "output_type": "display_data",
     "data": {
      "text/plain": "<Figure size 640x480 with 1 Axes>",
      "image/png": "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"
     },
     "metadata": {}
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**That looks much better. We see that each rating class is sufficiently represented, and we can expect to get a more well-rounded analyzer. While this is a good way to even things out, our model can still be biased due to the reviews themselves. People leave comments when they have stronger opinions about a product. This is why balancing the types of reviews we give our model is necessary, so that the model can get a complete representation of the range of opinions**\n",
    "\n",
    "**We will also encounter things like typos, improper punctuation and spacing, along with other grammatical issues. While we will leave the dataset as is for now, it is important to try other approaches to identify these issues and filter them out.**\n",
    "\n",
    "**Now that we have our dataset ready, let's get to work on preprocessing it. Our reviews contain things like punctuations that we don't need to work with. To get rid of these, we use regular expressions to filter them out, and convert every character to lowercase to achieve uniformity.**\n",
    "\n",
    "**Something else we can do is a process called Lemmatization. This is the process of replacing variants of a word by the base word itself. An example of this would be to change the words knew, knowing, and known to their base word: know. This will help us achieve better uniformity by avoiding the misplacement of a word's variants.** <span style=\"color:blue\">Do you actually use the lemmatizer?"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "stop = stopwords.words('english') # Imported from nltk.corpus\n",
    "lem = WordNetLemmatizer()         # Imported from nltk.stem"
   ],
   "metadata": {
    "_kg_hide-input": true,
    "execution": {
     "iopub.status.busy": "2024-03-14T19:34:09.816897Z",
     "iopub.execute_input": "2024-03-14T19:34:09.817617Z",
     "iopub.status.idle": "2024-03-14T19:34:09.825828Z",
     "shell.execute_reply.started": "2024-03-14T19:34:09.817584Z",
     "shell.execute_reply": "2024-03-14T19:34:09.824928Z"
    },
    "trusted": true
   },
   "execution_count": 11,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "stop = sorted(stop) #it's easier to use if it's sorted\n",
    "showD (f'{stop}\\n')\n",
    "# No need printd (f'{lem}\\n')\n",
    "\n",
    "# test lemmatizer\n",
    "word = \"dogs\"\n",
    "lemmatized_word = lem.lemmatize(word)\n",
    "showD(f'The lemmatized version of \"{word}\" is \"{lemmatized_word}\".')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T19:34:38.797969Z",
     "iopub.execute_input": "2024-03-14T19:34:38.798355Z",
     "iopub.status.idle": "2024-03-14T19:34:38.804138Z",
     "shell.execute_reply.started": "2024-03-14T19:34:38.798326Z",
     "shell.execute_reply": "2024-03-14T19:34:38.803215Z"
    },
    "trusted": true
   },
   "execution_count": 13,
   "outputs": [
    {
     "name": "stdout",
     "text": "DEV: ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n\nDEV: The lemmatized version of \"dogs\" is \"dog\".\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Let's create a function that takes our reviews and returns a lemmanized, lower-case, punctuation-free version of it.** **We can then store this new version in a new column called 'CleanedReview' for easy access.**\n",
    "\n",
    "***Heads up: This cell takes a little longer to execute.***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Takes some time to run\n",
    "\n",
    "def tokenizer(text):\n",
    "    \"\"\"\n",
    "    Tokenizes a text string and removes stop words.\n",
    "\n",
    "    Args:\n",
    "        text (str): The text string to tokenize.\n",
    "\n",
    "    Returns:\n",
    "        list: The tokenized text string.\n",
    "    \"\"\"\n",
    "    text = text.lower()  # Convert text to lowercase.\n",
    "    text = re.sub(\"<.*?>\", \"\", text)  # Remove HTML tags.\n",
    "    text = re.sub('[^\\w\\s\\']+', \"\", text)  # Remove punctuation and symbols.\n",
    "    # text = text.split('\\n')  # Split text on new lines.\n",
    "    \n",
    "    #>> Have we decided not to use stop words?\n",
    "    text = [lem.lemmatize(word) for word in text.split()]#if word not in stop]  # Remove stop words. \n",
    "\n",
    "    return text\n",
    "\n",
    "# Apply the function to the Text column and store it in a new column\n",
    "balanced_data['CleanedReview'] = balanced_data['Text'].apply(tokenizer)\n",
    "\n",
    "# show that cell has finished executing\n",
    "showD(f'{tokenizer} defined, and then used to create CleanedReview column')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T19:34:51.165191Z",
     "iopub.execute_input": "2024-03-14T19:34:51.165952Z",
     "iopub.status.idle": "2024-03-14T19:34:53.745124Z",
     "shell.execute_reply.started": "2024-03-14T19:34:51.165920Z",
     "shell.execute_reply": "2024-03-14T19:34:53.743981Z"
    },
    "trusted": true
   },
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "text": "DEV: <function tokenizer at 0x7b018fa4f490> defined, and then used to create CleanedReview column\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Another look at the data after the addition of the CleanedReview column.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Store the Rating column\n",
    "rating = balanced_data['Score']  \n",
    "\n",
    "# Store the CleanedReview column\n",
    "tokenized_review = balanced_data['CleanedReview']\n",
    "showD(f'specify the columns that will be used to train the classifier')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T19:35:03.420640Z",
     "iopub.execute_input": "2024-03-14T19:35:03.421005Z",
     "iopub.status.idle": "2024-03-14T19:35:03.426687Z",
     "shell.execute_reply.started": "2024-03-14T19:35:03.420979Z",
     "shell.execute_reply": "2024-03-14T19:35:03.425693Z"
    },
    "trusted": true
   },
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "text": "DEV: specify the columns that will be used to train the classifier\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**We can see that our data now has 11 columns, with the addition of CleanReview, and that the CleanedReview column is the product review mapped to a sequence of standardized words.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**There are just a few more steps remaining before we can load the data. We have to tokenize the words from the reviews because neural networks, much like computers, don't really understand words. Instead, our tokenizer is going to associate every word with a number that can be used to look up the word's embeddings.**\n",
    "\n",
    "**Think of embeddings as vector representations of the word in space.**\n",
    "\n",
    "**There are many approaches we can take to vectorizing our reviews, so much so in fact that word embeddings are a big part of Natural Language Processing. Without getting too bogged down in details, some approaches use statistical approaches like bag-of-words to figure out context, and others can use neural network-based models that are trained to find features themselves.** \n",
    "\n",
    "**The quickest way would be to take an already trained tokenizer made for established transformer-based models. For example, the BertTokenizer is a tokenizer that was trained and used by BERT. BERT is a massive Transformer-based model created by Google in 2018. It was a significant achievement because it was able to perform up to 11 NLP tasks, including summarization, text-generation(think ChatGPT), and even sentiment analysis.**\n",
    "\n",
    "**Word2vec-google-news-300 is a pre-trained deep-learning word embedding model that was trained on a massive dataset of 100 billion words from the Google News corpus. The model contains 300-dimensional vectors for 3 million words and phrases. That is what we will be using for this project**\n",
    "\n",
    "**Word2Vec extracts both semantic and contextual representations of words. The semantic representation of a word captures the meaning of the word itself, while the contextual representation captures the meaning of the word in the context of the surrounding words.**\n",
    "\n",
    "**To explain what's happening in the Word2Vec embedding process:**\n",
    "\n",
    "1. **The tokenizer splits the raw text into tokens/words.**\n",
    "2. **Word2Vec has IDs that serve as indices into a lookup table that stores the vector representations, meaning that each ID corresponds to a unique vector representation in the table.**\n",
    "3. **For each token, we lookup the corresponding ID in the Word2Vec vocabulary using .key_to_index.**\n",
    "4. **This maps the tokens to existing Word2Vec IDs.**\n",
    "5. **We pass these IDs into the embedding layer.**\n",
    "6. **The embedding layer has a 300-dim vector for each ID.**\n",
    "7. **So each token gets replaced by its pre-trained 300-dim Word2Vec vector.**\n",
    "\n",
    "**To summarize:**\n",
    "\n",
    "* **Tokenizer splits text into words.**\n",
    "* **Word2Vec vocab provides ID for each word.**\n",
    "* **Embedding layer maps IDs to 300-dim vectors.**\n",
    "* **So tokens are replaced by 300-dim pretrained embeddings.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Let's start by downloading our word2vec model and set a variable we will use to limit the number of out tokens per review to 100 tokens. We will later zero-pad these reviews so we can have a uniform number of tokens per review.**\n",
    "\n",
    "\n",
    "***Heads up: This cell will take some time to execute.***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Load Word2Vec model\n",
    "w2v = api.load('word2vec-google-news-300')\n",
    "\n",
    "# Define the maximum sequence length (adjust as needed)\n",
    "#>> Will increasing max_sequence_length impact performance?\n",
    "max_sequence_length = 100\n",
    "\n",
    "showD(f'{w2v} can map words onto vectors with 300 dimensions')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T19:35:15.156269Z",
     "iopub.execute_input": "2024-03-14T19:35:15.156667Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": [
    {
     "name": "stdout",
     "text": "[--------------------------------------------------] 0.1% 1.2/1662.8MB downloaded",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Now that we have downloaded our model, let's use our CUDA-enabled GPU to take our token and look for its corresponding vector from our model. Once we find it, we swap it out with the new vector and if we don't, we pad that token with zeros.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Checks if a CUDA enabled GPU is available and prints out its information\n",
    "if torch.cuda.is_available():\n",
    "    print(\"CUDA is available!\")\n",
    "    for i in range(torch.cuda.device_count()):\n",
    "        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n",
    "        \n",
    "    device = torch.device(\"cuda:0\")\n",
    "\n",
    "else:\n",
    "    print(\"CUDA is not available.\")\n",
    "    device = torch.device(\"cpu\")"
   ],
   "metadata": {
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "**After ensuring that we have our GPUs available, we can go onto the next step. The code continues even if a CUDA is not available.**\n",
    "\n",
    "**In the cell below, we will do the following:**\n",
    "\n",
    "* **Create a new tensor and populate it with zeros**\n",
    "* **Compare the length of our review to the maximum length we allow (100) and take the minimum of the two**\n",
    "* **We lookup the token against what's in the w2v model. If we find it, we replace it with the embedding.**\n",
    "* **If we can't find it, we leave it as is (zero vectors).**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "***Heads Up: Cell below takes about 5 minutes to run***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Assume you have a list of tokenized review called tokenized_review\n",
    "# Each element in tokenized_review is a list of tokens for a single review\n",
    "\n",
    "# Initialize an empty tensor for padded reviews on the GPU\n",
    "padded_reviews = torch.zeros((len(tokenized_review), max_sequence_length, 300))#, device = device\n",
    "\n",
    "# Pad shorter reviews and convert tokens to Word2Vec embeddings\n",
    "for i, review_tokens in enumerate(tokenized_review):\n",
    "    review_length = min(len(review_tokens), max_sequence_length)\n",
    "    for j in range(review_length):\n",
    "        word = review_tokens[j]\n",
    "        if word in w2v:\n",
    "            # Use Word2Vec vector if available and move to GPU\n",
    "            padded_reviews[i, j, :] = torch.tensor(w2v[word])#, device = device\n",
    "        # Otherwise, it remains as zeros (padding)\n",
    "\n",
    "# Apply max pooling to aggregate embeddings along the sequence dimension\n",
    "# review_embeddings = torch.max(padded_reviews, dim=1)[0]\n",
    "\n",
    "# Now,review_embeddings contains the aggregated Word2Vec \n",
    "# embeddings for each review on the GPU\n",
    "\n",
    "print(\"Cell has finished!\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T08:55:55.783780Z",
     "iopub.execute_input": "2024-03-14T08:55:55.784125Z",
     "iopub.status.idle": "2024-03-14T08:56:02.988753Z",
     "shell.execute_reply.started": "2024-03-14T08:55:55.784097Z",
     "shell.execute_reply": "2024-03-14T08:56:02.987591Z"
    },
    "trusted": true
   },
   "execution_count": 24,
   "outputs": [
    {
     "name": "stdout",
     "text": "Cell has finished!\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Once we have our embeddings ready, we can prepare them as inputs for the model. The next step is to convert our inputs, now converted to embedding-rich vectors, to tensors. Tensors are a kind of data structure that store information in multidimensional space. They are a generalization of vectors and matrices, and can have any number of dimensions.**\n",
    "\n",
    "**Converting vectors to tensors is computationally expensive, which is one of the reasons why GPUs are the main processors used in AI. GPUs are specialized for performing parallel computations, which makes them ideal for tasks such as tensor conversion.**\n",
    "\n",
    "**But first, a quick introduction to PyTorch. PyTorch is a popular deep learning framework that provides a lot of resources for building deep learning architectures, including popular pretrained models. It has become prevalent in academia, research, and industry, being utilized by Tesla, Uber, Hugging Face, and many more.**\n",
    "\n",
    "**PyTorch will help us convert our vectors to tensors. It also support GPU acceleration. CUDA is a firmware developed by NVIDIA that allows GPUs to be used for general-purpose computing, such as tensor conversion.**\n",
    "\n",
    "**Once the embeddings have been converted to tensors, we can print out the dimensions of our new dataset. This will tell us how many data points we have and how many features each data point has. We can then load the dataset to our data loaders, which will prepare it for training the neural network.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Tensors](https://hkilter.com/images/7/7a/Tensors.png)\n",
    "\n",
    "* Source: [What is Tensor](https://hkilter.com/index.php?title=What_is_Tensor%3F)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**When we utilize tokenization and convert them to their embeddings, we are only doing this for one instance of them to avoid redundancy. So for example, if the word \"the\" appears 2000 times, it would only count once for unique tokens.**\n",
    "\n",
    "*Thus, a total of 39,753 unique tokens were converted to vectors and 9,373,966 was the total number of tokens including duplicates were converted into tensors and stored in our GPU.*\n",
    "\n",
    "**Since this Word2Vec model is trained on a huge corpus, it likely has vectors for the vast majority of tokens we extracted. The only ones missing would be very rare or irregular words.**\n",
    "\n",
    "***Note: It is imporant to remember that we are not just using this vocabulary as a look-up dictionary. That's just a small part of the step. What we are doing is far more advanced. The embeddings are rich contextual vectors that will highlight the relationships between words in different ways. For example, lexicographically speaking, the word 'car' is more similar to 'cat', but when viewed semantically, and/or in terms of its context, it is far more similar to 'dog'. Same goes for the word 'bank', which can be used to refer to a financial institution or the side of a river. These kinds of relationships are the foundation for our model and will serve as the basis for how it perceives them.***"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "print(torch.cuda.memory_summary())\n",
    "print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T08:56:35.673590Z",
     "iopub.execute_input": "2024-03-14T08:56:35.674305Z",
     "iopub.status.idle": "2024-03-14T08:56:35.680472Z",
     "shell.execute_reply.started": "2024-03-14T08:56:35.674271Z",
     "shell.execute_reply": "2024-03-14T08:56:35.679482Z"
    },
    "trusted": true
   },
   "execution_count": 26,
   "outputs": [
    {
     "name": "stdout",
     "text": "|===========================================================================|\n|                  PyTorch CUDA memory summary, device ID 0                 |\n|---------------------------------------------------------------------------|\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n|===========================================================================|\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n|---------------------------------------------------------------------------|\n| Allocated memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n|---------------------------------------------------------------------------|\n| Active memory         |      0 B   |      0 B   |      0 B   |      0 B   |\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n|---------------------------------------------------------------------------|\n| Requested memory      |      0 B   |      0 B   |      0 B   |      0 B   |\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n|---------------------------------------------------------------------------|\n| GPU reserved memory   |      0 B   |      0 B   |      0 B   |      0 B   |\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n|---------------------------------------------------------------------------|\n| Non-releasable memory |      0 B   |      0 B   |      0 B   |      0 B   |\n|       from large pool |      0 B   |      0 B   |      0 B   |      0 B   |\n|       from small pool |      0 B   |      0 B   |      0 B   |      0 B   |\n|---------------------------------------------------------------------------|\n| Allocations           |       0    |       0    |       0    |       0    |\n|       from large pool |       0    |       0    |       0    |       0    |\n|       from small pool |       0    |       0    |       0    |       0    |\n|---------------------------------------------------------------------------|\n| Active allocs         |       0    |       0    |       0    |       0    |\n|       from large pool |       0    |       0    |       0    |       0    |\n|       from small pool |       0    |       0    |       0    |       0    |\n|---------------------------------------------------------------------------|\n| GPU reserved segments |       0    |       0    |       0    |       0    |\n|       from large pool |       0    |       0    |       0    |       0    |\n|       from small pool |       0    |       0    |       0    |       0    |\n|---------------------------------------------------------------------------|\n| Non-releasable allocs |       0    |       0    |       0    |       0    |\n|       from large pool |       0    |       0    |       0    |       0    |\n|       from small pool |       0    |       0    |       0    |       0    |\n|---------------------------------------------------------------------------|\n| Oversize allocations  |       0    |       0    |       0    |       0    |\n|---------------------------------------------------------------------------|\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\n|===========================================================================|\n\nTotal allocated memory: 0 bytes\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#>> padded_reviews are 100 x 300 tensors, zero padded if necessary\n",
    "#>> to get the standard lenth\n",
    "text_embeddings_tensors = padded_reviews.to(device)\n",
    "\n",
    "# Rating labels\n",
    "rating_labels_tensors = torch.tensor(rating.values).to(device)\n",
    "\n",
    "# Dataset\n",
    "dataset = TensorDataset(text_embeddings_tensors, rating_labels_tensors)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T08:56:50.493336Z",
     "iopub.execute_input": "2024-03-14T08:56:50.494147Z",
     "iopub.status.idle": "2024-03-14T08:56:50.791600Z",
     "shell.execute_reply.started": "2024-03-14T08:56:50.494098Z",
     "shell.execute_reply": "2024-03-14T08:56:50.790699Z"
    },
    "trusted": true
   },
   "execution_count": 27,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\n",
    "!nvidia-smi\n",
    "print('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\n",
    "print(torch.cuda.memory_summary())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T08:56:57.626300Z",
     "iopub.execute_input": "2024-03-14T08:56:57.627003Z",
     "iopub.status.idle": "2024-03-14T08:56:58.867202Z",
     "shell.execute_reply.started": "2024-03-14T08:56:57.626974Z",
     "shell.execute_reply": "2024-03-14T08:56:58.865961Z"
    },
    "trusted": true
   },
   "execution_count": 28,
   "outputs": [
    {
     "name": "stdout",
     "text": "Total allocated memory: 600040448 bytes\nThu Mar 14 08:56:58 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla T4                       Off | 00000000:00:04.0 Off |                    0 |\n| N/A   39C    P0              26W /  70W |    679MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n|   1  Tesla T4                       Off | 00000000:00:05.0 Off |                    0 |\n| N/A   38C    P8               9W /  70W |      3MiB / 15360MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\n\n\n\n\n\n\n\n\n\n\n\n|===========================================================================|\n|                  PyTorch CUDA memory summary, device ID 0                 |\n|---------------------------------------------------------------------------|\n|            CUDA OOMs: 0            |        cudaMalloc retries: 0         |\n|===========================================================================|\n|        Metric         | Cur Usage  | Peak Usage | Tot Alloc  | Tot Freed  |\n|---------------------------------------------------------------------------|\n| Allocated memory      | 585977 KiB | 585977 KiB | 585977 KiB |      0 B   |\n|       from large pool | 585937 KiB | 585937 KiB | 585937 KiB |      0 B   |\n|       from small pool |     39 KiB |     39 KiB |     39 KiB |      0 B   |\n|---------------------------------------------------------------------------|\n| Active memory         | 585977 KiB | 585977 KiB | 585977 KiB |      0 B   |\n|       from large pool | 585937 KiB | 585937 KiB | 585937 KiB |      0 B   |\n|       from small pool |     39 KiB |     39 KiB |     39 KiB |      0 B   |\n|---------------------------------------------------------------------------|\n| Requested memory      | 585976 KiB | 585976 KiB | 585976 KiB |      0 B   |\n|       from large pool | 585937 KiB | 585937 KiB | 585937 KiB |      0 B   |\n|       from small pool |     39 KiB |     39 KiB |     39 KiB |      0 B   |\n|---------------------------------------------------------------------------|\n| GPU reserved memory   | 589824 KiB | 589824 KiB | 589824 KiB |      0 B   |\n|       from large pool | 587776 KiB | 587776 KiB | 587776 KiB |      0 B   |\n|       from small pool |   2048 KiB |   2048 KiB |   2048 KiB |      0 B   |\n|---------------------------------------------------------------------------|\n| Non-releasable memory |   3847 KiB |   3847 KiB |   3847 KiB |      0 B   |\n|       from large pool |   1838 KiB |   1838 KiB |   1838 KiB |      0 B   |\n|       from small pool |   2008 KiB |   2008 KiB |   2008 KiB |      0 B   |\n|---------------------------------------------------------------------------|\n| Allocations           |       2    |       2    |       2    |       0    |\n|       from large pool |       1    |       1    |       1    |       0    |\n|       from small pool |       1    |       1    |       1    |       0    |\n|---------------------------------------------------------------------------|\n| Active allocs         |       2    |       2    |       2    |       0    |\n|       from large pool |       1    |       1    |       1    |       0    |\n|       from small pool |       1    |       1    |       1    |       0    |\n|---------------------------------------------------------------------------|\n| GPU reserved segments |       2    |       2    |       2    |       0    |\n|       from large pool |       1    |       1    |       1    |       0    |\n|       from small pool |       1    |       1    |       1    |       0    |\n|---------------------------------------------------------------------------|\n| Non-releasable allocs |       2    |       2    |       2    |       0    |\n|       from large pool |       1    |       1    |       1    |       0    |\n|       from small pool |       1    |       1    |       1    |       0    |\n|---------------------------------------------------------------------------|\n| Oversize allocations  |       0    |       0    |       0    |       0    |\n|---------------------------------------------------------------------------|\n| Oversize GPU segments |       0    |       0    |       0    |       0    |\n|===========================================================================|\n\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Our output confirms that we have successfully converted our data to tensors and is now loaded on our GPU. The output shows that CUDA is available and the GPU name is Tesla P100-PCIE-16GB. The text_tensor and rating_tensor are both on the GPU (device='cuda:0'). The shape of the text_tensor is torch.Size([125000, 100, 300]), which means that it has 125000 rows, 100 columns, with 300 embeddings per column. The shape of the rating_tensor is torch.Size([125000]), which means that it has 125000 rows (ratings). The mean of the rating_tensor is 3 meaning that the we have perfectly divided all our ratings.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![numeric_tensors](https://miro.medium.com/v2/resize:fit:1400/1*Shsgt3h9yxlQwjkfIptfYQ.png)\n",
    "\n",
    "* Source: [From Vectors to Tensors: Exploring the Mathematics of Tensor Algebra](https://towardsdatascience.com/what-are-tensors-in-machine-learning-5671814646ff)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**We can now split our dataset into training and validation sets. When working on machine learning or deep learning models, we want to train the model on a subset of the data, and then test the accuracy of the model's predictions on the remaining data. This is called data splitting. We typically split the data into an 80/20 split, where we train the model on 80% of the data and test it on the remaining 20%.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**And there we have it! It looks like we have successfully split our data 80/20, and are now going to load the tensors in batches to our training and validation loaders. We will use these to load our data into the model once we have finished building it. We have also stored the data in batches of 32. This will make it easier to process the data instead of dealing with the whole thing at once. To confirm that it is all loaded, we can see that the number of batches, 3,125, multiplied by the batch size, 32, will indeed return 125,000**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**We have successfully completed the preprocessing, splitting, and loading of our data. This section may have felt overwhelming, but it is important to remember that preparing the data properly is just as important as building the model. In fact, it is often said that 80% of the work in machine learning is in data preparation. This is because the quality of the data will have a significant impact on the performance of the model.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**And now for the really exciting part: the Transformer, the T in Chat-GPT. Arguably one of the most impactful architectures in recent history, the Transformer has been the state of the art in natural language processing (NLP) and other sequence-to-sequence tasks. In this section, we will break down and build on the individual components of this architecture, and use it to create our sentiment analyzer.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Section 2: The Sentiment Analyzer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Detailed Architecture Diagram](https://lena-voita.github.io/resources/lectures/seq2seq/transformer/model-min.png)\n",
    "\n",
    "* Source: [Sequence to Sequence (seq2seq) and Attention](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Above is a diagram of what the Transformer architecture looks like. It might look complicated, but each cell will work on one component of the layer so we can isolate and understand the various sections of our model.**\n",
    "\n",
    "***Heads Up: Since we are building a sentiment analyzer, we will not be generating any outputs. Instead we will just use a simple classifier to make our classifications. Thus, we will not be using the decoder layer (the longer section on the right side of the diagram). But do note that, while most of the components are indeed similar, the two layers function somewhat differently.***\n",
    "\n",
    "## Here is a quick rundown of what our Transformer model will contain the following:\n",
    "\n",
    "## 1. Embedding Layer:\n",
    "\n",
    "### a. Word Embeddings: \n",
    "**These are the learned dense vectors that represent each word in \n",
    "your vocabulary. These vectors capture the semantic meaning of words. Of course, for our use case, we are utilizing the embeddings from word2vec**\n",
    "\n",
    "### b. Positional Encodings: \n",
    "**These are vectors that encode the position of each word in the \n",
    "sequence. They help the attention mechanism also take the positoning of the words when factoring in the attention scores.**\n",
    "\n",
    "## 2. Encoder Layer:\n",
    "\n",
    "### a. Multi-Head Attention: \n",
    "**This mechanism allows the model to attend to different parts of the\n",
    "input sequence while capturing various relationships between words.**\n",
    "\n",
    "### b. Addition (Residual) and Normalization Layer: \n",
    "**After multi-head attention, you typically have a residual connection \n",
    "(addition) followed by layer normalization. This helps with stable \n",
    "training and information flow.**\n",
    "\n",
    "### c. Feed-Forward Neural Network (Pointwise Feed-Forward Layer): \n",
    "**This network applies a simple feed-forward transformation to each \n",
    "position separately, allowing the model to capture non-linear \n",
    "relationships between words.**\n",
    "\n",
    "## 3. Classifier Layer:\n",
    "\n",
    "### a. Linear Layer: \n",
    "**This layer maps the output of the encoder to the number of classes \n",
    "you have in your sentiment analysis task. For example, if you have \n",
    "three sentiment classes (negative, neutral, positive), this layer\n",
    "will output logits for each class.**\n",
    "\n",
    "### b. Softmax Activation: \n",
    "**This activation function is applied to the logits to convert them \n",
    "into probabilities for each class. It makes the model's output \n",
    "interpretable as class probabilities.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**When following the diagram as a pipeline, we see that the first thing we do with the inputs is include the embedding. The embedding is layer involves replacing the tokens from our reviews with their vectors. SInce we have used Word2Vec to create the embeddings from our tokens, we just need may proceed to the next step.** **The next step in our diagram is the Positional Encoding. This is a clever approach that the creaters of the Transformer architecture utilized to include even more information into our input embeddings. While the first set of vectors helped give our tokens their contextual vectors, the positional encoder assigns a sin or cosine value to these vectors depending on whether they are located in odd of even positions. This adds to our vectors by highlighting the location of the token on top of its meaning, thus further enriching the information it carries.**\n",
    "\n",
    "**We will wrap all this up in one function and call that Embeddings.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "**Now we delve into what truly makes the Transformer architecture exceptional: the Attention mechanism. This mechanism, often referred to as self-attention, has been a transformative development in NLP. It serves as a way to allocate \"focus\" or \"attention\" values to the different embedded vectors that pass through the model's embedding layer. This allocation is achieved by segmenting the input vectors into three key components: queries, keys, and values.**\n",
    "\n",
    "**The process begins with the transformation of the input embeddings into three distinct matrices: the Query matrix (Q), Key matrix (K), and Value matrix (V). These matrices are obtained through linear transformations of the original embeddings.**\n",
    "\n",
    "**The heart of the attention mechanism involves calculating dot products between the Query matrix and the Transposed Key matrix. The resulting dot products are then scaled by the square root of the dimension of the key vectors. This scaling factor plays a crucial role in maintaining stable gradients during training.**\n",
    "\n",
    "**The next step in the process employs a softmax operation on the scaled dot products. The softmax function normalizes the values, converting them into attention weights. These attention weights indicate the \"importance\" or \"weight\" assigned to each word in relation to the others. The summation of the attention weights for each query-key pair ensures that the model focuses on the most relevant information.**\n",
    "\n",
    "**The weighted sum of the Value matrix, determined by the attention weights, generates an attended representation. In essence, the attention mechanism enables the model to capture the contextual relationships between words, determining how much each word contributes to the overall understanding of the sequence.**\n",
    "\n",
    "**One innovation that distinguishes the Transformer architecture is multi-head attention. Instead of relying on a single attention mechanism, multiple parallel attention mechanisms, or \"heads,\" are employed. Each head attends to the input independently and learns different aspects of the relationships between words. The outputs of the different heads are concatenated and linearly transformed, resulting in a comprehensive representation that encompasses various perspectives on the input data.**\n",
    "\n",
    "**Example:**\n",
    "\n",
    "**Consider the sentence: \"Diana wanted to visit Seattle in the Winter, but was ill-prepared for the cold, Pacific Northwest weather.\"**\n",
    "\n",
    "**In this sentence, the attention mechanism discerns connections between words, prioritizing specific words when analyzing others. For instance, in the context of \"visit Seattle,\" the word \"Seattle\" would attract more attention when considering the word \"visit.\" Similarly, the words \"ill-prepared\" and \"cold\" would stand out in the presence of the term \"Winter.\"**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Positional Encoding"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# pytorch implementation\n",
    "\n",
    "class PositionalEncoding(nn.Module):\n",
    "\n",
    "    def __init__(self, d_model: int, dropout: float, seq_len: int):\n",
    "        super().__init__()\n",
    "        self.dropout = nn.Dropout(p = dropout)\n",
    "\n",
    "        position = torch.arange(seq_len).unsqueeze(1)\n",
    "        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n",
    "        pe = torch.zeros(seq_len, 1, d_model)\n",
    "        pe[:, 0, 0::2] = torch.sin(position * div_term)\n",
    "        pe[:, 0, 1::2] = torch.cos(position * div_term)\n",
    "        self.register_buffer('pe', pe)\n",
    "\n",
    "    def forward(self, x: Tensor) -> Tensor:\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n",
    "        \"\"\"\n",
    "        x = x + self.pe[:x.size(0)]\n",
    "        return self.dropout(x)\n",
    "\n",
    "#>> Show what happened\n",
    "printd(f'{PositionalEncoding} defined')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T09:00:06.700004Z",
     "iopub.execute_input": "2024-03-14T09:00:06.700424Z",
     "iopub.status.idle": "2024-03-14T09:00:06.710586Z",
     "shell.execute_reply.started": "2024-03-14T09:00:06.700393Z",
     "shell.execute_reply": "2024-03-14T09:00:06.709559Z"
    },
    "trusted": true
   },
   "execution_count": 31,
   "outputs": [
    {
     "name": "stdout",
     "text": "DEV: <class '__main__.PositionalEncoding'> defined\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "![image.png](attachment:dcbbcd14-b671-403b-903f-86a9c94add2b.png)\n",
    "\n",
    "* Source: [Transformer Tutorial - Tensorflow](https://www.tensorflow.org/text/tutorials/transformer)"
   ],
   "metadata": {},
   "attachments": {
    "dcbbcd14-b671-403b-903f-86a9c94add2b.png": {
     "image/png": "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"
    }
   }
  },
  {
   "cell_type": "code",
   "source": [
    "def scaled_dot_product_attention(query, key, value, attn_mask = None, dropout_p = float, is_causal = False, scale = None) -> torch.Tensor:\n",
    "    # Efficient implementation equivalent to the following:\n",
    "    L, S = query.size(-2), key.size(-2)\n",
    "    scale_factor = 1 / math.sqrt(query.size(-1)) if scale is None else scale\n",
    "    attn_bias = torch.zeros(L, S, dtype=query.dtype).to(device)\n",
    "    if is_causal:\n",
    "        assert attn_mask is None\n",
    "        temp_mask = torch.ones(L, S, dtype=torch.bool).tril(diagonal = 0)\n",
    "        attn_bias.masked_fill_(temp_mask.logical_not(), float(\"-inf\"))\n",
    "        attn_bias.to(query.dtype)\n",
    "\n",
    "    if attn_mask is not None:\n",
    "        if attn_mask.dtype == torch.bool:\n",
    "            attn_mask.masked_fill_(attn_mask.logical_not(), float(\"-inf\"))\n",
    "        else:\n",
    "            attn_bias += attn_mask\n",
    "    attn_weight = query @ key.transpose(-2, -1) * scale_factor\n",
    "    attn_weight += attn_bias\n",
    "    attn_weight = torch.softmax(attn_weight, dim =- 1)\n",
    "    attn_weight = torch.dropout(attn_weight, dropout_p, train = True)\n",
    "    return attn_weight @ value\n",
    "\n",
    "#>> Show what happened\n",
    "printd(f'{scaled_dot_product_attention} defined')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-14T09:01:25.750195Z",
     "iopub.execute_input": "2024-03-14T09:01:25.750525Z",
     "iopub.status.idle": "2024-03-14T09:01:25.761080Z",
     "shell.execute_reply.started": "2024-03-14T09:01:25.750503Z",
     "shell.execute_reply": "2024-03-14T09:01:25.760120Z"
    },
    "trusted": true
   },
   "execution_count": 33,
   "outputs": [
    {
     "name": "stdout",
     "text": "DEV: <function scaled_dot_product_attention at 0x7aadf11f7d90> defined\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Attention + Multi-head"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class MultiHeadedAttention(nn.Module):\n",
    "    def __init__(self, h, d_model, dropout = 0.1):\n",
    "        super().__init__()\n",
    "\n",
    "        self.h = h\n",
    "        self.d_k = d_model // h\n",
    "        self.attention_heads = [nn.Linear(d_model, d_model // h).to(device) for _ in range(self.h)]\n",
    "\n",
    "        \n",
    "    def forward(self, query, key, value, attn_mask = None, dropout_p=0.0):\n",
    "        attention_outputs = []\n",
    "        for attention_head in self.attention_heads:\n",
    "            attention_output = scaled_dot_product_attention(\n",
    "                attention_head(query),\n",
    "                attention_head(key),\n",
    "                attention_head(value),\n",
    "                attn_mask = attn_mask,\n",
    "                dropout_p = dropout_p,\n",
    "            )\n",
    "            attention_outputs.append(attention_output)\n",
    "            \n",
    "        seq_len = query.size(1)\n",
    "        attention_output = torch.cat(attention_outputs, dim =- 1).view(query.size(0), seq_len, d_model)\n",
    "        return attention_output"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:30.116825Z",
     "iopub.execute_input": "2024-03-10T23:07:30.117235Z",
     "iopub.status.idle": "2024-03-10T23:07:30.127220Z",
     "shell.execute_reply.started": "2024-03-10T23:07:30.117200Z",
     "shell.execute_reply": "2024-03-10T23:07:30.126204Z"
    },
    "trusted": true
   },
   "execution_count": 30,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "![Self-Attention Diagram](https://lena-voita.github.io/resources/lectures/seq2seq/transformer/qkv_explained-min.png)\n",
    "\n",
    "![Components of Self-Attention](https://lena-voita.github.io/resources/lectures/seq2seq/transformer/qkv_attention_formula-min.png)\n",
    "\n",
    "* Source: [Sequence to Sequence (seq2seq) and Attention](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Add/Residual layer + Normalization Layer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "def add_layer(x, y):\n",
    "    \"\"\"Adds two tensors together.\n",
    "\n",
    "    Args:\n",
    "    x: A torch.Tensor of shape (batch_size, seq_len, hidden_size).\n",
    "    y: A torch.Tensor of the same shape as x.\n",
    "\n",
    "    Returns:\n",
    "    A torch.Tensor of the same shape as x and y, containing the sum of the two tensors.\n",
    "    \"\"\"\n",
    "\n",
    "    return torch.add(x, y)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:30.128678Z",
     "iopub.execute_input": "2024-03-10T23:07:30.129077Z",
     "iopub.status.idle": "2024-03-10T23:07:30.140994Z",
     "shell.execute_reply.started": "2024-03-10T23:07:30.129041Z",
     "shell.execute_reply": "2024-03-10T23:07:30.140014Z"
    },
    "trusted": true
   },
   "execution_count": 31,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class LayerNorm(nn.Module):\n",
    "    \"Construct a layernorm module (See citation for details).\"\n",
    "\n",
    "    def __init__(self, features, eps = float):\n",
    "        super(LayerNorm, self).__init__()\n",
    "        self.a_2 = nn.Parameter(torch.ones(features))\n",
    "        self.b_2 = nn.Parameter(torch.zeros(features))\n",
    "        self.eps = eps\n",
    "\n",
    "    def forward(self, x):\n",
    "        mean = x.mean(-1, keepdim = True)\n",
    "        std = x.std(-1, keepdim = True)\n",
    "        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:30.142187Z",
     "iopub.execute_input": "2024-03-10T23:07:30.142486Z",
     "iopub.status.idle": "2024-03-10T23:07:30.152030Z",
     "shell.execute_reply.started": "2024-03-10T23:07:30.142444Z",
     "shell.execute_reply": "2024-03-10T23:07:30.150893Z"
    },
    "trusted": true
   },
   "execution_count": 32,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Position-wise Feed Forward Network"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class PositionwiseFeedForward(nn.Module):\n",
    "    def __init__(self, d_model: int, d_ffn: int, dropout: float):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            d_model:      dimension of embeddings\n",
    "            d_ffn:        dimension of feed-forward network\n",
    "            dropout:      probability of dropout occurring\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "\n",
    "        self.w_1 = nn.Linear(d_model, d_ffn)\n",
    "        self.w_2 = nn.Linear(d_ffn, d_model)\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            x:            output from attention (batch_size, seq_length, d_model)\n",
    "\n",
    "        Returns:\n",
    "            expanded-and-contracted representation (batch_size, seq_length, d_model)\n",
    "        \"\"\"\n",
    "        \n",
    "        return self.w_2(self.dropout(self.w_1(x).relu()))"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:30.153202Z",
     "iopub.execute_input": "2024-03-10T23:07:30.153483Z",
     "iopub.status.idle": "2024-03-10T23:07:30.162586Z",
     "shell.execute_reply.started": "2024-03-10T23:07:30.153453Z",
     "shell.execute_reply": "2024-03-10T23:07:30.161476Z"
    },
    "trusted": true
   },
   "execution_count": 33,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Hyperparameters"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# HyperParameters for the module\n",
    "d_model = 300  # Should match the embedding dimension of your word embeddings\n",
    "seq_len = 100  # Maximum sequence length\n",
    "dropout = 0.1  # Adjust the dropout if needed\n",
    "\n",
    "h       = 4    # number of attention head\n",
    "num_heads = 4    # number of attention head\n",
    "\n",
    "d_ffn   = 1024 # dimension of the feedforward layer\n",
    "eps     = 1e-6 # epsilon value to prevent the standard deviation from becoming zero\n",
    "num_classes = 5  # Replace with your number of classes\n",
    "epochs = 100\n",
    "learning_rate = 0.01\n",
    "num_layers = 6\n",
    "\n",
    "input_size = d_model  # Adjust this based on the output size of your feed-forward network\n",
    "# input_size = len(train_data[0])  # Adjust based on your input size (should match the output size of your model)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:30.163818Z",
     "iopub.execute_input": "2024-03-10T23:07:30.164100Z",
     "iopub.status.idle": "2024-03-10T23:07:30.176604Z",
     "shell.execute_reply.started": "2024-03-10T23:07:30.164076Z",
     "shell.execute_reply": "2024-03-10T23:07:30.175485Z"
    },
    "trusted": true
   },
   "execution_count": 34,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!nvidia-smi\n",
    "#print('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\n",
    "#print(torch.cuda.memory_summary())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:30.177823Z",
     "iopub.execute_input": "2024-03-10T23:07:30.178121Z",
     "iopub.status.idle": "2024-03-10T23:07:31.285811Z",
     "shell.execute_reply.started": "2024-03-10T23:07:30.178097Z",
     "shell.execute_reply": "2024-03-10T23:07:31.284507Z"
    },
    "trusted": true
   },
   "execution_count": 35,
   "outputs": [
    {
     "name": "stdout",
     "text": "Sun Mar 10 23:07:31 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n| N/A   39C    P0              32W / 250W |    832MiB / 16384MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Encoder Layer"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class StackedEncoder(nn.Module):\n",
    "    def __init__(self, num_layers, d_model, seq_len, dropout, num_heads, d_ffn):\n",
    "        super(StackedEncoder, self).__init__()\n",
    "\n",
    "        self.layers = nn.ModuleList([\n",
    "            EncoderLayer(d_model, seq_len, dropout, num_heads, d_ffn) for _ in range(num_layers)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        for layer in self.layers:\n",
    "            x = layer(x)\n",
    "        return x\n",
    "\n",
    "class EncoderLayer(nn.Module):\n",
    "    def __init__(self, d_model, seq_len, dropout, num_heads, d_ffn):\n",
    "        super().__init__()\n",
    "\n",
    "        self.positional_encoding = PositionalEncoding(d_model, dropout, seq_len)\n",
    "        self.multihead_attention = MultiHeadedAttention(num_heads, d_model, dropout)\n",
    "        self.norm1 = LayerNorm(d_model, eps)\n",
    "        self.feed_forward = PositionwiseFeedForward(d_model, d_ffn, dropout)\n",
    "        self.norm2 = LayerNorm(d_model, eps)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x_pe = self.positional_encoding(x)\n",
    "        attn_output = self.multihead_attention(x_pe, x_pe, x_pe)\n",
    "        x_attn = x + attn_output # Residual connection from multi-head attention\n",
    "        x_norm1 = self.norm1(x_attn)\n",
    "        ff_output = self.feed_forward(x_norm1)\n",
    "        x_ff = x_attn + ff_output # Residual connection from feed-forward network\n",
    "        x_norm2 = self.norm2(x_ff)\n",
    "\n",
    "        return x_norm2 # Return the normalized output"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:31.287614Z",
     "iopub.execute_input": "2024-03-10T23:07:31.287967Z",
     "iopub.status.idle": "2024-03-10T23:07:31.298744Z",
     "shell.execute_reply.started": "2024-03-10T23:07:31.287936Z",
     "shell.execute_reply": "2024-03-10T23:07:31.297771Z"
    },
    "trusted": true
   },
   "execution_count": 36,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "# Encoder Test"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "###################################### TEST ##########################################\n",
    "###################################### TEST ##########################################\n",
    "###################################### TEST ##########################################\n",
    "\n",
    "##################################### hyperparam #####################################\n",
    "##################################### hyperparam #####################################\n",
    "##################################### hyperparam #####################################\n",
    "\n",
    "# HyperParameters for the module\n",
    "d_model = 300  # Should match the embedding dimension of your word embeddings\n",
    "seq_len = 100  # Maximum sequence length\\ndropout = 0.1  # You can adjust the dropout if needed\n",
    "h       = 4    # number of attention head\\nd_ffn   = 1024 # dimension of the feedforward layer\n",
    "eps     = 1e-6 # epsilon value to prevent the standard deviation from becoming zero\n",
    "num_classes = 3  # Replace with your number of classes\n",
    "input_size = d_model  # Adjust this based on the output size of your feed-forward network\\n\\n\n",
    "epochs = 10\n",
    "learning_rate = 0.01\n",
    "\n",
    "## Dropout - During training, randomly zeroes some of the elements of the input\n",
    "## tensor with probability p using samples from a Bernoulli distribution. Each\n",
    "## channel will be zeroed out independently on every forward call.\n",
    "\n",
    "###################################### embedding #####################################\n",
    "###################################### embedding #####################################\n",
    "###################################### embedding #####################################\n",
    "\n",
    "word_embeddings = torch.randn(32, 100, 300).to(device)\n",
    "\n",
    "print (f\"Word Embedding Shape: {word_embeddings.size}\")\n",
    "print (f\"Word Embedding Shape: {word_embeddings.shape}\")\n",
    "print(f\"The Word Embeddings are on: {word_embeddings.device}\")\n",
    "print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\n",
    "!nvidia-smi\n",
    "      \n",
    "####################################### p.e. #########################################\n",
    "####################################### p.e. #########################################\n",
    "####################################### p.e. #########################################\n",
    "\n",
    "# Instantiate the PositionalEncoding module\n",
    "positional_encoder = PositionalEncoding(d_model, dropout, seq_len).to(device)\n",
    "\n",
    "# Apply the positional encoding to your word embeddings\n",
    "encoded_embeddings = positional_encoder(word_embeddings)\n",
    "      \n",
    "# Print the dimensions of the encoded embeddings\n",
    "print(f\"Encoded Embeddings Shape: {encoded_embeddings.shape}\")\n",
    "print(f\"The Encoded Embeddings are on: {encoded_embeddings.device}\")\n",
    "print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\n",
    "!nvidia-smi\n",
    "    \n",
    "####################################### attn ##########################################\n",
    "####################################### attn ##########################################\n",
    "####################################### attn ##########################################\n",
    "      \n",
    "# Create an instance of the MultiHeadedAttention class\n",
    "multi_head_attention = MultiHeadedAttention(h, d_model, dropout).to(device)\n",
    "      \n",
    "# Define your query, key, and value tensors (they can be the same for self-attention)\n",
    "query = encoded_embeddings.to(device)\n",
    "key = encoded_embeddings.to(device)\n",
    "value = encoded_embeddings.to(device)\n",
    "\n",
    "print(f\"The Query Tensor is on: {query.device}\")\n",
    "print(f\"The Key Tensor is on: {key.device}\")\n",
    "print(f\"The Value Tensor is on: {value.device}\")\n",
    "\n",
    "# Optional: Define an attention mask or use None if not needed\n",
    "attn_mask = None\n",
    "\n",
    "# Apply the MultiHeadedAttention\\n\n",
    "attention_output = multi_head_attention(query, key, value, attn_mask = attn_mask)\n",
    "\n",
    "# Print the dimensions of the attention output\\n\n",
    "print(f\"Attention Output Shape: {attention_output.shape}\")\n",
    "print(f\"The Attention Output is on: {attention_output.device}\")\n",
    "print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\n",
    "!nvidia-smi\n",
    "\n",
    "######################################## add ##########################################\n",
    "######################################## add ##########################################\n",
    "######################################## add ##########################################\n",
    "\n",
    "residual_connection = add_layer(attention_output, encoded_embeddings)\n",
    "\n",
    "print(f\"Residual Connection Shape: {residual_connection.shape}\")\n",
    "print(f\"The Residual Connection is on: {residual_connection.device}\")\n",
    "print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\n",
    "!nvidia-smi\n",
    "\n",
    "######################################## norm #########################################\n",
    "######################################## norm #########################################\n",
    "######################################## norm #########################################\n",
    "\n",
    "norm = LayerNorm(d_model, eps).to(device)\n",
    "normalized_values = norm(residual_connection)\n",
    "      \n",
    "print(f\"Normalized Values Shape: {normalized_values.shape}\")\n",
    "print(f\"The Normalized Values are on: {normalized_values.device}\")\n",
    "print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\n",
    "!nvidia-smi\n",
    "\n",
    "######################################## fc ##########################################\n",
    "######################################## fc ##########################################\n",
    "######################################## fc ##########################################\n",
    "      \n",
    "feedforward = PositionwiseFeedForward(d_model, d_ffn, dropout).to(device)\n",
    "ff_output = feedforward(normalized_values)\n",
    "\n",
    "print(f\"FF Output Shape: {ff_output.shape}\")\n",
    "print(f\"The Output is on: {ff_output.device}\")\n",
    "print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\n",
    "!nvidia-smi"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:31.300481Z",
     "iopub.execute_input": "2024-03-10T23:07:31.300866Z",
     "iopub.status.idle": "2024-03-10T23:07:38.293061Z",
     "shell.execute_reply.started": "2024-03-10T23:07:31.300830Z",
     "shell.execute_reply": "2024-03-10T23:07:38.291954Z"
    },
    "trusted": true
   },
   "execution_count": 37,
   "outputs": [
    {
     "name": "stdout",
     "text": "Word Embedding Shape: <built-in method size of Tensor object at 0x7c2586f2cf40>\nWord Embedding Shape: torch.Size([32, 100, 300])\nThe Word Embeddings are on: cuda:0\nTotal allocated memory: 603880448 bytes\nSun Mar 10 23:07:32 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n| N/A   39C    P0              32W / 250W |    852MiB / 16384MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\nEncoded Embeddings Shape: torch.Size([32, 100, 300])\nThe Encoded Embeddings are on: cuda:0\nTotal allocated memory: 607840768 bytes\nSun Mar 10 23:07:33 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n| N/A   39C    P0              32W / 250W |    882MiB / 16384MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\nThe Query Tensor is on: cuda:0\nThe Key Tensor is on: cuda:0\nThe Value Tensor is on: cuda:0\nAttention Output Shape: torch.Size([32, 100, 300])\nThe Attention Output is on: cuda:0\nTotal allocated memory: 638737408 bytes\nSun Mar 10 23:07:34 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n| N/A   39C    P0              32W / 250W |    928MiB / 16384MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\nResidual Connection Shape: torch.Size([32, 100, 300])\nThe Residual Connection is on: cuda:0\nTotal allocated memory: 642577408 bytes\nSun Mar 10 23:07:35 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n| N/A   39C    P0              32W / 250W |    928MiB / 16384MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\nNormalized Values Shape: torch.Size([32, 100, 300])\nThe Normalized Values are on: cuda:0\nTotal allocated memory: 654126080 bytes\nSun Mar 10 23:07:37 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n| N/A   39C    P0              32W / 250W |    948MiB / 16384MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\nFF Output Shape: torch.Size([32, 100, 300])\nThe Output is on: cuda:0\nTotal allocated memory: 690668032 bytes\nSun Mar 10 23:07:38 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n| N/A   39C    P0              32W / 250W |    982MiB / 16384MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "**We can now split our dataset into training and validation sets. When working on machine learning or deep learning models, we want to train the model on a subset of the data, and then test the accuracy of the model's predictions on the remaining data. This is called data splitting. We typically split the data into an 80/20 split, where we train the model on 80% of the data and test it on the remaining 20%.**"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\n",
    "!nvidia-smi\n",
    "#print('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\n",
    "#print(torch.cuda.memory_summary())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:38.300083Z",
     "iopub.execute_input": "2024-03-10T23:07:38.300437Z",
     "iopub.status.idle": "2024-03-10T23:07:39.401991Z",
     "shell.execute_reply.started": "2024-03-10T23:07:38.300405Z",
     "shell.execute_reply": "2024-03-10T23:07:39.400928Z"
    },
    "trusted": true
   },
   "execution_count": 38,
   "outputs": [
    {
     "name": "stdout",
     "text": "Total allocated memory: 690668032 bytes\nSun Mar 10 23:07:39 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n| N/A   39C    P0              31W / 250W |    982MiB / 16384MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "stacked_encoder = StackedEncoder(num_layers, d_model, \n",
    "                                 seq_len, dropout, num_heads, d_ffn).to(device)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:39.403480Z",
     "iopub.execute_input": "2024-03-10T23:07:39.403844Z",
     "iopub.status.idle": "2024-03-10T23:07:39.469785Z",
     "shell.execute_reply.started": "2024-03-10T23:07:39.403750Z",
     "shell.execute_reply": "2024-03-10T23:07:39.468924Z"
    },
    "trusted": true
   },
   "execution_count": 39,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "!nvidia-smi\n",
    "#print('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\n",
    "#print(torch.cuda.memory_summary())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:39.470931Z",
     "iopub.execute_input": "2024-03-10T23:07:39.471201Z",
     "iopub.status.idle": "2024-03-10T23:07:40.575693Z",
     "shell.execute_reply.started": "2024-03-10T23:07:39.471177Z",
     "shell.execute_reply": "2024-03-10T23:07:40.574475Z"
    },
    "trusted": true
   },
   "execution_count": 40,
   "outputs": [
    {
     "name": "stdout",
     "text": "Sun Mar 10 23:07:40 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n| N/A   39C    P0              32W / 250W |    982MiB / 16384MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# DataLoader\n",
    "data_loader = DataLoader(dataset, batch_size = 32, shuffle = True)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:40.577197Z",
     "iopub.execute_input": "2024-03-10T23:07:40.577536Z",
     "iopub.status.idle": "2024-03-10T23:07:40.583537Z",
     "shell.execute_reply.started": "2024-03-10T23:07:40.577506Z",
     "shell.execute_reply": "2024-03-10T23:07:40.582504Z"
    },
    "trusted": true
   },
   "execution_count": 41,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "total_encoded_batches = []  # List to store encoded batches\n",
    "total_y_batches = []        # List to store corresponding y batches\n",
    "i = 0\n",
    "\n",
    "for x_batch, y_batch in data_loader:\n",
    "    print(f'Size of batch: {x_batch.shape}')\n",
    "    i += 1\n",
    "    print(i)\n",
    "    print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\n",
    "    \n",
    "    # Move the batch to the device\n",
    "    x_batch = x_batch.to(device)\n",
    "    y_batch = y_batch.to(device)\n",
    "    \n",
    "    # Encode the batch using the stacked_encoder\n",
    "    encoded_batch = stacked_encoder(x_batch)\n",
    "    \n",
    "    # Append the encoded batch to the list\n",
    "    total_encoded_batches.append(encoded_batch.detach().cpu())\n",
    "    total_y_batches.append(y_batch.detach().cpu())\n",
    "    \n",
    "    print(f'Current Size of Reviews: {len(total_encoded_batches)} tensors')\n",
    "    print(f'Current Size of Ratings: {len(total_y_batches)} tensors')\n",
    "\n",
    "\n",
    "# Concatenate all the encoded batches into a single tensor\n",
    "total_encoded_batch = torch.cat(total_encoded_batches, dim = 0)\n",
    "\n",
    "# Concatenate all the corresponding y batches into a single tensor\n",
    "total_y_batch = torch.cat(total_y_batches, dim = 0)\n",
    "\n",
    "print(f'Concatenated Reviews Size: {total_encoded_batch.shape}')\n",
    "print(f'Concatenated Ratings Size: {total_y_batch.shape}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:40.584448Z",
     "iopub.execute_input": "2024-03-10T23:07:40.584721Z",
     "iopub.status.idle": "2024-03-10T23:07:44.215250Z",
     "shell.execute_reply.started": "2024-03-10T23:07:40.584700Z",
     "shell.execute_reply": "2024-03-10T23:07:44.214201Z"
    },
    "trusted": true
   },
   "execution_count": 42,
   "outputs": [
    {
     "name": "stdout",
     "text": "Size of batch: torch.Size([32, 100, 300])\n1\nTotal allocated memory: 713262080 bytes\nCurrent Size of Reviews: 1 tensors\nCurrent Size of Ratings: 1 tensors\nSize of batch: torch.Size([32, 100, 300])\n2\nTotal allocated memory: 1194400256 bytes\nCurrent Size of Reviews: 2 tensors\nCurrent Size of Ratings: 2 tensors\nSize of batch: torch.Size([32, 100, 300])\n3\nTotal allocated memory: 1194236416 bytes\nCurrent Size of Reviews: 3 tensors\nCurrent Size of Ratings: 3 tensors\nSize of batch: torch.Size([32, 100, 300])\n4\nTotal allocated memory: 1195784704 bytes\nCurrent Size of Reviews: 4 tensors\nCurrent Size of Ratings: 4 tensors\nSize of batch: torch.Size([32, 100, 300])\n5\nTotal allocated memory: 1195209216 bytes\nCurrent Size of Reviews: 5 tensors\nCurrent Size of Ratings: 5 tensors\nSize of batch: torch.Size([32, 100, 300])\n6\nTotal allocated memory: 1195303424 bytes\nCurrent Size of Reviews: 6 tensors\nCurrent Size of Ratings: 6 tensors\nSize of batch: torch.Size([32, 100, 300])\n7\nTotal allocated memory: 1195465216 bytes\nCurrent Size of Reviews: 7 tensors\nCurrent Size of Ratings: 7 tensors\nSize of batch: torch.Size([32, 100, 300])\n8\nTotal allocated memory: 1193355776 bytes\nCurrent Size of Reviews: 8 tensors\nCurrent Size of Ratings: 8 tensors\nSize of batch: torch.Size([32, 100, 300])\n9\nTotal allocated memory: 1195276800 bytes\nCurrent Size of Reviews: 9 tensors\nCurrent Size of Ratings: 9 tensors\nSize of batch: torch.Size([32, 100, 300])\n10\nTotal allocated memory: 1194738176 bytes\nCurrent Size of Reviews: 10 tensors\nCurrent Size of Ratings: 10 tensors\nSize of batch: torch.Size([32, 100, 300])\n11\nTotal allocated memory: 1194969600 bytes\nCurrent Size of Reviews: 11 tensors\nCurrent Size of Ratings: 11 tensors\nSize of batch: torch.Size([32, 100, 300])\n12\nTotal allocated memory: 1193941504 bytes\nCurrent Size of Reviews: 12 tensors\nCurrent Size of Ratings: 12 tensors\nSize of batch: torch.Size([32, 100, 300])\n13\nTotal allocated memory: 1194500608 bytes\nCurrent Size of Reviews: 13 tensors\nCurrent Size of Ratings: 13 tensors\nSize of batch: torch.Size([32, 100, 300])\n14\nTotal allocated memory: 1194248704 bytes\nCurrent Size of Reviews: 14 tensors\nCurrent Size of Ratings: 14 tensors\nSize of batch: torch.Size([32, 100, 300])\n15\nTotal allocated memory: 1193716224 bytes\nCurrent Size of Reviews: 15 tensors\nCurrent Size of Ratings: 15 tensors\nSize of batch: torch.Size([32, 100, 300])\n16\nTotal allocated memory: 1196196352 bytes\nCurrent Size of Reviews: 16 tensors\nCurrent Size of Ratings: 16 tensors\nSize of batch: torch.Size([32, 100, 300])\n17\nTotal allocated memory: 1194185216 bytes\nCurrent Size of Reviews: 17 tensors\nCurrent Size of Ratings: 17 tensors\nSize of batch: torch.Size([32, 100, 300])\n18\nTotal allocated memory: 1195522560 bytes\nCurrent Size of Reviews: 18 tensors\nCurrent Size of Ratings: 18 tensors\nSize of batch: torch.Size([32, 100, 300])\n19\nTotal allocated memory: 1194404352 bytes\nCurrent Size of Reviews: 19 tensors\nCurrent Size of Ratings: 19 tensors\nSize of batch: torch.Size([32, 100, 300])\n20\nTotal allocated memory: 1194637824 bytes\nCurrent Size of Reviews: 20 tensors\nCurrent Size of Ratings: 20 tensors\nSize of batch: torch.Size([32, 100, 300])\n21\nTotal allocated memory: 1192303104 bytes\nCurrent Size of Reviews: 21 tensors\nCurrent Size of Ratings: 21 tensors\nSize of batch: torch.Size([32, 100, 300])\n22\nTotal allocated memory: 1195876864 bytes\nCurrent Size of Reviews: 22 tensors\nCurrent Size of Ratings: 22 tensors\nSize of batch: torch.Size([32, 100, 300])\n23\nTotal allocated memory: 1192448512 bytes\nCurrent Size of Reviews: 23 tensors\nCurrent Size of Ratings: 23 tensors\nSize of batch: torch.Size([32, 100, 300])\n24\nTotal allocated memory: 1194529280 bytes\nCurrent Size of Reviews: 24 tensors\nCurrent Size of Ratings: 24 tensors\nSize of batch: torch.Size([32, 100, 300])\n25\nTotal allocated memory: 1192448512 bytes\nCurrent Size of Reviews: 25 tensors\nCurrent Size of Ratings: 25 tensors\nSize of batch: torch.Size([32, 100, 300])\n26\nTotal allocated memory: 1195729408 bytes\nCurrent Size of Reviews: 26 tensors\nCurrent Size of Ratings: 26 tensors\nSize of batch: torch.Size([32, 100, 300])\n27\nTotal allocated memory: 1191649792 bytes\nCurrent Size of Reviews: 27 tensors\nCurrent Size of Ratings: 27 tensors\nSize of batch: torch.Size([32, 100, 300])\n28\nTotal allocated memory: 1196712448 bytes\nCurrent Size of Reviews: 28 tensors\nCurrent Size of Ratings: 28 tensors\nSize of batch: torch.Size([32, 100, 300])\n29\nTotal allocated memory: 1191465472 bytes\nCurrent Size of Reviews: 29 tensors\nCurrent Size of Ratings: 29 tensors\nSize of batch: torch.Size([32, 100, 300])\n30\nTotal allocated memory: 1196405248 bytes\nCurrent Size of Reviews: 30 tensors\nCurrent Size of Ratings: 30 tensors\nSize of batch: torch.Size([32, 100, 300])\n31\nTotal allocated memory: 1190973952 bytes\nCurrent Size of Reviews: 31 tensors\nCurrent Size of Ratings: 31 tensors\nSize of batch: torch.Size([32, 100, 300])\n32\nTotal allocated memory: 1197275648 bytes\nCurrent Size of Reviews: 32 tensors\nCurrent Size of Ratings: 32 tensors\nSize of batch: torch.Size([32, 100, 300])\n33\nTotal allocated memory: 1191956992 bytes\nCurrent Size of Reviews: 33 tensors\nCurrent Size of Ratings: 33 tensors\nSize of batch: torch.Size([32, 100, 300])\n34\nTotal allocated memory: 1195594240 bytes\nCurrent Size of Reviews: 34 tensors\nCurrent Size of Ratings: 34 tensors\nSize of batch: torch.Size([32, 100, 300])\n35\nTotal allocated memory: 1190478336 bytes\nCurrent Size of Reviews: 35 tensors\nCurrent Size of Ratings: 35 tensors\nSize of batch: torch.Size([32, 100, 300])\n36\nTotal allocated memory: 1194048000 bytes\nCurrent Size of Reviews: 36 tensors\nCurrent Size of Ratings: 36 tensors\nSize of batch: torch.Size([32, 100, 300])\n37\nTotal allocated memory: 1190703616 bytes\nCurrent Size of Reviews: 37 tensors\nCurrent Size of Ratings: 37 tensors\nSize of batch: torch.Size([32, 100, 300])\n38\nTotal allocated memory: 1193484800 bytes\nCurrent Size of Reviews: 38 tensors\nCurrent Size of Ratings: 38 tensors\nSize of batch: torch.Size([32, 100, 300])\n39\nTotal allocated memory: 1192921600 bytes\nCurrent Size of Reviews: 39 tensors\nCurrent Size of Ratings: 39 tensors\nSize of batch: torch.Size([32, 100, 300])\n40\nTotal allocated memory: 1192307200 bytes\nCurrent Size of Reviews: 40 tensors\nCurrent Size of Ratings: 40 tensors\nSize of batch: torch.Size([32, 100, 300])\n41\nTotal allocated memory: 1192174080 bytes\nCurrent Size of Reviews: 41 tensors\nCurrent Size of Ratings: 41 tensors\nSize of batch: torch.Size([32, 100, 300])\n42\nTotal allocated memory: 1190693376 bytes\nCurrent Size of Reviews: 42 tensors\nCurrent Size of Ratings: 42 tensors\nSize of batch: torch.Size([32, 100, 300])\n43\nTotal allocated memory: 1193157120 bytes\nCurrent Size of Reviews: 43 tensors\nCurrent Size of Ratings: 43 tensors\nSize of batch: torch.Size([32, 100, 300])\n44\nTotal allocated memory: 1192378880 bytes\nCurrent Size of Reviews: 44 tensors\nCurrent Size of Ratings: 44 tensors\nSize of batch: torch.Size([32, 100, 300])\n45\nTotal allocated memory: 1193228800 bytes\nCurrent Size of Reviews: 45 tensors\nCurrent Size of Ratings: 45 tensors\nSize of batch: torch.Size([32, 100, 300])\n46\nTotal allocated memory: 1191031296 bytes\nCurrent Size of Reviews: 46 tensors\nCurrent Size of Ratings: 46 tensors\nSize of batch: torch.Size([32, 100, 300])\n47\nTotal allocated memory: 1193157120 bytes\nCurrent Size of Reviews: 47 tensors\nCurrent Size of Ratings: 47 tensors\nSize of batch: torch.Size([32, 100, 300])\n48\nTotal allocated memory: 1193167360 bytes\nCurrent Size of Reviews: 48 tensors\nCurrent Size of Ratings: 48 tensors\nSize of batch: torch.Size([32, 100, 300])\n49\nTotal allocated memory: 1194027520 bytes\nCurrent Size of Reviews: 49 tensors\nCurrent Size of Ratings: 49 tensors\nSize of batch: torch.Size([32, 100, 300])\n50\nTotal allocated memory: 1193550336 bytes\nCurrent Size of Reviews: 50 tensors\nCurrent Size of Ratings: 50 tensors\nSize of batch: torch.Size([32, 100, 300])\n51\nTotal allocated memory: 1192864256 bytes\nCurrent Size of Reviews: 51 tensors\nCurrent Size of Ratings: 51 tensors\nSize of batch: torch.Size([32, 100, 300])\n52\nTotal allocated memory: 1193216512 bytes\nCurrent Size of Reviews: 52 tensors\nCurrent Size of Ratings: 52 tensors\nSize of batch: torch.Size([32, 100, 300])\n53\nTotal allocated memory: 1193536000 bytes\nCurrent Size of Reviews: 53 tensors\nCurrent Size of Ratings: 53 tensors\nSize of batch: torch.Size([32, 100, 300])\n54\nTotal allocated memory: 1192942080 bytes\nCurrent Size of Reviews: 54 tensors\nCurrent Size of Ratings: 54 tensors\nSize of batch: torch.Size([32, 100, 300])\n55\nTotal allocated memory: 1194103296 bytes\nCurrent Size of Reviews: 55 tensors\nCurrent Size of Ratings: 55 tensors\nSize of batch: torch.Size([32, 100, 300])\n56\nTotal allocated memory: 1191703040 bytes\nCurrent Size of Reviews: 56 tensors\nCurrent Size of Ratings: 56 tensors\nSize of batch: torch.Size([32, 100, 300])\n57\nTotal allocated memory: 1193579008 bytes\nCurrent Size of Reviews: 57 tensors\nCurrent Size of Ratings: 57 tensors\nSize of batch: torch.Size([32, 100, 300])\n58\nTotal allocated memory: 1193357824 bytes\nCurrent Size of Reviews: 58 tensors\nCurrent Size of Ratings: 58 tensors\nSize of batch: torch.Size([32, 100, 300])\n59\nTotal allocated memory: 1192718848 bytes\nCurrent Size of Reviews: 59 tensors\nCurrent Size of Ratings: 59 tensors\nSize of batch: torch.Size([32, 100, 300])\n60\nTotal allocated memory: 1194217984 bytes\nCurrent Size of Reviews: 60 tensors\nCurrent Size of Ratings: 60 tensors\nSize of batch: torch.Size([32, 100, 300])\n61\nTotal allocated memory: 1192718848 bytes\nCurrent Size of Reviews: 61 tensors\nCurrent Size of Ratings: 61 tensors\nSize of batch: torch.Size([32, 100, 300])\n62\nTotal allocated memory: 1194435072 bytes\nCurrent Size of Reviews: 62 tensors\nCurrent Size of Ratings: 62 tensors\nSize of batch: torch.Size([32, 100, 300])\n63\nTotal allocated memory: 1192718848 bytes\nCurrent Size of Reviews: 63 tensors\nCurrent Size of Ratings: 63 tensors\nSize of batch: torch.Size([32, 100, 300])\n64\nTotal allocated memory: 1193871872 bytes\nCurrent Size of Reviews: 64 tensors\nCurrent Size of Ratings: 64 tensors\nSize of batch: torch.Size([32, 100, 300])\n65\nTotal allocated memory: 1191627264 bytes\nCurrent Size of Reviews: 65 tensors\nCurrent Size of Ratings: 65 tensors\nSize of batch: torch.Size([32, 100, 300])\n66\nTotal allocated memory: 1195305472 bytes\nCurrent Size of Reviews: 66 tensors\nCurrent Size of Ratings: 66 tensors\nSize of batch: torch.Size([32, 100, 300])\n67\nTotal allocated memory: 1192538624 bytes\nCurrent Size of Reviews: 67 tensors\nCurrent Size of Ratings: 67 tensors\nSize of batch: torch.Size([32, 100, 300])\n68\nTotal allocated memory: 1195452928 bytes\nCurrent Size of Reviews: 68 tensors\nCurrent Size of Ratings: 68 tensors\nSize of batch: torch.Size([32, 100, 300])\n69\nTotal allocated memory: 1190875648 bytes\nCurrent Size of Reviews: 69 tensors\nCurrent Size of Ratings: 69 tensors\nSize of batch: torch.Size([32, 100, 300])\n70\nTotal allocated memory: 1195344384 bytes\nCurrent Size of Reviews: 70 tensors\nCurrent Size of Ratings: 70 tensors\nSize of batch: torch.Size([32, 100, 300])\n71\nTotal allocated memory: 1192755712 bytes\nCurrent Size of Reviews: 71 tensors\nCurrent Size of Ratings: 71 tensors\nSize of batch: torch.Size([32, 100, 300])\n72\nTotal allocated memory: 1194852864 bytes\nCurrent Size of Reviews: 72 tensors\nCurrent Size of Ratings: 72 tensors\nSize of batch: torch.Size([32, 100, 300])\n73\nTotal allocated memory: 1193247232 bytes\nCurrent Size of Reviews: 73 tensors\nCurrent Size of Ratings: 73 tensors\nSize of batch: torch.Size([32, 100, 300])\n74\nTotal allocated memory: 1194668544 bytes\nCurrent Size of Reviews: 74 tensors\nCurrent Size of Ratings: 74 tensors\nSize of batch: torch.Size([32, 100, 300])\n75\nTotal allocated memory: 1193431552 bytes\nCurrent Size of Reviews: 75 tensors\nCurrent Size of Ratings: 75 tensors\nSize of batch: torch.Size([32, 100, 300])\n76\nTotal allocated memory: 1194375680 bytes\nCurrent Size of Reviews: 76 tensors\nCurrent Size of Ratings: 76 tensors\nSize of batch: torch.Size([32, 100, 300])\n77\nTotal allocated memory: 1193161216 bytes\nCurrent Size of Reviews: 77 tensors\nCurrent Size of Ratings: 77 tensors\nSize of batch: torch.Size([32, 100, 300])\n78\nTotal allocated memory: 1192983040 bytes\nCurrent Size of Reviews: 78 tensors\nCurrent Size of Ratings: 78 tensors\nSize of batch: torch.Size([32, 100, 300])\n79\nTotal allocated memory: 1192489472 bytes\nCurrent Size of Reviews: 79 tensors\nCurrent Size of Ratings: 79 tensors\nSize of batch: torch.Size([32, 100, 300])\n80\nTotal allocated memory: 1194023424 bytes\nCurrent Size of Reviews: 80 tensors\nCurrent Size of Ratings: 80 tensors\nSize of batch: torch.Size([32, 100, 300])\n81\nTotal allocated memory: 1192720896 bytes\nCurrent Size of Reviews: 81 tensors\nCurrent Size of Ratings: 81 tensors\nSize of batch: torch.Size([32, 100, 300])\n82\nTotal allocated memory: 1194099200 bytes\nCurrent Size of Reviews: 82 tensors\nCurrent Size of Ratings: 82 tensors\nSize of batch: torch.Size([32, 100, 300])\n83\nTotal allocated memory: 1191860736 bytes\nCurrent Size of Reviews: 83 tensors\nCurrent Size of Ratings: 83 tensors\nSize of batch: torch.Size([32, 100, 300])\n84\nTotal allocated memory: 1193792000 bytes\nCurrent Size of Reviews: 84 tensors\nCurrent Size of Ratings: 84 tensors\nSize of batch: torch.Size([32, 100, 300])\n85\nTotal allocated memory: 1194416640 bytes\nCurrent Size of Reviews: 85 tensors\nCurrent Size of Ratings: 85 tensors\nSize of batch: torch.Size([32, 100, 300])\n86\nTotal allocated memory: 1193792000 bytes\nCurrent Size of Reviews: 86 tensors\nCurrent Size of Ratings: 86 tensors\nSize of batch: torch.Size([32, 100, 300])\n87\nTotal allocated memory: 1194615296 bytes\nCurrent Size of Reviews: 87 tensors\nCurrent Size of Ratings: 87 tensors\nSize of batch: torch.Size([32, 100, 300])\n88\nTotal allocated memory: 1193976320 bytes\nCurrent Size of Reviews: 88 tensors\nCurrent Size of Ratings: 88 tensors\nSize of batch: torch.Size([32, 100, 300])\n89\nTotal allocated memory: 1193830912 bytes\nCurrent Size of Reviews: 89 tensors\nCurrent Size of Ratings: 89 tensors\nSize of batch: torch.Size([32, 100, 300])\n90\nTotal allocated memory: 1194084864 bytes\nCurrent Size of Reviews: 90 tensors\nCurrent Size of Ratings: 90 tensors\nSize of batch: torch.Size([32, 100, 300])\n91\nTotal allocated memory: 1194015232 bytes\nCurrent Size of Reviews: 91 tensors\nCurrent Size of Ratings: 91 tensors\nSize of batch: torch.Size([32, 100, 300])\n92\nTotal allocated memory: 1193716224 bytes\nCurrent Size of Reviews: 92 tensors\nCurrent Size of Ratings: 92 tensors\nSize of batch: torch.Size([32, 100, 300])\n93\nTotal allocated memory: 1194383872 bytes\nCurrent Size of Reviews: 93 tensors\nCurrent Size of Ratings: 93 tensors\nSize of batch: torch.Size([32, 100, 300])\n94\nTotal allocated memory: 1193239040 bytes\nCurrent Size of Reviews: 94 tensors\nCurrent Size of Ratings: 94 tensors\nSize of batch: torch.Size([32, 100, 300])\n95\nTotal allocated memory: 1194568192 bytes\nCurrent Size of Reviews: 95 tensors\nCurrent Size of Ratings: 95 tensors\nSize of batch: torch.Size([32, 100, 300])\n96\nTotal allocated memory: 1192851968 bytes\nCurrent Size of Reviews: 96 tensors\nCurrent Size of Ratings: 96 tensors\nSize of batch: torch.Size([32, 100, 300])\n97\nTotal allocated memory: 1193708032 bytes\nCurrent Size of Reviews: 97 tensors\nCurrent Size of Ratings: 97 tensors\nSize of batch: torch.Size([32, 100, 300])\n98\nTotal allocated memory: 1193978368 bytes\nCurrent Size of Reviews: 98 tensors\nCurrent Size of Ratings: 98 tensors\nSize of batch: torch.Size([32, 100, 300])\n99\nTotal allocated memory: 1192432128 bytes\nCurrent Size of Reviews: 99 tensors\nCurrent Size of Ratings: 99 tensors\nSize of batch: torch.Size([32, 100, 300])\n100\nTotal allocated memory: 1195708928 bytes\nCurrent Size of Reviews: 100 tensors\nCurrent Size of Ratings: 100 tensors\nSize of batch: torch.Size([32, 100, 300])\n101\nTotal allocated memory: 1194271232 bytes\nCurrent Size of Reviews: 101 tensors\nCurrent Size of Ratings: 101 tensors\nSize of batch: torch.Size([32, 100, 300])\n102\nTotal allocated memory: 1195033088 bytes\nCurrent Size of Reviews: 102 tensors\nCurrent Size of Ratings: 102 tensors\nSize of batch: torch.Size([32, 100, 300])\n103\nTotal allocated memory: 1194347008 bytes\nCurrent Size of Reviews: 103 tensors\nCurrent Size of Ratings: 103 tensors\nSize of batch: torch.Size([32, 100, 300])\n104\nTotal allocated memory: 1194848768 bytes\nCurrent Size of Reviews: 104 tensors\nCurrent Size of Ratings: 104 tensors\nSize of batch: torch.Size([32, 100, 300])\n105\nTotal allocated memory: 1194531328 bytes\nCurrent Size of Reviews: 105 tensors\nCurrent Size of Ratings: 105 tensors\nSize of batch: torch.Size([32, 100, 300])\n106\nTotal allocated memory: 1194848768 bytes\nCurrent Size of Reviews: 106 tensors\nCurrent Size of Ratings: 106 tensors\nSize of batch: torch.Size([32, 100, 300])\n107\nTotal allocated memory: 1192651264 bytes\nCurrent Size of Reviews: 107 tensors\nCurrent Size of Ratings: 107 tensors\nSize of batch: torch.Size([32, 100, 300])\n108\nTotal allocated memory: 1195448832 bytes\nCurrent Size of Reviews: 108 tensors\nCurrent Size of Ratings: 108 tensors\nSize of batch: torch.Size([32, 100, 300])\n109\nTotal allocated memory: 1194162688 bytes\nCurrent Size of Reviews: 109 tensors\nCurrent Size of Ratings: 109 tensors\nSize of batch: torch.Size([32, 100, 300])\n110\nTotal allocated memory: 1195524608 bytes\nCurrent Size of Reviews: 110 tensors\nCurrent Size of Ratings: 110 tensors\nSize of batch: torch.Size([32, 100, 300])\n111\nTotal allocated memory: 1194347008 bytes\nCurrent Size of Reviews: 111 tensors\nCurrent Size of Ratings: 111 tensors\nSize of batch: torch.Size([32, 100, 300])\n112\nTotal allocated memory: 1193865728 bytes\nCurrent Size of Reviews: 112 tensors\nCurrent Size of Ratings: 112 tensors\nSize of batch: torch.Size([32, 100, 300])\n113\nTotal allocated memory: 1194729984 bytes\nCurrent Size of Reviews: 113 tensors\nCurrent Size of Ratings: 113 tensors\nSize of batch: torch.Size([32, 100, 300])\n114\nTotal allocated memory: 1194357248 bytes\nCurrent Size of Reviews: 114 tensors\nCurrent Size of Ratings: 114 tensors\nSize of batch: torch.Size([32, 100, 300])\n115\nTotal allocated memory: 1194422784 bytes\nCurrent Size of Reviews: 115 tensors\nCurrent Size of Ratings: 115 tensors\nSize of batch: torch.Size([32, 100, 300])\n116\nTotal allocated memory: 1194848768 bytes\nCurrent Size of Reviews: 116 tensors\nCurrent Size of Ratings: 116 tensors\nSize of batch: torch.Size([32, 100, 300])\n117\nTotal allocated memory: 1194265088 bytes\nCurrent Size of Reviews: 117 tensors\nCurrent Size of Ratings: 117 tensors\nSize of batch: torch.Size([32, 100, 300])\n118\nTotal allocated memory: 1195231744 bytes\nCurrent Size of Reviews: 118 tensors\nCurrent Size of Ratings: 118 tensors\nSize of batch: torch.Size([32, 100, 300])\n119\nTotal allocated memory: 1192999424 bytes\nCurrent Size of Reviews: 119 tensors\nCurrent Size of Ratings: 119 tensors\nSize of batch: torch.Size([32, 100, 300])\n120\nTotal allocated memory: 1194916352 bytes\nCurrent Size of Reviews: 120 tensors\nCurrent Size of Ratings: 120 tensors\nSize of batch: torch.Size([32, 100, 300])\n121\nTotal allocated memory: 1192507904 bytes\nCurrent Size of Reviews: 121 tensors\nCurrent Size of Ratings: 121 tensors\nSize of batch: torch.Size([32, 100, 300])\n122\nTotal allocated memory: 1194514944 bytes\nCurrent Size of Reviews: 122 tensors\nCurrent Size of Ratings: 122 tensors\nSize of batch: torch.Size([32, 100, 300])\n123\nTotal allocated memory: 1192876544 bytes\nCurrent Size of Reviews: 123 tensors\nCurrent Size of Ratings: 123 tensors\nSize of batch: torch.Size([32, 100, 300])\n124\nTotal allocated memory: 1194146304 bytes\nCurrent Size of Reviews: 124 tensors\nCurrent Size of Ratings: 124 tensors\nSize of batch: torch.Size([32, 100, 300])\n125\nTotal allocated memory: 1193060864 bytes\nCurrent Size of Reviews: 125 tensors\nCurrent Size of Ratings: 125 tensors\nSize of batch: torch.Size([32, 100, 300])\n126\nTotal allocated memory: 1194746368 bytes\nCurrent Size of Reviews: 126 tensors\nCurrent Size of Ratings: 126 tensors\nSize of batch: torch.Size([32, 100, 300])\n127\nTotal allocated memory: 1193968128 bytes\nCurrent Size of Reviews: 127 tensors\nCurrent Size of Ratings: 127 tensors\nSize of batch: torch.Size([32, 100, 300])\n128\nTotal allocated memory: 1193947648 bytes\nCurrent Size of Reviews: 128 tensors\nCurrent Size of Ratings: 128 tensors\nSize of batch: torch.Size([32, 100, 300])\n129\nTotal allocated memory: 1192876544 bytes\nCurrent Size of Reviews: 129 tensors\nCurrent Size of Ratings: 129 tensors\nSize of batch: torch.Size([32, 100, 300])\n130\nTotal allocated memory: 1195039232 bytes\nCurrent Size of Reviews: 130 tensors\nCurrent Size of Ratings: 130 tensors\nSize of batch: torch.Size([32, 100, 300])\n131\nTotal allocated memory: 1193060864 bytes\nCurrent Size of Reviews: 131 tensors\nCurrent Size of Ratings: 131 tensors\nSize of batch: torch.Size([32, 100, 300])\n132\nTotal allocated memory: 1194547712 bytes\nCurrent Size of Reviews: 132 tensors\nCurrent Size of Ratings: 132 tensors\nSize of batch: torch.Size([32, 100, 300])\n133\nTotal allocated memory: 1194459648 bytes\nCurrent Size of Reviews: 133 tensors\nCurrent Size of Ratings: 133 tensors\nSize of batch: torch.Size([32, 100, 300])\n134\nTotal allocated memory: 1193640448 bytes\nCurrent Size of Reviews: 134 tensors\nCurrent Size of Ratings: 134 tensors\nSize of batch: torch.Size([32, 100, 300])\n135\nTotal allocated memory: 1194004992 bytes\nCurrent Size of Reviews: 135 tensors\nCurrent Size of Ratings: 135 tensors\nSize of batch: torch.Size([32, 100, 300])\n136\nTotal allocated memory: 1193640448 bytes\nCurrent Size of Reviews: 136 tensors\nCurrent Size of Ratings: 136 tensors\nSize of batch: torch.Size([32, 100, 300])\n137\nTotal allocated memory: 1193636352 bytes\nCurrent Size of Reviews: 137 tensors\nCurrent Size of Ratings: 137 tensors\nSize of batch: torch.Size([32, 100, 300])\n138\nTotal allocated memory: 1194009088 bytes\nCurrent Size of Reviews: 138 tensors\nCurrent Size of Ratings: 138 tensors\nSize of batch: torch.Size([32, 100, 300])\n139\nTotal allocated memory: 1191827968 bytes\nCurrent Size of Reviews: 139 tensors\nCurrent Size of Ratings: 139 tensors\nSize of batch: torch.Size([32, 100, 300])\n140\nTotal allocated memory: 1194500608 bytes\nCurrent Size of Reviews: 140 tensors\nCurrent Size of Ratings: 140 tensors\nSize of batch: torch.Size([32, 100, 300])\n141\nTotal allocated memory: 1193306624 bytes\nCurrent Size of Reviews: 141 tensors\nCurrent Size of Ratings: 141 tensors\nSize of batch: torch.Size([32, 100, 300])\n142\nTotal allocated memory: 1194609152 bytes\nCurrent Size of Reviews: 142 tensors\nCurrent Size of Ratings: 142 tensors\nSize of batch: torch.Size([32, 100, 300])\n143\nTotal allocated memory: 1191719424 bytes\nCurrent Size of Reviews: 143 tensors\nCurrent Size of Ratings: 143 tensors\nSize of batch: torch.Size([32, 100, 300])\n144\nTotal allocated memory: 1193933312 bytes\nCurrent Size of Reviews: 144 tensors\nCurrent Size of Ratings: 144 tensors\nSize of batch: torch.Size([32, 100, 300])\n145\nTotal allocated memory: 1192395264 bytes\nCurrent Size of Reviews: 145 tensors\nCurrent Size of Ratings: 145 tensors\nSize of batch: torch.Size([32, 100, 300])\n146\nTotal allocated memory: 1193933312 bytes\nCurrent Size of Reviews: 146 tensors\nCurrent Size of Ratings: 146 tensors\nSize of batch: torch.Size([32, 100, 300])\n147\nTotal allocated memory: 1194166784 bytes\nCurrent Size of Reviews: 147 tensors\nCurrent Size of Ratings: 147 tensors\nSize of batch: torch.Size([32, 100, 300])\n148\nTotal allocated memory: 1193748992 bytes\nCurrent Size of Reviews: 148 tensors\nCurrent Size of Ratings: 148 tensors\nSize of batch: torch.Size([32, 100, 300])\n149\nTotal allocated memory: 1194166784 bytes\nCurrent Size of Reviews: 149 tensors\nCurrent Size of Ratings: 149 tensors\nSize of batch: torch.Size([32, 100, 300])\n150\nTotal allocated memory: 1192780288 bytes\nCurrent Size of Reviews: 150 tensors\nCurrent Size of Ratings: 150 tensors\nSize of batch: torch.Size([32, 100, 300])\n151\nTotal allocated memory: 1194351104 bytes\nCurrent Size of Reviews: 151 tensors\nCurrent Size of Ratings: 151 tensors\nSize of batch: torch.Size([32, 100, 300])\n152\nTotal allocated memory: 1192964608 bytes\nCurrent Size of Reviews: 152 tensors\nCurrent Size of Ratings: 152 tensors\nSize of batch: torch.Size([32, 100, 300])\n153\nTotal allocated memory: 1195258368 bytes\nCurrent Size of Reviews: 153 tensors\nCurrent Size of Ratings: 153 tensors\nSize of batch: torch.Size([32, 100, 300])\n154\nTotal allocated memory: 1193148928 bytes\nCurrent Size of Reviews: 154 tensors\nCurrent Size of Ratings: 154 tensors\nSize of batch: torch.Size([32, 100, 300])\n155\nTotal allocated memory: 1193179648 bytes\nCurrent Size of Reviews: 155 tensors\nCurrent Size of Ratings: 155 tensors\nSize of batch: torch.Size([32, 100, 300])\n156\nTotal allocated memory: 1193640448 bytes\nCurrent Size of Reviews: 156 tensors\nCurrent Size of Ratings: 156 tensors\nSize of batch: torch.Size([8, 100, 300])\n157\nTotal allocated memory: 1191579648 bytes\nCurrent Size of Reviews: 157 tensors\nCurrent Size of Ratings: 157 tensors\nConcatenated Reviews Size: torch.Size([5000, 100, 300])\nConcatenated Ratings Size: torch.Size([5000])\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "# total_encoded_batch = []\n",
    "# total_y_batch = []\n",
    "# i = 0\n",
    "\n",
    "# for x_batch, y_batch in data_loader:  # Iterate over the training batches\n",
    "#     print(f'size of batch: {x_batch.shape}')\n",
    "#     i = i + 1\n",
    "    \n",
    "#     print(i)\n",
    "#     print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\n",
    "    \n",
    "#     !nvidia-smi\n",
    "#     print('\\n\\n')\n",
    "    \n",
    "#     x_batch_encoded = stacked_encoder(x_batch).to(device)  # Encode the reviews using the stacked encoder\n",
    "    \n",
    "#     total_encoded_batch.append(x_batch_encoded)\n",
    "#     total_y_batch.append(y_batch)\n",
    "\n",
    "# total_encoded_batch = torch.cat(total_encoded_batch, dim = 0)  # Concatenate all the encoded batches into a single tensor\n",
    "# total_y_batch = torch.cat(total_y_batch)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:44.216453Z",
     "iopub.execute_input": "2024-03-10T23:07:44.216773Z",
     "iopub.status.idle": "2024-03-10T23:07:44.222990Z",
     "shell.execute_reply.started": "2024-03-10T23:07:44.216728Z",
     "shell.execute_reply": "2024-03-10T23:07:44.221949Z"
    },
    "trusted": true
   },
   "execution_count": 43,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(total_encoded_batch.shape)  # Check the shape of the combined encoded tensor\n",
    "print(total_y_batch.shape)\n",
    "print('\\n')\n",
    "print(f\"The Encoded batch is on: {total_encoded_batch.device}\")\n",
    "print(f\"The Y batch is on: {total_y_batch.device}\")\n",
    "print('\\n')\n",
    "print(stacked_encoder)\n",
    "print('\\n')\n",
    "\n",
    "\n",
    "# size in MB\n",
    "print(f'x_batch: { total_encoded_batch.nelement() * total_encoded_batch.element_size() }')\n",
    "print(f'y_batch: { total_y_batch.nelement() * total_y_batch.element_size() }')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:44.224745Z",
     "iopub.execute_input": "2024-03-10T23:07:44.225138Z",
     "iopub.status.idle": "2024-03-10T23:07:44.234660Z",
     "shell.execute_reply.started": "2024-03-10T23:07:44.225109Z",
     "shell.execute_reply": "2024-03-10T23:07:44.233734Z"
    },
    "trusted": true
   },
   "execution_count": 44,
   "outputs": [
    {
     "name": "stdout",
     "text": "torch.Size([5000, 100, 300])\ntorch.Size([5000])\n\n\nThe Encoded batch is on: cpu\nThe Y batch is on: cpu\n\n\nStackedEncoder(\n  (layers): ModuleList(\n    (0-5): 6 x EncoderLayer(\n      (positional_encoding): PositionalEncoding(\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (multihead_attention): MultiHeadedAttention()\n      (norm1): LayerNorm()\n      (feed_forward): PositionwiseFeedForward(\n        (w_1): Linear(in_features=300, out_features=1024, bias=True)\n        (w_2): Linear(in_features=1024, out_features=300, bias=True)\n        (dropout): Dropout(p=0.1, inplace=False)\n      )\n      (norm2): LayerNorm()\n    )\n  )\n)\n\n\nx_batch: 600000000\ny_batch: 40000\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "#del dataset\n",
    "#torch.cuda.empty_cache()\n",
    "\n",
    "#!nvidia-smi\n",
    "#print(torch.cuda.memory_summary())\n",
    "\n",
    "#print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\n",
    "#print('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\n",
    "#print(torch.cuda.memory_summary())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:44.236474Z",
     "iopub.execute_input": "2024-03-10T23:07:44.236868Z",
     "iopub.status.idle": "2024-03-10T23:07:44.247627Z",
     "shell.execute_reply.started": "2024-03-10T23:07:44.236833Z",
     "shell.execute_reply": "2024-03-10T23:07:44.246631Z"
    },
    "trusted": true
   },
   "execution_count": 45,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(total_encoded_batch.shape)  # Check the shape of the combined encoded tensor\n",
    "print(total_y_batch.shape)\n",
    "print('\\n')\n",
    "print(f\"The Encoded batch is on: {total_encoded_batch.device}\")\n",
    "print(f\"The Y batch is on: {total_y_batch.device}\")"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:44.249031Z",
     "iopub.execute_input": "2024-03-10T23:07:44.249386Z",
     "iopub.status.idle": "2024-03-10T23:07:44.259786Z",
     "shell.execute_reply.started": "2024-03-10T23:07:44.249351Z",
     "shell.execute_reply": "2024-03-10T23:07:44.258825Z"
    },
    "trusted": true
   },
   "execution_count": 46,
   "outputs": [
    {
     "name": "stdout",
     "text": "torch.Size([5000, 100, 300])\ntorch.Size([5000])\n\n\nThe Encoded batch is on: cpu\nThe Y batch is on: cpu\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Realized that I was spliting the data before encoding and thus the training data was only being encoded. Might also explain why the validation score was so low (along with how small the dataset is and how the large epochs are definitely overfitting)"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Lengths \n",
    "train_len = int(0.8 * len(dataset))\n",
    "val_len = len(dataset) - train_len\n",
    "\n",
    "# Random split\n",
    "train_data, val_data = random_split(dataset, [train_len, val_len])\n",
    "\n",
    "print(f\"The amount of data we have to train with is {len(train_data)}\") \n",
    "print(f\"The amount of data we have to validate with is {len(val_data)}\")\n",
    "#print(f\"The amount of data we have to validate with is on {train_data.device}\")\n",
    "#print(f\"The amount of data we have to validate with is on {val_data.device}\")\n",
    "\n",
    "# DataLoader for training data\n",
    "train_loader = DataLoader(train_data, batch_size = 32, shuffle = True)  # Use shuffle for training\n",
    "\n",
    "# DataLoader for validation data\n",
    "val_loader = DataLoader(val_data, batch_size = 32, shuffle = False)  # No need to shuffle for validation"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:44.261088Z",
     "iopub.execute_input": "2024-03-10T23:07:44.261452Z",
     "iopub.status.idle": "2024-03-10T23:07:44.272217Z",
     "shell.execute_reply.started": "2024-03-10T23:07:44.261419Z",
     "shell.execute_reply": "2024-03-10T23:07:44.271202Z"
    },
    "trusted": true
   },
   "execution_count": 47,
   "outputs": [
    {
     "name": "stdout",
     "text": "The amount of data we have to train with is 4000\nThe amount of data we have to validate with is 1000\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Moved input_size here"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# new dataset object post encoding\n",
    "#encoded_training_dataset = TensorDataset(total_encoded_batch, total_y_batch)\n",
    "\n",
    "# Print the sliced dataset\n",
    "#print(encoded_review_dataset[:5])\n",
    "\n",
    "# Should match the output size of your model\n",
    "#input_size = len(train_data[0])"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:44.273524Z",
     "iopub.execute_input": "2024-03-10T23:07:44.273901Z",
     "iopub.status.idle": "2024-03-10T23:07:44.282400Z",
     "shell.execute_reply.started": "2024-03-10T23:07:44.273866Z",
     "shell.execute_reply": "2024-03-10T23:07:44.281306Z"
    },
    "trusted": true
   },
   "execution_count": 48,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\n",
    "!nvidia-smi\n",
    "#print('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\n",
    "#print(torch.cuda.memory_summary())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:44.283633Z",
     "iopub.execute_input": "2024-03-10T23:07:44.284008Z",
     "iopub.status.idle": "2024-03-10T23:07:45.424784Z",
     "shell.execute_reply.started": "2024-03-10T23:07:44.283971Z",
     "shell.execute_reply": "2024-03-10T23:07:45.423679Z"
    },
    "trusted": true
   },
   "execution_count": 49,
   "outputs": [
    {
     "name": "stdout",
     "text": "Total allocated memory: 834439680 bytes\nSun Mar 10 23:07:45 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n| N/A   41C    P0              37W / 250W |   1970MiB / 16384MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Classifier"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, r_size,v_size, num_classes):\n",
    "        # r_size is the number of tokens in a review, 100.\n",
    "        # v_size is the number of values in an embedding vector, 300.\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        # The input to fc will be a 2D tensor with with n rows and\n",
    "        # r_size * v_size columns, where n >= 1; and the output will be a 2D tensor\n",
    "        # with n rows and num_classes columns.\n",
    "        self.fc = nn.Linear(r_size * v_size, num_classes)\n",
    "\n",
    "    def forward(self, x1):\n",
    "        # Pass input through the linear layer\n",
    "        return self.fc(x1)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:45.426466Z",
     "iopub.execute_input": "2024-03-10T23:07:45.426928Z",
     "iopub.status.idle": "2024-03-10T23:07:45.434193Z",
     "shell.execute_reply.started": "2024-03-10T23:07:45.426886Z",
     "shell.execute_reply": "2024-03-10T23:07:45.433118Z"
    },
    "trusted": true
   },
   "execution_count": 50,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, r_size,v_size, num_classes):\n",
    "        # r_size is the number of tokens in a review, 100.\n",
    "        # v_size is the number of values in an embedding vector, 300.\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        # The input to fc will be a 2D tensor with with n rows and\n",
    "        # r_size * v_size columns, where n >= 1; and the output will be a 2D tensor\n",
    "        # with n rows and num_classes columns.\n",
    "        self.fc = nn.Linear(r_size * v_size, num_classes)\n",
    "\n",
    "    def forward(self, x1):\n",
    "        # Pass input through the linear layer\n",
    "        return self.fc(x1)\n",
    "\n",
    "# Create the classifier\n",
    "classifier = Classifier(seq_len, d_model, num_classes + 1).to(device)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:45.435472Z",
     "iopub.execute_input": "2024-03-10T23:07:45.436106Z",
     "iopub.status.idle": "2024-03-10T23:07:45.447819Z",
     "shell.execute_reply.started": "2024-03-10T23:07:45.436064Z",
     "shell.execute_reply": "2024-03-10T23:07:45.446811Z"
    },
    "trusted": true
   },
   "execution_count": 51,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\n",
    "!nvidia-smi\n",
    "#print('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\n",
    "#print(torch.cuda.memory_summary())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:45.449136Z",
     "iopub.execute_input": "2024-03-10T23:07:45.449422Z",
     "iopub.status.idle": "2024-03-10T23:07:46.575882Z",
     "shell.execute_reply.started": "2024-03-10T23:07:45.449398Z",
     "shell.execute_reply": "2024-03-10T23:07:46.574530Z"
    },
    "trusted": true
   },
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "text": "Total allocated memory: 834920448 bytes\nSun Mar 10 23:07:46 2024       \n+---------------------------------------------------------------------------------------+\n| NVIDIA-SMI 535.129.03             Driver Version: 535.129.03   CUDA Version: 12.2     |\n|-----------------------------------------+----------------------+----------------------+\n| GPU  Name                 Persistence-M | Bus-Id        Disp.A | Volatile Uncorr. ECC |\n| Fan  Temp   Perf          Pwr:Usage/Cap |         Memory-Usage | GPU-Util  Compute M. |\n|                                         |                      |               MIG M. |\n|=========================================+======================+======================|\n|   0  Tesla P100-PCIE-16GB           Off | 00000000:00:04.0 Off |                    0 |\n| N/A   41C    P0              37W / 250W |   1970MiB / 16384MiB |      0%      Default |\n|                                         |                      |                  N/A |\n+-----------------------------------------+----------------------+----------------------+\n                                                                                         \n+---------------------------------------------------------------------------------------+\n| Processes:                                                                            |\n|  GPU   GI   CI        PID   Type   Process name                            GPU Memory |\n|        ID   ID                                                             Usage      |\n|=======================================================================================|\n+---------------------------------------------------------------------------------------+\n",
     "output_type": "stream"
    }
   ]
  },
  {
   "cell_type": "markdown",
   "source": [
    "### Changing reshaping format to check on the input size. Hardcoding the reshaping dimensions as 32 was breaking the classifier (presumably due to the data not being perfectly divisible by 32)\n",
    "### Moved the hyperparameters a few cells up where the encoder's hyperparameters were since they were similar"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# Define Cross-Entropy loss\n",
    "criterion = nn.CrossEntropyLoss() # nn.CategoricalCrossentropy() #nn.Softmax() \n",
    "\n",
    "# Define SGD optimizer\n",
    "# Is Adam better?\n",
    "optimizer = optim.SGD(classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "DEV = True\n",
    "# Training loop (adjust this to match your data and DataLoader)\n",
    "for epoch in range(epochs):\n",
    "    for inputs, targets in train_loader :  # Assuming you have a DataLoader\n",
    "        # for batch_data in train_loader:  # Assuming you have a DataLoader\n",
    "        # inputs, targets = batch_data  # Assuming your DataLoader provides input data and targets    \n",
    "    \n",
    "        #printd(f'inputs shape: {inputs.shape}')\n",
    "        #printd(f'targets shape: {targets.shape}')\n",
    "        #printd(f'targets: {targets}')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # keep nn.linear happy by combining the last two dimensions of inputs.\n",
    "        inputs = torch.reshape(inputs, (inputs.size(0), -1)) # get current batch size\n",
    "        #inputs = torch.reshape(inputs, (32,30000))\n",
    "        \n",
    "        #printd(f'Reshaped inputs: {inputs.shape}')\n",
    "        \n",
    "        outputs = classifier(inputs)\n",
    "        #printd(f'outputs shape {outputs.shape}')\n",
    "        \n",
    "        # output is a 32 x 6 tensor of floats,\n",
    "        # targets will be a 32 x 1 tensor of ints\n",
    "        loss = criterion(outputs, targets)\n",
    "        # print(f'loss.item: {loss.item()}')\n",
    "        loss.backward(retain_graph=True)\n",
    "        optimizer.step()\n",
    "     \n",
    "    print(f'Epoch [{epoch+1}/{epochs}] Loss: {loss.item()}')\n",
    "    \n",
    "DEV = False"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:17:50.884821Z",
     "iopub.execute_input": "2024-03-10T23:17:50.885283Z",
     "iopub.status.idle": "2024-03-10T23:17:51.197051Z",
     "shell.execute_reply.started": "2024-03-10T23:17:50.885248Z",
     "shell.execute_reply": "2024-03-10T23:17:51.195485Z"
    },
    "trusted": true
   },
   "execution_count": 54,
   "outputs": [
    {
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mRuntimeError\u001B[0m                              Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[54], line 11\u001B[0m\n\u001B[1;32m      9\u001B[0m \u001B[38;5;66;03m# Training loop (adjust this to match your data and DataLoader)\u001B[39;00m\n\u001B[1;32m     10\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[0;32m---> 11\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m inputs, targets \u001B[38;5;129;01min\u001B[39;00m train_loader :  \u001B[38;5;66;03m# Assuming you have a DataLoader\u001B[39;00m\n\u001B[1;32m     12\u001B[0m         \u001B[38;5;66;03m# for batch_data in train_loader:  # Assuming you have a DataLoader\u001B[39;00m\n\u001B[1;32m     13\u001B[0m         \u001B[38;5;66;03m# inputs, targets = batch_data  # Assuming your DataLoader provides input data and targets    \u001B[39;00m\n\u001B[1;32m     14\u001B[0m     \n\u001B[1;32m     15\u001B[0m         \u001B[38;5;66;03m#printd(f'inputs shape: {inputs.shape}')\u001B[39;00m\n\u001B[1;32m     16\u001B[0m         \u001B[38;5;66;03m#printd(f'targets shape: {targets.shape}')\u001B[39;00m\n\u001B[1;32m     17\u001B[0m         \u001B[38;5;66;03m#printd(f'targets: {targets}')\u001B[39;00m\n\u001B[1;32m     19\u001B[0m         optimizer\u001B[38;5;241m.\u001B[39mzero_grad()\n\u001B[1;32m     21\u001B[0m         \u001B[38;5;66;03m# keep nn.linear happy by combining the last two dimensions of inputs.\u001B[39;00m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:634\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    631\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    632\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    633\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 634\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    635\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    636\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    637\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    638\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/dataloader.py:678\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    676\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    677\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 678\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    679\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    680\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/fetch.py:54\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     52\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     53\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[possibly_batched_index]\n\u001B[0;32m---> 54\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mcollate_fn\u001B[49m\u001B[43m(\u001B[49m\u001B[43mdata\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:264\u001B[0m, in \u001B[0;36mdefault_collate\u001B[0;34m(batch)\u001B[0m\n\u001B[1;32m    203\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mdefault_collate\u001B[39m(batch):\n\u001B[1;32m    204\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    205\u001B[0m \u001B[38;5;124;03m        Function that takes in a batch of data and puts the elements within the batch\u001B[39;00m\n\u001B[1;32m    206\u001B[0m \u001B[38;5;124;03m        into a tensor with an additional outer dimension - batch size. The exact output type can be\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m    262\u001B[0m \u001B[38;5;124;03m            >>> default_collate(batch)  # Handle `CustomType` automatically\u001B[39;00m\n\u001B[1;32m    263\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 264\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mdefault_collate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    139\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m--> 142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [collate(samples, collate_fn_map\u001B[38;5;241m=\u001B[39mcollate_fn_map) \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    144\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:142\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    139\u001B[0m transposed \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mlist\u001B[39m(\u001B[38;5;28mzip\u001B[39m(\u001B[38;5;241m*\u001B[39mbatch))  \u001B[38;5;66;03m# It may be accessed twice, so we use a list.\u001B[39;00m\n\u001B[1;32m    141\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, \u001B[38;5;28mtuple\u001B[39m):\n\u001B[0;32m--> 142\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[43mcollate\u001B[49m\u001B[43m(\u001B[49m\u001B[43msamples\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m samples \u001B[38;5;129;01min\u001B[39;00m transposed]  \u001B[38;5;66;03m# Backwards compatibility.\u001B[39;00m\n\u001B[1;32m    143\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m    144\u001B[0m     \u001B[38;5;28;01mtry\u001B[39;00m:\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:119\u001B[0m, in \u001B[0;36mcollate\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    117\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m collate_fn_map \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    118\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m elem_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[0;32m--> 119\u001B[0m         \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mcollate_fn_map\u001B[49m\u001B[43m[\u001B[49m\u001B[43melem_type\u001B[49m\u001B[43m]\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mcollate_fn_map\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mcollate_fn_map\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    121\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m collate_type \u001B[38;5;129;01min\u001B[39;00m collate_fn_map:\n\u001B[1;32m    122\u001B[0m         \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28misinstance\u001B[39m(elem, collate_type):\n",
      "File \u001B[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/data/_utils/collate.py:162\u001B[0m, in \u001B[0;36mcollate_tensor_fn\u001B[0;34m(batch, collate_fn_map)\u001B[0m\n\u001B[1;32m    160\u001B[0m     storage \u001B[38;5;241m=\u001B[39m elem\u001B[38;5;241m.\u001B[39m_typed_storage()\u001B[38;5;241m.\u001B[39m_new_shared(numel, device\u001B[38;5;241m=\u001B[39melem\u001B[38;5;241m.\u001B[39mdevice)\n\u001B[1;32m    161\u001B[0m     out \u001B[38;5;241m=\u001B[39m elem\u001B[38;5;241m.\u001B[39mnew(storage)\u001B[38;5;241m.\u001B[39mresize_(\u001B[38;5;28mlen\u001B[39m(batch), \u001B[38;5;241m*\u001B[39m\u001B[38;5;28mlist\u001B[39m(elem\u001B[38;5;241m.\u001B[39msize()))\n\u001B[0;32m--> 162\u001B[0m \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mtorch\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mstack\u001B[49m\u001B[43m(\u001B[49m\u001B[43mbatch\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mout\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43mout\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mRuntimeError\u001B[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ],
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error"
    }
   ]
  },
  {
   "cell_type": "code",
   "source": [
    "print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\n",
    "!nvidia-smi\n",
    "#print('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\n",
    "print(torch.cuda.memory_summary())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:46.936062Z",
     "iopub.status.idle": "2024-03-10T23:07:46.936645Z",
     "shell.execute_reply.started": "2024-03-10T23:07:46.936347Z",
     "shell.execute_reply": "2024-03-10T23:07:46.936373Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "# Put model in evaluation mode\n",
    "classifier.eval() \n",
    "\n",
    "# Tracking variables\n",
    "predictions = []\n",
    "actuals = []\n",
    "\n",
    "# Evaluate on validation set\n",
    "with torch.no_grad():\n",
    "    for inputs, targets in val_loader:\n",
    "        inputs = inputs.reshape(inputs.shape[0], -1)\n",
    "        \n",
    "        outputs = classifier(inputs)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        \n",
    "        predictions.extend(predicted.tolist())\n",
    "        actuals.extend(targets.tolist())\n",
    "        \n",
    "# Print sample outputs        \n",
    "print(\"Predicted | Actual\")\n",
    "for i in range (60):\n",
    "    print(f\"{predictions[i]} | {actuals[i]}\")\n",
    "    \n",
    "# Calculate validation accuracy\n",
    "num_correct = sum([p == a for p, a in zip(predictions, actuals)]) \n",
    "val_accuracy = num_correct / len(predictions)\n",
    "print(f'Validation Accuracy: {val_accuracy:.2f}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:46.938329Z",
     "iopub.status.idle": "2024-03-10T23:07:46.938896Z",
     "shell.execute_reply.started": "2024-03-10T23:07:46.938598Z",
     "shell.execute_reply": "2024-03-10T23:07:46.938623Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "print(total_encoded_batch.device)\n",
    "print(total_y_batch.device)\n",
    "\n",
    "print(stacked_encoder)\n",
    "print(classifier)\n",
    "\n",
    "print(f'x_batch: { total_encoded_batch.nelement() * total_encoded_batch.element_size() }')\n",
    "print(f'y_batch: { total_y_batch.nelement() * total_y_batch.element_size() }')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:46.940504Z",
     "iopub.status.idle": "2024-03-10T23:07:46.940949Z",
     "shell.execute_reply.started": "2024-03-10T23:07:46.940715Z",
     "shell.execute_reply": "2024-03-10T23:07:46.940734Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [
    "import sys \n",
    "\n",
    "# Stacked Encoder \n",
    "for name, param in stacked_encoder.named_parameters():\n",
    "    print(f\"{name}:\\t{sys.getsizeof(param.untyped_storage()) / 1e6:.2f} MB\")\n",
    "\n",
    "# Classifier \n",
    "for name, param in classifier.named_parameters():\n",
    "    print(f\"{name}:\\t{sys.getsizeof(param.untyped_storage()) / 1e6:.2f} MB\")\n",
    "    \n",
    "\n",
    "del dataset\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "!nvidia-smi\n",
    "print(torch.cuda.memory_summary())"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:46.943345Z",
     "iopub.status.idle": "2024-03-10T23:07:46.943776Z",
     "shell.execute_reply.started": "2024-03-10T23:07:46.943559Z",
     "shell.execute_reply": "2024-03-10T23:07:46.943578Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Try and print every utilization of .to(device) to try and see what'son the gpu"
   ],
   "metadata": {}
  },
  {
   "cell_type": "code",
   "source": [
    "# attention components\n",
    "#self.attention_heads\n",
    "#print(attn_bias.device)\n",
    "\n",
    "# pre-processed input tensors\n",
    "print(text_embeddings_tensors.device)\n",
    "print(f'text_embeddings: { text_embeddings_tensors.nelement() * text_embeddings_tensors.element_size() }')\n",
    "print(rating_labels_tensors.device)\n",
    "print(f'rating_labels: { rating_labels_tensors.nelement() * rating_labels_tensors.element_size() }')\n",
    "\n",
    "#tensor object\n",
    "#print(dataset)\n",
    "\n",
    "# processed input tensor\n",
    "print(total_encoded_batch.device)\n",
    "print(f'total_encoded_batch: { total_encoded_batch.nelement() * total_encoded_batch.element_size() }')\n",
    "print(total_y_batch.device)\n",
    "print(f'y_batch: { total_y_batch.nelement() * total_y_batch.element_size() }')\n",
    "\n",
    "# moedels\n",
    "#print(stacked_encoder.device)\n",
    "#print(classifier.device)"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2024-03-10T23:07:46.945219Z",
     "iopub.status.idle": "2024-03-10T23:07:46.945624Z",
     "shell.execute_reply.started": "2024-03-10T23:07:46.945422Z",
     "shell.execute_reply": "2024-03-10T23:07:46.945440Z"
    },
    "trusted": true
   },
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "code",
   "source": [],
   "metadata": {},
   "execution_count": null,
   "outputs": []
  },
  {
   "cell_type": "markdown",
   "source": [
    "class Classifier(nn.Module):\n",
    "    def __init__(self, r_size,v_size, num_classes):\n",
    "        # r_size is the number of tokens in a review, 100.\n",
    "        # v_size is the number of values in an embedding vector, 300.\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        # The input to fc will be a 2D tensor with with n rows and\n",
    "        # r_size * v_size columns, where n >= 1; and the output will be a 2D tensor\n",
    "        # with n rows and num_classes columns.\n",
    "        self.fc = nn.Linear(r_size * v_size, num_classes)\n",
    "\n",
    "    def forward(self, x1):\n",
    "        # Pass input through the linear layer\n",
    "        return self.fc(x1)\n",
    "\n",
    "# The next two lines were an attempt to fix the obscure CUDA assert error --\n",
    "# didn't work. But there's a workaround, just run without the accelerator.\n",
    "# You can get away with that if you just have 5,000 reviews in each category.\n",
    "#\n",
    "CUDA_LAUNCH_BLOCKING=1 \n",
    "TORCH_USE_CUDA_DSA=1\n",
    "\n",
    "# Create the classifier\n",
    "classifier = Classifier(seq_len, d_model, num_classes+1)#.to(device)\n",
    "\n",
    "# Define Cross-Entropy loss\n",
    "criterion = nn.CrossEntropyLoss() # nn.CategoricalCrossentropy() #nn.Softmax() \n",
    "\n",
    "# Define SGD optimizer\n",
    "# Is Adam better?\n",
    "optimizer = optim.SGD(classifier.parameters(), lr=learning_rate)\n",
    "\n",
    "# DEV = True\n",
    "# Training loop (adjust this to match your data and DataLoader)\n",
    "for epoch in range(epochs):\n",
    "    for x_batch, y_batch in encoded_review_dataset:  # Assuming you have a DataLoader\n",
    "        inputs, targets = x_batch, y_batch  # Assuming your DataLoader provides input data and targets\n",
    "       \n",
    "        printd(f'targets shape: {targets.shape}')\n",
    "        printd(f'targets: {targets}')\n",
    "        printd(f'inputs shape: {inputs.shape}')\n",
    "        printd(f'inputs: {inputs}')\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "        # keep nn.linear happy by combining the last two dimensions of inputs.\n",
    "        #\n",
    "        inputs = torch.reshape(inputs, (32,30000))\n",
    "        printd(f'Reshaped inputs: {inputs.shape}')\n",
    "        \n",
    "        outputs = classifier(inputs)\n",
    "        printd(f'outputs shape {outputs.shape}')\n",
    "        \n",
    "        #dummy_output = torch.randn(32, 5, requires_grad=True).to(device)\n",
    "        # printd(f'dummy_output shape {dummy_output.shape}')\n",
    "        # printd(f'dummy_output {dummy_output}')\n",
    "        # output should be a 32 x 5 tensor of floats,\n",
    "        # targets will be a 32 x 1 tensor of ints\n",
    "        loss = criterion(outputs, targets)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    print(f'Epoch [{epoch+1}/{epochs}] Loss: {loss.item()}')\n",
    "    \n",
    "DEV = False\n",
    "\n",
    "# Define the Classifier class\n",
    "class Classifier(nn.Module):\n",
    "    def __init__(self, input_size, num_classes):\n",
    "        super(Classifier, self).__init__()\n",
    "        \n",
    "        self.linear_1 = nn.Linear(input_size, num_classes)\n",
    "        self.linear_2 = nn.Linear(1, num_classes)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x1):\n",
    "        \n",
    "        linear_1_output = self.linear_1(x_batch)\n",
    "        linear_2_output = self.linear_2(y_batch)\n",
    "        combined_output = linear_1_output + linear_2_output\n",
    "        output = self.sigmoid(combined_output)\n",
    "        \n",
    "        return output\n",
    "    \n",
    "# Create the classifier\n",
    "classifier = Classifier(input_size, num_classes)#.to(device)\n",
    "\n",
    "# Define Cross-Entropy loss\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Define SGD optimizer for both classifier\n",
    "optimizer = optim.SGD(list(classifier.parameters()), lr = learning_rate)\n",
    "\n",
    "# Training loop (adjust this to match your data and DataLoader)\n",
    "for epoch in range(epochs):\n",
    "    for batch_data in :  # Assuming you have a DataLoader\n",
    "        inputs, targets = x_batch, y_batch  # Assuming your DataLoader provides input data and targets\n",
    "        optimizer.zero_grad()\n",
    "        \n",
    "        outputs = classifier()  \n",
    "        loss = criterion(outputs, targets)\n",
    "        \n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    print(f'Epoch [{epoch + 1}/{epochs}] Loss: {loss.item()}')"
   ],
   "metadata": {
    "execution": {
     "iopub.status.busy": "2023-12-18T04:38:14.013759Z",
     "iopub.execute_input": "2023-12-18T04:38:14.014019Z",
     "iopub.status.idle": "2023-12-18T04:38:14.553673Z",
     "shell.execute_reply.started": "2023-12-18T04:38:14.013986Z",
     "shell.execute_reply": "2023-12-18T04:38:14.552074Z"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "You can think of the loss function as the valley, with the steepest parts being where the loss is highest and the flatter parts being where the loss is lower. The hiker is the set of model parameters, which are being updated with each step (iteration). SGD is like the GPS for the hiker, helping it navigate toward the lowest point in the valley (i.e. the global minimum of the loss function) with each step. The key difference is that SGD is an iterative process that updates the parameters in small steps, rather than finding the global minimum in a single shot. The learning rate is essentially the \"speed limit\" for the hiker (the model parameters). The learning rate would be how far the GPS would tell the hiker to go before it iterates/updates. A higher learning rate means that the hiker can make larger updates to the parameters with each step, while a lower learning rate means that the updates are smaller. This is important because it determines not only how quickly the model can find the global minimum, but also how stable the descent is - if the learning rate is too high, the hiker could get lost in the valley, but if it's too low, it could take forever to reach the bottom. So, the learning rate controls the speed of the descent and helps the model find the optimal set of parameters without overshooting or taking too long.\n",
    "\n",
    "Some additional points to augment the analogy:\n",
    "\n",
    "The terrain can be rugged with many hills, valleys, and obstacles - like the high-dimensional, non-convex loss function landscape.\n",
    "\n",
    "Momentum in SGD helps the hiker build up speed in consistently downhill directions, like momentum in GD.\n",
    "\n",
    "Adaptive LR is like the GPS dynamically recommending faster or slower speeds depending on terrain.\n",
    "\n",
    "Regularization is like constraining the hiker's path to stay on trails and avoid dangerous cliffs (to prevent overfitting).\n",
    "\n",
    "Batch size is like the number of hikers traversing together (to average gradient noise).\n",
    "\n",
    "Epochs are like hiking to the bottom, then restarting from the top to repeat the descent.\n",
    "\n",
    "Early stopping is like stopping the hike once you reach a good enough point close to the valley floor.\n",
    "\n",
    "Hyperparameter tuning is like tweaking the GPS settings for optimal navigation.\n",
    "\n",
    "Vanishing gradients are like certain paths becoming too steep or hitting dead-ends.\n",
    "\n",
    "Local minima: The terrain can be rugged with many local minima, which are small valleys that are not as deep as the global minimum. SGD can get stuck in local minima, but there are various techniques that can help to avoid this, such as momentum and adaptive learning rate.\n",
    "\n",
    "Learning rate schedule: The learning rate can be adjusted over time to improve the performance of SGD. This is known as a learning rate schedule. For example, the learning rate can be decreased as the model converges to the global minimum, in order to prevent overshooting.\n",
    "\n",
    "Noise: The gradient calculation can be noisy, especially when the batch size is small. This can cause SGD to take a more erratic path towards the global minimum. However, the noise can be averaged out by using a larger batch size."
   ],
   "metadata": {}
  }
 ]
}
