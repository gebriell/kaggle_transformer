{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":2307650,"sourceType":"datasetVersion","datasetId":1391881},{"sourceId":2415872,"sourceType":"datasetVersion","datasetId":1461623}],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h1 align=\"center\" style=\"color:blue;font-size: 3em;\" >Sentiment Analysis of Amazon Reviews using Transformers</h1>\n\n## This program is broken down into 3 sections:\n\n**1. We will work on data cleaning and preprocessing.**\n\n**2. We will then work on creating the sentiment analyzer and train it on the data we have preprocessed.**\n\n**3. Finally, we will evauate our model and visualize the results.**\n\n***Heads Up: Some of the cells might not have an output after they finish running. This is completely normal. You can always hover over the play button you click to run them and it will let you know if the cell has been executed and how long the process took. If there ever is an error, the cell will print out the stack trace and the issue it encountered.***","metadata":{}},{"cell_type":"markdown","source":"## Let us begin by importing the necessary libraries\n\n***Heads Up: You might see a warning when importing the packages, but you may ignore this, as it won't cause any issues for our needs.***","metadata":{}},{"cell_type":"code","source":"# For viewing and manipulating data\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Importing the necessary libraries\nimport re\nimport math\nimport string\nimport nltk\nimport torch\nimport torch.nn as nn\nimport torch.optim as optim\nimport torch.nn.functional as F\nimport gensim.downloader as api\nfrom gensim.models import KeyedVectors # >> alternative to gensim.downloader\nimport matplotlib.pyplot as plt\n\n# Getting particular functions from these libraries \nfrom torch import Tensor\nfrom sklearn.utils import resample\nfrom gensim.models import KeyedVectors\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.feature_extraction.text import CountVectorizer\nfrom torch.utils.data import random_split, DataLoader, TensorDataset, Dataset\n\n# Using the NLTK to tokenize the text\nfrom nltk.corpus import stopwords\nfrom nltk.stem import WordNetLemmatizer\n\n# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nreviews_file = ''\nw2v_file = ''\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        file_name = os.path.join(dirname, filename)\n        if file_name.endswith('.csv'): \n            reviews_file = file_name\n        elif file_name.endswith('.bin'):\n            w2v_file = file_name\n        else:\n            print(f'Found unexpected file: {file_name}')\n                \nprint(f'Amazon reviews file: {reviews_file}')\nprint(f'Google news word to vec file: {w2v_file}')\n            \n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session\nVERBOSE = True\ndef printv(text):\n    if VERBOSE: print('VERBOSE:', text)\n    return\n\ndef showV(text):\n    '''unconditional verbose output'''\n    print('VERBOSE:', text)\n    return\n\nDEV = True\ndef printd(text):\n    if DEV: print('DEV:', text)\n    return\n\ndef showD(text):\n    '''unconditional DEV output'''\n    print('VERBOSE:', text)\n    return\n\nshowCellCompletion = True\ndef showC(text):\n    if showCellCompletion:\n        print('Cell complete:', text)\n    return\n\nimport subprocess\nshowNv = True\naccelerator = False\n\ndef printNv():\n    if not showNv or not accelerator: return\n    mem_usage = subprocess.run(['nvidia-smi'], stdout=subprocess.PIPE)\n    print(mem_usage.stdout.decode('utf-8'))\n\nshowMemoryAllocation = True\ndef printM():\n    if not showMemoryAllocation: return\n    print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\n    ","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:07:41.101561Z","iopub.execute_input":"2024-03-30T05:07:41.102536Z","iopub.status.idle":"2024-03-30T05:08:09.886061Z","shell.execute_reply.started":"2024-03-30T05:07:41.102489Z","shell.execute_reply":"2024-03-30T05:08:09.884780Z"},"trusted":true},"execution_count":1,"outputs":[{"name":"stdout","text":"Amazon reviews file: /kaggle/input/amazon-product-reviews/Reviews.csv\nGoogle news word to vec file: /kaggle/input/googlenewsvectors/GoogleNews-vectors-negative300.bin\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**This magic command we are running below gives the notebook access to parts of the NLTK library. When ran correctly, it should unzip the wordnet file and copy over its contents.**\n\n**Please only run this command once when you start the notebook. If you run it again, it will prompt you to replace the existing files. After you run it once, you may comment it out. If you happen to run it again, and you are prompted for a response, simply stop the cell and move on to the next section.** \n","metadata":{}},{"cell_type":"code","source":"## Only run once\n#>> Seems to need to be rerun after every Kaggle timeout.\n!unzip /usr/share/nltk_data/corpora/wordnet.zip -d /usr/share/nltk_data/corpora/","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:08:09.888473Z","iopub.execute_input":"2024-03-30T05:08:09.889516Z","iopub.status.idle":"2024-03-30T05:08:11.431286Z","shell.execute_reply.started":"2024-03-30T05:08:09.889471Z","shell.execute_reply":"2024-03-30T05:08:11.429785Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"Archive:  /usr/share/nltk_data/corpora/wordnet.zip\n   creating: /usr/share/nltk_data/corpora/wordnet/\n  inflating: /usr/share/nltk_data/corpora/wordnet/lexnames  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adv.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.verb  \n  inflating: /usr/share/nltk_data/corpora/wordnet/cntlist.rev  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.adj  \n  inflating: /usr/share/nltk_data/corpora/wordnet/LICENSE  \n  inflating: /usr/share/nltk_data/corpora/wordnet/citation.bib  \n  inflating: /usr/share/nltk_data/corpora/wordnet/noun.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/verb.exc  \n  inflating: /usr/share/nltk_data/corpora/wordnet/README  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.sense  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/data.adv  \n  inflating: /usr/share/nltk_data/corpora/wordnet/index.noun  \n  inflating: /usr/share/nltk_data/corpora/wordnet/adj.exc  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Section 1: Data Cleaning and Preprocessing\n\n**One thing you will hear often when working with data is that preprocessing is the most important part. If the data is not cleaned and prepared for the model, you will always get sub-par results.**\n\n**The image below illustrate our goals for this section. It may look confusing now, but things will be clearer as we go through the section.**\n\n**For this project, we will be using over 568,000 reviews collected from Amazon. The cell below the image contains the code that will give us access to the dataset. You can also find the dataset linked here.**\n\n(Note that a word embedding is a representation of a word in an n-dimensonal vector space, n â‰¥ 2)\n\n[Amazon Reviews](https://www.kaggle.com/datasets/arhamrumi/amazon-product-reviews)","metadata":{}},{"cell_type":"markdown","source":"![Example of Embeddings](https://www.researchgate.net/publication/340825443/figure/fig6/AS:882927785238529@1587517796128/Word-embeddings-map-words-in-a-corpus-of-text-to-vector-space-Linear-combinations-of.png)\n\n* Source: [Word embeddings map words in a corpus of text to vector space](https://figshare.com/articles/figure/Word_embeddings_map_words_in_a_corpus_of_text_to_vector_space_/12169047/1)","metadata":{}},{"cell_type":"markdown","source":"**Let's access the dataset and see how many reviews we actually have.**","metadata":{}},{"cell_type":"code","source":"# Load data from CSV\n#>>  3/13 needed to change the path as below\n# path ='/kaggle/input/Reviews.csv'#\"/kaggle/input/amazon-product-reviews/Reviews.csv\"\ndata = pd.read_csv(reviews_file) # Use pandas to analyze data\nshowD('Amazon reviews loaded into Panda')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:08:11.433019Z","iopub.execute_input":"2024-03-30T05:08:11.433526Z","iopub.status.idle":"2024-03-30T05:08:20.482882Z","shell.execute_reply.started":"2024-03-30T05:08:11.433482Z","shell.execute_reply":"2024-03-30T05:08:20.481725Z"},"trusted":true},"execution_count":3,"outputs":[{"name":"stdout","text":"VERBOSE: Amazon reviews loaded into Panda\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**We can use the pandas object methods and fields to explore the Amazon reviews.**","metadata":{}},{"cell_type":"code","source":"# print number of rows in our ratings column\nprintv(f'Number of reviews: {len(data[\"Score\"])}')\nprintv(f'Column names -\\n {data.columns}\\n') \nprintv(f'First five rows -\\n{data.head()}')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:08:20.485625Z","iopub.execute_input":"2024-03-30T05:08:20.486004Z","iopub.status.idle":"2024-03-30T05:08:20.505494Z","shell.execute_reply.started":"2024-03-30T05:08:20.485972Z","shell.execute_reply":"2024-03-30T05:08:20.504126Z"},"trusted":true},"execution_count":4,"outputs":[{"name":"stdout","text":"VERBOSE: Number of reviews: 568454\nVERBOSE: Column names -\n Index(['Id', 'ProductId', 'UserId', 'ProfileName', 'HelpfulnessNumerator',\n       'HelpfulnessDenominator', 'Score', 'Time', 'Summary', 'Text'],\n      dtype='object')\n\nVERBOSE: First five rows -\n   Id   ProductId          UserId                      ProfileName  \\\n0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n\n   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n0                     1                       1      5  1303862400   \n1                     0                       0      1  1346976000   \n2                     1                       1      4  1219017600   \n3                     3                       3      2  1307923200   \n4                     0                       0      5  1350777600   \n\n                 Summary                                               Text  \n0  Good Quality Dog Food  I have bought several of the Vitality canned d...  \n1      Not as Advertised  Product arrived labeled as Jumbo Salted Peanut...  \n2  \"Delight\" says it all  This is a confection that has been around a fe...  \n3         Cough Medicine  If you are looking for the secret ingredient i...  \n4            Great taffy  Great taffy at a great price.  There was a wid...  \n","output_type":"stream"}]},{"cell_type":"markdown","source":"**The data has 1O columns, including \"Score,\" indicating the review's sentiment, and \"Text,\" the product review the score is based on. In Machine Learning, Text would be called the FEATURE, the term for the column(s) used for inference.**\n\n\n**There is far too much data to print, but we can print the total number of reviews per rating and use the functions provided to us by matplotlib to visualize the distribution as a bar graph.**","metadata":{}},{"cell_type":"code","source":"# Get count of ratings \nrating_counts = data['Score'].value_counts()\n\n# Sort counts by index ascending\nrating_counts = rating_counts.sort_index()  \n\n# Print number of reviews per rating\n#for rating, count in rating_counts.items():\n#    print(f\"{count:,} reviews with a rating score of {rating}\", \"\\n\")\n\n# Get count of ratings\n#>> Seems to work even if we do not redefine rating_count\n#>> rating_counts = data['Score'].value_counts().sort_index() \n\n# Create bar plot\nax = rating_counts.plot(kind = 'bar')\n\nax.set_title(\"Ratings Distribution\")\nax.set_xlabel(\"Rating\")\nax.set_ylabel(\"Number of Occurrences\")\n\n# Fix x-axis tick labels\nax.set_xticklabels(ax.get_xticklabels(), rotation = 0) \n\nfor rating, count in rating_counts.items():\n        print(f\"{count:,} samples from balanced data with rating {rating}\\n\")\n\nplt.show() #<< show the rating in each of the 5 categories","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:08:20.507295Z","iopub.execute_input":"2024-03-30T05:08:20.507778Z","iopub.status.idle":"2024-03-30T05:08:20.883676Z","shell.execute_reply.started":"2024-03-30T05:08:20.507736Z","shell.execute_reply":"2024-03-30T05:08:20.882307Z"},"trusted":true},"execution_count":5,"outputs":[{"name":"stdout","text":"52,268 samples from balanced data with rating 1\n\n29,769 samples from balanced data with rating 2\n\n42,640 samples from balanced data with rating 3\n\n80,655 samples from balanced data with rating 4\n\n363,122 samples from balanced data with rating 5\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"iVBORw0KGgoAAAANSUhEUgAAAlUAAAHHCAYAAACWQK1nAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjcuNSwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy/xnp5ZAAAACXBIWXMAAA9hAAAPYQGoP6dpAABNgElEQVR4nO3de1zUdd7//+eADngCPHCQJCU1FRVdUZFM15JExb5ZdqXWKppZumApZWiZmh1MyzzkqbYD7m5uaptWmhhi6pWSB4wUU1PTqBTwBKOoIDC/P/oxlxOajH5oGHncb7e5Xc3785r35zUz18azz+E9JqvVahUAAABuiJuzGwAAALgZEKoAAAAMQKgCAAAwAKEKAADAAIQqAAAAAxCqAAAADECoAgAAMAChCgAAwACEKgAAAAMQqgA4xdSpU2UymZzdhqFMJpOmTp1a4fvZuHGjTCaTNm7caBvr0aOH2rRpU+H7lqSjR4/KZDIpMTHxT9kf4CoIVQAkSYmJiTKZTLZHtWrVdMstt2jYsGH69ddfr2vO8+fPa+rUqXZ//F1FkyZNbJ+Fm5ubfHx81LZtWz3++OPatm2bYftZunSp5syZY9h8RqrMvQGVkYnf/gMg/Raqhg8frmnTpik4OFgXL17UN998o8TERDVp0kQZGRny9PR0aM6TJ0/K19dXU6ZMKXMEp6ioSEVFRQ7P+Wdp0qSJ6tatq6efflqSdPbsWe3bt08rVqxQVlaWxo0bpzfffNPuNRcvXlS1atVUrVq1cu+nX79+ysjI0NGjR8v9mpKSEhUWFspsNsvN7bf/Nu7Ro4dOnjypjIyMcs9zvb1ZrVYVFBSoevXqcnd3N2x/gKsr///yAVQJffr0UceOHSVJjz32mBo0aKAZM2bos88+00MPPWTYfhwNH85wyy236G9/+5vd2IwZM/Twww9r9uzZat68uUaPHm3bVtEB8eLFi7Yg5cwwajKZKm0YBpyJ038A/lC3bt0kSYcPH7aNFRYWavLkyQoLC5O3t7dq1aqlbt266auvvrLVHD16VL6+vpKkF1980XYqrfSI1ZWuqTKZTIqLi9OqVavUpk0beXh4qHXr1kpKSirT18aNG9WxY0d5enqqadOmevvtt684Z3Jysu688075+Piodu3aatGihZ577rnr/jxq1Kihf/3rX6pXr55eeeUVXX6w//fXVJ09e1Zjx45VkyZN5OHhIT8/P91zzz3atWuXpN+OLq1Zs0Y//fST7fNp0qSJ7f2ZTCZ99NFHmjRpkm655RbVrFlTFovlitdUlUpLS9Mdd9yhGjVqKDg4WIsXL7bbXnqa9/dHn34/5x/1drVrqjZs2KBu3bqpVq1a8vHx0X333ad9+/bZ1ZR+R4cOHdKwYcPk4+Mjb29vDR8+XOfPny/flwBUUpX7PxMBOF3pH9+6devaxiwWi959910NHjxYI0eO1NmzZ/Xee+8pKipK27dvV/v27eXr66tFixZp9OjRuv/++/XAAw9IkkJDQ/9wf19//bU++eQT/f3vf1edOnU0b948DRgwQJmZmapfv74k6dtvv1Xv3r3VsGFDvfjiiyouLta0adNsIa7U3r171a9fP4WGhmratGny8PDQoUOHtGXLlhv6TGrXrq37779f7733nr7//nu1bt36inWjRo3Sxx9/rLi4OIWEhOjUqVP6+uuvtW/fPnXo0EHPP/+88vLy9Msvv2j27Nm2uS/30ksvyWw265lnnlFBQYHMZvNV+zpz5oz69u2rhx56SIMHD9by5cs1evRomc1mPfroow69x/L0drn169erT58+uu222zR16lRduHBBb731lrp27apdu3bZAlmphx56SMHBwZo+fbp27dqld999V35+fpoxY4ZDfQKVihUArFbrBx98YJVkXb9+vfXEiRPWn3/+2frxxx9bfX19rR4eHtaff/7ZVltUVGQtKCiwe/2ZM2es/v7+1kcffdQ2duLECask65QpU8rsb8qUKdbf/ytIktVsNlsPHTpkG/vuu++skqxvvfWWbezee++11qxZ0/rrr7/axg4ePGitVq2a3ZyzZ8+2SrKeOHHC4c+jcePG1ujo6KtuL537008/tev/8vfq7e1tjY2N/cP9REdHWxs3blxm/KuvvrJKst52223W8+fPX3HbV199ZRv761//apVknTVrlm2soKDA2r59e6ufn5+1sLDQarX+3/d85MiRa855td6OHDlilWT94IMPbGOl+zl16pRt7LvvvrO6ublZhw4dahsr/d4v//8Tq9Vqvf/++63169cvsy/AlXD6D4CdyMhI+fr6KigoSA8++KBq1aqlzz77TI0aNbLVuLu7246YlJSU6PTp0yoqKlLHjh1tp7ZuZP9Nmza1PQ8NDZWXl5d+/PFHSVJxcbHWr1+v/v37KzAw0FbXrFkz9enTx24uHx8fSdKnn36qkpKSG+rr90qP2pw9e/aqNT4+Ptq2bZuOHTt23fuJiYlRjRo1ylVbrVo1PfHEE7bnZrNZTzzxhHJycpSWlnbdPVzL8ePHlZ6ermHDhqlevXq28dDQUN1zzz364osvyrxm1KhRds+7deumU6dOyWKxVFifQEUjVAGws2DBAiUnJ+vjjz9W3759dfLkSXl4eJSpW7JkiUJDQ+Xp6an69evL19dXa9asUV5e3g3t/9Zbby0zVrduXZ05c0aSlJOTowsXLqhZs2Zl6n4/NnDgQHXt2lWPPfaY/P39NWjQIC1fvtyQgHXu3DlJUp06da5aM3PmTGVkZCgoKEidO3fW1KlTbeGwvIKDg8tdGxgYqFq1atmN3X777ZLk0N2Fjvrpp58kSS1atCizrVWrVjp58qTy8/Ptxn//PZeeXi79ngFXRKgCYKdz586KjIzUgAED9Nlnn6lNmzZ6+OGHbSFCkv79739r2LBhatq0qd577z0lJSUpOTlZd9999w0Hlqvdom+9jtVfatSooc2bN2v9+vUaMmSIdu/erYEDB+qee+5RcXHxDfVZunTBlcJdqYceekg//vij3nrrLQUGBur1119X69attXbtWofeg5GutuDqjX4ejjLyewYqC0IVgKtyd3fX9OnTdezYMc2fP982/vHHH+u2227TJ598oiFDhigqKkqRkZG6ePGi3esrYsV0Pz8/eXp66tChQ2W2XWnMzc1NPXv21Jtvvqnvv/9er7zyijZs2GB3p6Kjzp07p5UrVyooKEitWrX6w9qGDRvq73//u1atWqUjR46ofv36euWVV2zbjfyMjh07VuaI0A8//CBJtgvFS48I5ebm2tWVHm26XHl7a9y4sSTpwIEDZbbt379fDRo0KHMEDbgZEaoA/KEePXqoc+fOmjNnji00lR5luPyowrZt25Sammr32po1a0oq+wf8Rri7uysyMlKrVq2yu1bp0KFDZY4AnT59uszr27dvL0kqKCi4rv1fuHBBQ4YM0enTp/X888//4ZGf358K9fPzU2BgoN2+a9WqdcOnTEsVFRXp7bfftj0vLCzU22+/LV9fX4WFhUmS7Xq1zZs32/X6zjvvlJmvvL01bNhQ7du315IlS+y+64yMDH355Zfq27fv9b4lwKWwpAKAaxo/frz+53/+R4mJiRo1apT69eunTz75RPfff7+io6N15MgRLV68WCEhIXanCWvUqKGQkBAtW7ZMt99+u+rVq6c2bdrc8G/UTZ06VV9++aW6du2q0aNHq7i4WPPnz1ebNm2Unp5uq5s2bZo2b96s6OhoNW7cWDk5OVq4cKEaNWqkO++885r7+fXXX/Xvf/9b0m9Hp77//nvbiupPP/203UXhv3f27Fk1atRIDz74oNq1a6fatWtr/fr12rFjh2bNmmWrCwsL07JlyxQfH69OnTqpdu3auvfee6/rcwkMDNSMGTN09OhR3X777Vq2bJnS09P1zjvvqHr16pKk1q1bq0uXLpo4caJOnz6tevXq6aOPPlJRUVGZ+Rzp7fXXX1efPn0UERGhESNG2JZU8Pb2/lN+DxGoFJx89yGASqL0VvsdO3aU2VZcXGxt2rSptWnTptaioiJrSUmJ9dVXX7U2btzY6uHhYf3LX/5iXb16tTUmJqbMLfhbt261hoWFWc1ms92SA1dbUuFKSxA0btzYGhMTYzeWkpJi/ctf/mI1m83Wpk2bWt99913r008/bfX09LSrue+++6yBgYFWs9lsDQwMtA4ePNj6ww8/XPPzaNy4sVWSVZLVZDJZvby8rK1bt7aOHDnSum3btiu+5vL3V1BQYB0/fry1Xbt21jp16lhr1aplbdeunXXhwoV2rzl37pz14Ycftvr4+Fgl2T6/0iUOVqxYUWY/V1tSoXXr1tadO3daIyIirJ6entbGjRtb58+fX+b1hw8ftkZGRlo9PDys/v7+1ueee86anJxcZs6r9XalJRWsVqt1/fr11q5du1pr1Khh9fLyst57773W77//3q6m9Hv//TIXV1vqAXAl/PYfgJtG//79tXfvXh08eNDZrQCogrimCoBLunDhgt3zgwcP6osvvlCPHj2c0xCAKo8jVQBcUsOGDTVs2DDddttt+umnn7Ro0SIVFBTo22+/VfPmzZ3dHoAqiAvVAbik3r176z//+Y+ysrLk4eGhiIgIvfrqqwQqAE7DkSoAAAADcE0VAACAAQhVAAAABuCaqj9RSUmJjh07pjp16lTIz3cAAADjWa1WnT17VoGBgXJzu/rxKELVn+jYsWMKCgpydhsAAOA6/Pzzz2rUqNFVtxOq/kR16tSR9NuX4uXl5eRuAABAeVgsFgUFBdn+jl8NoepPVHrKz8vLi1AFAICLudalO1yoDgAAYABCFQAAgAEIVQAAAAYgVAEAABiAUAUAAGAAQhUAAIABCFUAAAAGIFQBAAAYgFAFAABgAEIVAACAAQhVAAAABiBUAQAAGIBQBQAAYABCFQAAgAEIVQAAAAao5uwGAACA8zSZsMbZLdywo69FO7sFSRypAgAAMAShCgAAwACEKgAAAAMQqgAAAAxAqAIAADAAoQoAAMAAhCoAAAADODVULVq0SKGhofLy8pKXl5ciIiK0du1a2/YePXrIZDLZPUaNGmU3R2ZmpqKjo1WzZk35+flp/PjxKioqsqvZuHGjOnToIA8PDzVr1kyJiYllelmwYIGaNGkiT09PhYeHa/v27XbbL168qNjYWNWvX1+1a9fWgAEDlJ2dbdyHAQAAXJpTQ1WjRo302muvKS0tTTt37tTdd9+t++67T3v37rXVjBw5UsePH7c9Zs6cadtWXFys6OhoFRYWauvWrVqyZIkSExM1efJkW82RI0cUHR2tu+66S+np6Ro7dqwee+wxrVu3zlazbNkyxcfHa8qUKdq1a5fatWunqKgo5eTk2GrGjRunzz//XCtWrNCmTZt07NgxPfDAAxX8CQEAAFdhslqtVmc3cbl69erp9ddf14gRI9SjRw+1b99ec+bMuWLt2rVr1a9fPx07dkz+/v6SpMWLFyshIUEnTpyQ2WxWQkKC1qxZo4yMDNvrBg0apNzcXCUlJUmSwsPD1alTJ82fP1+SVFJSoqCgII0ZM0YTJkxQXl6efH19tXTpUj344IOSpP3796tVq1ZKTU1Vly5dyvXeLBaLvL29lZeXJy8vr+v9iAAAMAwrql9bef9+V5prqoqLi/XRRx8pPz9fERERtvEPP/xQDRo0UJs2bTRx4kSdP3/eti01NVVt27a1BSpJioqKksVisR3tSk1NVWRkpN2+oqKilJqaKkkqLCxUWlqaXY2bm5siIyNtNWlpabp06ZJdTcuWLXXrrbfaaq6koKBAFovF7gEAAG5OTv/tvz179igiIkIXL15U7dq1tXLlSoWEhEiSHn74YTVu3FiBgYHavXu3EhISdODAAX3yySeSpKysLLtAJcn2PCsr6w9rLBaLLly4oDNnzqi4uPiKNfv377fNYTab5ePjU6amdD9XMn36dL344osOfiIAAMAVOT1UtWjRQunp6crLy9PHH3+smJgYbdq0SSEhIXr88cdtdW3btlXDhg3Vs2dPHT58WE2bNnVi1+UzceJExcfH255bLBYFBQU5sSMAAFBRnH76z2w2q1mzZgoLC9P06dPVrl07zZ0794q14eHhkqRDhw5JkgICAsrcgVf6PCAg4A9rvLy8VKNGDTVo0EDu7u5XrLl8jsLCQuXm5l615ko8PDxsdzaWPgAAwM3J6aHq90pKSlRQUHDFbenp6ZKkhg0bSpIiIiK0Z88eu7v0kpOT5eXlZTuFGBERoZSUFLt5kpOTbddtmc1mhYWF2dWUlJQoJSXFVhMWFqbq1avb1Rw4cECZmZl2138BAICqy6mn/yZOnKg+ffro1ltv1dmzZ7V06VJt3LhR69at0+HDh7V06VL17dtX9evX1+7duzVu3Dh1795doaGhkqRevXopJCREQ4YM0cyZM5WVlaVJkyYpNjZWHh4ekqRRo0Zp/vz5evbZZ/Xoo49qw4YNWr58udas+b+7HeLj4xUTE6OOHTuqc+fOmjNnjvLz8zV8+HBJkre3t0aMGKH4+HjVq1dPXl5eGjNmjCIiIsp95x8AALi5OTVU5eTkaOjQoTp+/Li8vb0VGhqqdevW6Z577tHPP/+s9evX2wJOUFCQBgwYoEmTJtle7+7urtWrV2v06NGKiIhQrVq1FBMTo2nTptlqgoODtWbNGo0bN05z585Vo0aN9O677yoqKspWM3DgQJ04cUKTJ09WVlaW2rdvr6SkJLuL12fPni03NzcNGDBABQUFioqK0sKFC/+cDwoAAFR6lW6dqpsZ61QBACob1qm6NpdbpwoAAMCVEaoAAAAMQKgCAAAwAKEKAADAAIQqAAAAAxCqAAAADECoAgAAMAChCgAAwACEKgAAAAMQqgAAAAxAqAIAADAAoQoAAMAAhCoAAAADEKoAAAAMQKgCAAAwAKEKAADAAIQqAAAAAxCqAAAADECoAgAAMAChCgAAwACEKgAAAAMQqgAAAAxAqAIAADAAoQoAAMAAhCoAAAADEKoAAAAMQKgCAAAwAKEKAADAAIQqAAAAAxCqAAAADECoAgAAMAChCgAAwACEKgAAAAMQqgAAAAxAqAIAADAAoQoAAMAAhCoAAAADEKoAAAAM4NRQtWjRIoWGhsrLy0teXl6KiIjQ2rVrbdsvXryo2NhY1a9fX7Vr19aAAQOUnZ1tN0dmZqaio6NVs2ZN+fn5afz48SoqKrKr2bhxozp06CAPDw81a9ZMiYmJZXpZsGCBmjRpIk9PT4WHh2v79u1228vTCwAAqLqcGqoaNWqk1157TWlpadq5c6fuvvtu3Xfffdq7d68kady4cfr888+1YsUKbdq0SceOHdMDDzxge31xcbGio6NVWFiorVu3asmSJUpMTNTkyZNtNUeOHFF0dLTuuusupaena+zYsXrssce0bt06W82yZcsUHx+vKVOmaNeuXWrXrp2ioqKUk5Njq7lWLwAAoGozWa1Wq7ObuFy9evX0+uuv68EHH5Svr6+WLl2qBx98UJK0f/9+tWrVSqmpqerSpYvWrl2rfv366dixY/L395ckLV68WAkJCTpx4oTMZrMSEhK0Zs0aZWRk2PYxaNAg5ebmKikpSZIUHh6uTp06af78+ZKkkpISBQUFacyYMZowYYLy8vKu2Ut5WCwWeXt7Ky8vT15eXoZ9ZgAAXK8mE9Y4u4UbdvS16Aqdv7x/vyvNNVXFxcX66KOPlJ+fr4iICKWlpenSpUuKjIy01bRs2VK33nqrUlNTJUmpqalq27atLVBJUlRUlCwWi+1oV2pqqt0cpTWlcxQWFiotLc2uxs3NTZGRkbaa8vRyJQUFBbJYLHYPAABwc3J6qNqzZ49q164tDw8PjRo1SitXrlRISIiysrJkNpvl4+NjV+/v76+srCxJUlZWll2gKt1euu2PaiwWiy5cuKCTJ0+quLj4ijWXz3GtXq5k+vTp8vb2tj2CgoLK96EAAACX4/RQ1aJFC6Wnp2vbtm0aPXq0YmJi9P333zu7LUNMnDhReXl5tsfPP//s7JYAAEAFqebsBsxms5o1ayZJCgsL044dOzR37lwNHDhQhYWFys3NtTtClJ2drYCAAElSQEBAmbv0Su/Iu7zm93fpZWdny8vLSzVq1JC7u7vc3d2vWHP5HNfq5Uo8PDzk4eHhwKcBAABcldOPVP1eSUmJCgoKFBYWpurVqyslJcW27cCBA8rMzFRERIQkKSIiQnv27LG7Sy85OVleXl4KCQmx1Vw+R2lN6Rxms1lhYWF2NSUlJUpJSbHVlKcXAABQtTn1SNXEiRPVp08f3XrrrTp79qyWLl2qjRs3at26dfL29taIESMUHx+vevXqycvLS2PGjFFERITtbrtevXopJCREQ4YM0cyZM5WVlaVJkyYpNjbWdoRo1KhRmj9/vp599lk9+uij2rBhg5YvX641a/7vbof4+HjFxMSoY8eO6ty5s+bMmaP8/HwNHz5cksrVCwAAqNqcGqpycnI0dOhQHT9+XN7e3goNDdW6det0zz33SJJmz54tNzc3DRgwQAUFBYqKitLChQttr3d3d9fq1as1evRoRUREqFatWoqJidG0adNsNcHBwVqzZo3GjRunuXPnqlGjRnr33XcVFRVlqxk4cKBOnDihyZMnKysrS+3bt1dSUpLdxevX6gUAAFRtlW6dqpsZ61QBACob1qm6NpdbpwoAAMCVEaoAAAAMQKgCAAAwAKEKAADAAIQqAAAAAxCqAAAADECoAgAAMAChCgAAwACEKgAAAAMQqgAAAAxAqAIAADAAoQoAAMAAhCoAAAADEKoAAAAMQKgCAAAwAKEKAADAAIQqAAAAAxCqAAAADOBwqNq1a5f27Nlje/7pp5+qf//+eu6551RYWGhocwAAAK7C4VD1xBNP6IcffpAk/fjjjxo0aJBq1qypFStW6NlnnzW8QQAAAFfgcKj64Ycf1L59e0nSihUr1L17dy1dulSJiYn673//a3R/AAAALsHhUGW1WlVSUiJJWr9+vfr27StJCgoK0smTJ43tDgAAwEU4HKo6duyol19+Wf/617+0adMmRUdHS5KOHDkif39/wxsEAABwBQ6Hqjlz5mjXrl2Ki4vT888/r2bNmkmSPv74Y91xxx2GNwgAAOAKqjn6gtDQULu7/0q9/vrrcnd3N6QpAAAAV3Nd61Tl5ubq3Xff1cSJE3X69GlJ0vfff6+cnBxDmwMAAHAVDh+p2r17t3r27CkfHx8dPXpUI0eOVL169fTJJ58oMzNT//znPyuiTwAAgErN4SNV8fHxGj58uA4ePChPT0/beN++fbV582ZDmwMAAHAVDoeqHTt26IknnigzfssttygrK8uQpgAAAFyNw6HKw8NDFoulzPgPP/wgX19fQ5oCAABwNQ6Hqv/3//6fpk2bpkuXLkmSTCaTMjMzlZCQoAEDBhjeIAAAgCtwOFTNmjVL586dk5+fny5cuKC//vWvatasmerUqaNXXnmlInoEAACo9By++8/b21vJycnasmWLvvvuO507d04dOnRQZGRkRfQHAADgEhwOVaW6du2qrl27GtkLAACAy3L49N+TTz6pefPmlRmfP3++xo4da0RPAAAALsfhUPXf//73ikeo7rjjDn388ceGNAUAAOBqHA5Vp06dkre3d5lxLy8vnTx50pCmAAAAXI3DoapZs2ZKSkoqM7527VrddtttDs01ffp0derUSXXq1JGfn5/69++vAwcO2NX06NFDJpPJ7jFq1Ci7mszMTEVHR6tmzZry8/PT+PHjVVRUZFezceNGdejQQR4eHmrWrJkSExPL9LNgwQI1adJEnp6eCg8P1/bt2+22X7x4UbGxsapfv75q166tAQMGKDs726H3DAAAbk4OX6geHx+vuLg4nThxQnfffbckKSUlRbNmzdKcOXMcmmvTpk2KjY1Vp06dVFRUpOeee069evXS999/r1q1atnqRo4cqWnTptme16xZ0/bPxcXFio6OVkBAgLZu3arjx49r6NChql69ul599VVJ0pEjRxQdHa1Ro0bpww8/VEpKih577DE1bNhQUVFRkqRly5YpPj5eixcvVnh4uObMmaOoqCgdOHBAfn5+kqRx48ZpzZo1WrFihby9vRUXF6cHHnhAW7ZscfRjBAAANxmT1Wq1OvqiRYsW6ZVXXtGxY8ckSU2aNNHUqVM1dOjQG2rmxIkT8vPz06ZNm9S9e3dJvx2pat++/VUD29q1a9WvXz8dO3ZM/v7+kqTFixcrISFBJ06ckNlsVkJCgtasWaOMjAzb6wYNGqTc3FzbUbfw8HB16tRJ8+fPlySVlJQoKChIY8aM0YQJE5SXlydfX18tXbpUDz74oCRp//79atWqlVJTU9WlS5drvj+LxSJvb2/l5eXJy8vruj8nAACM0mTCGme3cMOOvhZdofOX9++3w6f/JGn06NH65ZdflJ2dLYvFoh9//PGGA5Uk5eXlSZLq1atnN/7hhx+qQYMGatOmjSZOnKjz58/btqWmpqpt27a2QCVJUVFRslgs2rt3r63m9+toRUVFKTU1VZJUWFiotLQ0uxo3NzdFRkbaatLS0nTp0iW7mpYtW+rWW2+11fxeQUGBLBaL3QMAANycrnudKkmG/tZfSUmJxo4dq65du6pNmza28YcffliNGzdWYGCgdu/erYSEBB04cECffPKJJCkrK8suUEmyPS/9geer1VgsFl24cEFnzpxRcXHxFWv2799vm8NsNsvHx6dMzdV+SHr69Ol68cUXHfwkAACAK3I4VGVnZ+uZZ55RSkqKcnJy9Puzh8XFxdfVSGxsrDIyMvT111/bjT/++OO2f27btq0aNmyonj176vDhw2ratOl17evPMnHiRMXHx9ueWywWBQUFObEjAABQURwOVcOGDVNmZqZeeOEFNWzYUCaT6YabiIuL0+rVq7V582Y1atToD2vDw8MlSYcOHVLTpk0VEBBQ5i690jvyAgICbP/393fpZWdny8vLSzVq1JC7u7vc3d2vWHP5HIWFhcrNzbU7WnV5ze95eHjIw8PjGu8eAADcDBwOVV9//bX+93//V+3bt7/hnVutVo0ZM0YrV67Uxo0bFRwcfM3XpKenS5IaNmwoSYqIiNArr7yinJwc2116ycnJ8vLyUkhIiK3miy++sJsnOTlZERERkiSz2aywsDClpKSof//+kn47HZmSkqK4uDhJUlhYmKpXr66UlBQNGDBAknTgwAFlZmba5gEAAFWXw6EqKCiozCm/6xUbG6ulS5fq008/VZ06dWzXJnl7e6tGjRo6fPiwli5dqr59+6p+/fravXu3xo0bp+7duys0NFSS1KtXL4WEhGjIkCGaOXOmsrKyNGnSJMXGxtqOEo0aNUrz58/Xs88+q0cffVQbNmzQ8uXLtWbN/93xEB8fr5iYGHXs2FGdO3fWnDlzlJ+fr+HDh9t6GjFihOLj41WvXj15eXlpzJgxioiIKNedfwAA4ObmcKiaM2eOJkyYoLfffltNmjS5oZ0vWrRI0m/LJlzugw8+0LBhw2Q2m7V+/XpbwAkKCtKAAQM0adIkW627u7tWr16t0aNHKyIiQrVq1VJMTIzdulbBwcFas2aNxo0bp7lz56pRo0Z69913bWtUSdLAgQN14sQJTZ48WVlZWWrfvr2SkpLsLl6fPXu23NzcNGDAABUUFCgqKkoLFy68oc8AAADcHBxep6pu3bo6f/68ioqKVLNmTVWvXt1u++nTpw1t8GbCOlUAgMqGdaqurbx/v6/rSBUAAADsORyqYmJiKqIPAAAAl3ZdK6ofPnxYkyZN0uDBg5WTkyPpt5+LKV3BHAAAoKpxOFRt2rRJbdu21bZt2/TJJ5/o3LlzkqTvvvtOU6ZMMbxBAAAAV+BwqJowYYJefvllJScny2w228bvvvtuffPNN4Y2BwAA4CocDlV79uzR/fffX2bcz89PJ0+eNKQpAAAAV+NwqPLx8dHx48fLjH/77be65ZZbDGkKAADA1TgcqgYNGqSEhARlZWXJZDKppKREW7Zs0TPPPKOhQ4dWRI8AAACVnsOh6tVXX1XLli0VFBSkc+fOKSQkRN27d9cdd9xht9I5AABAVeLQOlVWq1VZWVmaN2+eJk+erD179ujcuXP6y1/+oubNm1dUjwAAAJWew6GqWbNm2rt3r5o3b66goKCK6gsAAMClOHT6z83NTc2bN9epU6cqqh8AAACX5PA1Va+99prGjx+vjIyMiugHAADAJTn8239Dhw7V+fPn1a5dO5nNZtWoUcNu++nTpw1rDgAAwFU4HKrmzJlTAW0AAAC4NodC1aVLl7Rp0ya98MILCg4OrqieAAAAXI5D11RVr15d//3vfyuqFwAAAJfl8IXq/fv316pVqyqgFQAAANfl8DVVzZs317Rp07RlyxaFhYWpVq1adtuffPJJw5oDAABwFQ6Hqvfee08+Pj5KS0tTWlqa3TaTyUSoAgAAVZLDoerIkSMV0QcAAIBLc/iaKgAAAJTl8JGqRx999A+3v//++9fdDAAAgKtyOFSdOXPG7vmlS5eUkZGh3Nxc3X333YY1BgAA4EocDlUrV64sM1ZSUqLRo0eradOmhjQFAADgagy5psrNzU3x8fGaPXu2EdMBAAC4HMMuVD98+LCKioqMmg4AAMClOHz6Lz4+3u651WrV8ePHtWbNGsXExBjWGAAAgCtxOFR9++23ds/d3Nzk6+urWbNmXfPOQAAAgJuVw6Hqq6++qog+AAAAXJrD11QdOXJEBw8eLDN+8OBBHT161IieAAAAXI7DoWrYsGHaunVrmfFt27Zp2LBhRvQEAADgchwOVd9++626du1aZrxLly5KT083oicAAACX43CoMplMOnv2bJnxvLw8FRcXG9IUAACAq3E4VHXv3l3Tp0+3C1DFxcWaPn267rzzTkObAwAAcBUO3/03Y8YMde/eXS1atFC3bt0kSf/7v/8ri8WiDRs2GN4gAACAK3D4SFVISIh2796thx56SDk5OTp79qyGDh2q/fv3q02bNhXRIwAAQKXn8JEqSQoMDNSrr75qdC8AAAAuy+EjVR988IFWrFhRZnzFihVasmSJQ3NNnz5dnTp1Up06deTn56f+/fvrwIEDdjUXL15UbGys6tevr9q1a2vAgAHKzs62q8nMzFR0dLRq1qwpPz8/jR8/vszvEG7cuFEdOnSQh4eHmjVrpsTExDL9LFiwQE2aNJGnp6fCw8O1fft2h3sBAABVk8Ohavr06WrQoEGZcT8/P4ePXm3atEmxsbH65ptvlJycrEuXLqlXr17Kz8+31YwbN06ff/65VqxYoU2bNunYsWN64IEHbNuLi4sVHR2twsJCbd26VUuWLFFiYqImT55sqzly5Iiio6N11113KT09XWPHjtVjjz2mdevW2WqWLVum+Ph4TZkyRbt27VK7du0UFRWlnJyccvcCAACqLpPVarU68gJPT0/t379fTZo0sRs/evSoWrVqpQsXLlx3MydOnJCfn582bdqk7t27Ky8vT76+vlq6dKkefPBBSdL+/fvVqlUrpaamqkuXLlq7dq369eunY8eOyd/fX5K0ePFiJSQk6MSJEzKbzUpISNCaNWuUkZFh29egQYOUm5urpKQkSVJ4eLg6deqk+fPnS5JKSkoUFBSkMWPGaMKECeXq5VosFou8vb2Vl5cnLy+v6/6cAAAwSpMJa5zdwg07+lp0hc5f3r/fDh+p8vPz0+7du8uMf/fdd6pfv76j09nJy8uTJNWrV0+SlJaWpkuXLikyMtJW07JlS916661KTU2VJKWmpqpt27a2QCVJUVFRslgs2rt3r63m8jlKa0rnKCwsVFpaml2Nm5ubIiMjbTXl6eX3CgoKZLFY7B4AAODm5HCoGjx4sJ588kl99dVXKi4uVnFxsTZs2KCnnnpKgwYNuu5GSkpKNHbsWHXt2tV2F2FWVpbMZrN8fHzsav39/ZWVlWWruTxQlW4v3fZHNRaLRRcuXNDJkydVXFx8xZrL57hWL783ffp0eXt72x5BQUHl/DQAAICrcfjuv5deeklHjx5Vz549Va3aby8vKSnR0KFDb+iOwNjYWGVkZOjrr7++7jkqm4kTJyo+Pt723GKxEKwAALhJORyqzGazli1bppdeeknfffedatSoobZt26px48bX3URcXJxWr16tzZs3q1GjRrbxgIAAFRYWKjc31+4IUXZ2tgICAmw1v79Lr/SOvMtrfn+XXnZ2try8vFSjRg25u7vL3d39ijWXz3GtXn7Pw8NDHh4eDnwSAADAVTl8+q9UvXr1dNddd6lfv37XHaisVqvi4uK0cuVKbdiwQcHBwXbbw8LCVL16daWkpNjGDhw4oMzMTEVEREiSIiIitGfPHru79JKTk+Xl5aWQkBBbzeVzlNaUzmE2mxUWFmZXU1JSopSUFFtNeXoBAABVl0OhKjc3V7GxsWrQoIH8/f3l7++vBg0aKC4uTrm5uQ7vPDY2Vv/+97+1dOlS1alTR1lZWcrKyrLdQejt7a0RI0YoPj5eX331ldLS0jR8+HBFRETY7rbr1auXQkJCNGTIEH333Xdat26dJk2apNjYWNtRolGjRunHH3/Us88+q/3792vhwoVavny5xo0bZ+slPj5e//jHP7RkyRLt27dPo0ePVn5+voYPH17uXgAAQNVV7tN/p0+fVkREhH799Vc98sgjatWqlSTp+++/V2JiolJSUrR161bVrVu33DtftGiRJKlHjx524x988IGGDRsmSZo9e7bc3Nw0YMAAFRQUKCoqSgsXLrTVuru7a/Xq1Ro9erQiIiJUq1YtxcTEaNq0abaa4OBgrVmzRuPGjdPcuXPVqFEjvfvuu4qKirLVDBw4UCdOnNDkyZOVlZWl9u3bKykpye7i9Wv1AgAAqq5yr1M1duxYpaSkaP369WXuksvKylKvXr3Us2dPzZ49u0IavRmwThUAoLJhnaprM3ydqlWrVumNN94oE6ik3y7injlzplauXHl93QIAALi4coeq48ePq3Xr1lfd3qZNm6uu1wQAAHCzK3eoatCggY4ePXrV7UeOHLGthA4AAFDVlDtURUVF6fnnn1dhYWGZbQUFBXrhhRfUu3dvQ5sDAABwFeW++2/atGnq2LGjmjdvrtjYWLVs2VJWq1X79u3TwoULVVBQoH/9618V2SsAAEClVe5Q1ahRI6Wmpurvf/+7Jk6cqNKbBk0mk+655x7Nnz+fn2ABAABVlkM/UxMcHKy1a9fqzJkzOnjwoCSpWbNmXEsFAACqPId/+0+S6tatq86dOxvdCwAAgMu67t/+AwAAwP8hVAEAABiAUAUAAGCAcoWqDh066MyZM5J+W1rh/PnzFdoUAACAqylXqNq3b5/y8/MlSS+++KLOnTtXoU0BAAC4mnLd/de+fXsNHz5cd955p6xWq9544w3Vrl37irWTJ082tEEAAABXUK5QlZiYqClTpmj16tUymUxau3atqlUr+1KTyUSoAgAAVVK5QlWLFi300UcfSZLc3NyUkpIiPz+/Cm0MAADAlTi8+GdJSUlF9AEAAODSrmtF9cOHD2vOnDnat2+fJCkkJERPPfWUmjZtamhzAAAArsLhdarWrVunkJAQbd++XaGhoQoNDdW2bdvUunVrJScnV0SPAAAAlZ7DR6omTJigcePG6bXXXisznpCQoHvuucew5gAAAFyFw0eq9u3bpxEjRpQZf/TRR/X9998b0hQAAICrcThU+fr6Kj09vcx4eno6dwQCAIAqy+HTfyNHjtTjjz+uH3/8UXfccYckacuWLZoxY4bi4+MNbxAAAMAVOByqXnjhBdWpU0ezZs3SxIkTJUmBgYGaOnWqnnzyScMbBAAAcAUOhyqTyaRx48Zp3LhxOnv2rCSpTp06hjcGAADgSq5rnapShCkAAIDfOHyhOgAAAMoiVAEAABiAUAUAAGAAh0LVpUuX1LNnTx08eLCi+gEAAHBJDoWq6tWra/fu3RXVCwAAgMty+PTf3/72N7333nsV0QsAAIDLcnhJhaKiIr3//vtav369wsLCVKtWLbvtb775pmHNAQAAuAqHQ1VGRoY6dOggSfrhhx/stplMJmO6AgAAcDEOh6qvvvqqIvoAAABwade9pMKhQ4e0bt06XbhwQZJktVoNawoAAMDVOByqTp06pZ49e+r2229X3759dfz4cUnSiBEj9PTTTxveIAAAgCtwOFSNGzdO1atXV2ZmpmrWrGkbHzhwoJKSkhyaa/Pmzbr33nsVGBgok8mkVatW2W0fNmyYTCaT3aN37952NadPn9YjjzwiLy8v+fj4aMSIETp37pxdze7du9WtWzd5enoqKChIM2fOLNPLihUr1LJlS3l6eqpt27b64osv7LZbrVZNnjxZDRs2VI0aNRQZGcl6XQAAwMbhUPXll19qxowZatSokd148+bN9dNPPzk0V35+vtq1a6cFCxZctaZ37946fvy47fGf//zHbvsjjzyivXv3Kjk5WatXr9bmzZv1+OOP27ZbLBb16tVLjRs3Vlpaml5//XVNnTpV77zzjq1m69atGjx4sEaMGKFvv/1W/fv3V//+/ZWRkWGrmTlzpubNm6fFixdr27ZtqlWrlqKionTx4kWH3jMAALg5OXyhen5+vt0RqlKnT5+Wh4eHQ3P16dNHffr0+cMaDw8PBQQEXHHbvn37lJSUpB07dqhjx46SpLfeekt9+/bVG2+8ocDAQH344YcqLCzU+++/L7PZrNatWys9PV1vvvmmLXzNnTtXvXv31vjx4yVJL730kpKTkzV//nwtXrxYVqtVc+bM0aRJk3TfffdJkv75z3/K399fq1at0qBBgxx63wAA4Obj8JGqbt266Z///KftuclkUklJiWbOnKm77rrL0OYkaePGjfLz81OLFi00evRonTp1yrYtNTVVPj4+tkAlSZGRkXJzc9O2bdtsNd27d5fZbLbVREVF6cCBAzpz5oytJjIy0m6/UVFRSk1NlSQdOXJEWVlZdjXe3t4KDw+31VxJQUGBLBaL3QMAANycHD5SNXPmTPXs2VM7d+5UYWGhnn32We3du1enT5/Wli1bDG2ud+/eeuCBBxQcHKzDhw/rueeeU58+fZSamip3d3dlZWXJz8/P7jXVqlVTvXr1lJWVJUnKyspScHCwXY2/v79tW926dZWVlWUbu7zm8jkuf92Vaq5k+vTpevHFF6/jnQMAAFfjcKhq06aNfvjhB82fP1916tTRuXPn9MADDyg2NlYNGzY0tLnLT6u1bdtWoaGhatq0qTZu3KiePXsauq+KMHHiRMXHx9ueWywWBQUFObEjAABQURwOVdJvp76ef/55o3u5pttuu00NGjTQoUOH1LNnTwUEBCgnJ8eupqioSKdPn7ZdhxUQEKDs7Gy7mtLn16q5fHvp2OXBMTs7W+3bt79qvx4eHg5fZwYAAFzTdS3+eebMGb3xxhsaMWKERowYoVmzZun06dNG91bGL7/8olOnTtmCTUREhHJzc5WWlmar2bBhg0pKShQeHm6r2bx5sy5dumSrSU5OVosWLVS3bl1bTUpKit2+kpOTFRERIUkKDg5WQECAXY3FYtG2bdtsNQAAoGpzOFRt3rxZTZo00bx583TmzBmdOXNG8+bNU3BwsDZv3uzQXOfOnVN6errS09Ml/XZBeHp6ujIzM3Xu3DmNHz9e33zzjY4ePaqUlBTdd999atasmaKioiRJrVq1Uu/evTVy5Eht375dW7ZsUVxcnAYNGqTAwEBJ0sMPPyyz2awRI0Zo7969WrZsmebOnWt3Wu6pp55SUlKSZs2apf3792vq1KnauXOn4uLiJP12Mf7YsWP18ssv67PPPtOePXs0dOhQBQYGqn///o5+hAAA4CZksjr4+zJt27ZVRESEFi1aJHd3d0lScXGx/v73v2vr1q3as2dPuefauHHjFe8YjImJ0aJFi9S/f399++23ys3NVWBgoHr16qWXXnrJ7oLx06dPKy4uTp9//rnc3Nw0YMAAzZs3T7Vr17bV7N69W7GxsdqxY4caNGigMWPGKCEhwW6fK1as0KRJk3T06FE1b95cM2fOVN++fW3brVarpkyZonfeeUe5ubm68847tXDhQt1+++3lfr8Wi0Xe3t7Ky8uTl5dXuV8HAEBFaTJhjbNbuGFHX4uu0PnL+/fb4VBVo0YNpaenq0WLFnbjBw4cUPv27W2/BYiyCFUAgMqGUHVt5f377fDpvw4dOmjfvn1lxvft26d27do5Oh0AAMBNoVx3/+3evdv2z08++aSeeuopHTp0SF26dJEkffPNN1qwYIFee+21iukSAACgkivX6T83NzeZTCZdq9RkMqm4uNiw5m42nP4DAFQ2nP67tvL+/S7XkaojR44Y1hgAAMDNqFyhqnHjxhXdBwAAgEu7rhXVjx07pq+//lo5OTkqKSmx2/bkk08a0hgAAIArcThUJSYm6oknnpDZbFb9+vVlMpls20wmE6EKAABUSQ6HqhdeeEGTJ0/WxIkT5eZ2Xb9yAwAAcNNxOBWdP39egwYNIlABAABcxuFkNGLECK1YsaIiegEAAHBZDp/+mz59uvr166ekpCS1bdtW1atXt9v+5ptvGtYcAACAq7iuULVu3Trbb//9/kJ1AACAqsjhUDVr1iy9//77GjZsWAW0AwAA4JocvqbKw8NDXbt2rYheAAAAXJbDoeqpp57SW2+9VRG9AAAAuCyHT/9t375dGzZs0OrVq9W6desyF6p/8sknhjUHAADgKhwOVT4+PnrggQcqohcAAACX5XCo+uCDDyqiDwAAAJfGsugAAAAGcPhIVXBw8B+uR/Xjjz/eUEMAAACuyOFQNXbsWLvnly5d0rfffqukpCSNHz/eqL4AAABcisOh6qmnnrri+IIFC7Rz584bbggAAMAVGXZNVZ8+ffTf//7XqOkAAABcimGh6uOPP1a9evWMmg4AAMClOHz67y9/+YvdhepWq1VZWVk6ceKEFi5caGhzAAAArsLhUNW/f3+7525ubvL19VWPHj3UsmVLo/oCAABwKQ6HqilTplREHwAAAC6NxT8BAAAMUO4jVW5ubn+46KckmUwmFRUV3XBTAAAArqbcoWrlypVX3Zaamqp58+appKTEkKYAAABcTblD1X333Vdm7MCBA5owYYI+//xzPfLII5o2bZqhzQEAALiK67qm6tixYxo5cqTatm2roqIipaena8mSJWrcuLHR/QEAALgEh0JVXl6eEhIS1KxZM+3du1cpKSn6/PPP1aZNm4rqDwAAwCWU+/TfzJkzNWPGDAUEBOg///nPFU8HAgAAVFUmq9VqLU+hm5ubatSoocjISLm7u1+17pNPPjGsuZuNxWKRt7e38vLy5OXl5ex2AABQkwlrnN3CDTv6WnSFzl/ev9/lPlI1dOjQay6pAAAAUFWVO1QlJiZWYBsAAACuzakrqm/evFn33nuvAgMDZTKZtGrVKrvtVqtVkydPVsOGDW2nHg8ePGhXc/r0aT3yyCPy8vKSj4+PRowYoXPnztnV7N69W926dZOnp6eCgoI0c+bMMr2sWLFCLVu2lKenp9q2basvvvjC4V4AAEDV5dRQlZ+fr3bt2mnBggVX3D5z5kzNmzdPixcv1rZt21SrVi1FRUXp4sWLtppHHnlEe/fuVXJyslavXq3Nmzfr8ccft223WCzq1auXGjdurLS0NL3++uuaOnWq3nnnHVvN1q1bNXjwYI0YMULffvut+vfvr/79+ysjI8OhXgAAQNVV7gvVK5rJZNLKlSvVv39/Sb8dGQoMDNTTTz+tZ555RtJvSzr4+/srMTFRgwYN0r59+xQSEqIdO3aoY8eOkqSkpCT17dtXv/zyiwIDA7Vo0SI9//zzysrKktlsliRNmDBBq1at0v79+yVJAwcOVH5+vlavXm3rp0uXLmrfvr0WL15crl7KgwvVAQCVDReqX1t5/35X2h9UPnLkiLKyshQZGWkb8/b2Vnh4uFJTUyX99vM4Pj4+tkAlSZGRkXJzc9O2bdtsNd27d7cFKkmKiorSgQMHdObMGVvN5fsprSndT3l6AQAAVVu5L1T/s2VlZUmS/P397cb9/f1t27KysuTn52e3vVq1aqpXr55dTXBwcJk5SrfVrVtXWVlZ19zPtXq5koKCAhUUFNieWyyWP3jHAADAlVXaI1U3g+nTp8vb29v2CAoKcnZLAACgglTaUBUQECBJys7OthvPzs62bQsICFBOTo7d9qKiIp0+fdqu5kpzXL6Pq9Vcvv1avVzJxIkTlZeXZ3v8/PPP13jXAADAVVXaUBUcHKyAgAClpKTYxiwWi7Zt26aIiAhJUkREhHJzc5WWlmar2bBhg0pKShQeHm6r2bx5sy5dumSrSU5OVosWLVS3bl1bzeX7Ka0p3U95erkSDw8PeXl52T0AAMDNyamh6ty5c0pPT1d6erqk3y4IT09PV2Zmpkwmk8aOHauXX35Zn332mfbs2aOhQ4cqMDDQdodgq1at1Lt3b40cOVLbt2/Xli1bFBcXp0GDBikwMFCS9PDDD8tsNmvEiBHau3evli1bprlz5yo+Pt7Wx1NPPaWkpCTNmjVL+/fv19SpU7Vz507FxcVJUrl6AQAAVZtTL1TfuXOn7rrrLtvz0qATExOjxMREPfvss8rPz9fjjz+u3Nxc3XnnnUpKSpKnp6ftNR9++KHi4uLUs2dPubm5acCAAZo3b55tu7e3t7788kvFxsYqLCxMDRo00OTJk+3Wsrrjjju0dOlSTZo0Sc8995yaN2+uVatWqU2bNraa8vQCAACqrkqzTlVVwDpVAIDKhnWqrs3l16kCAABwJYQqAAAAAxCqAAAADECoAgAAMAChCgAAwACEKgAAAAMQqgAAAAxAqAIAADAAoQoAAMAAhCoAAAADEKoAAAAMQKgCAAAwAKEKAADAANWc3QAAoGppMmGNs1swxNHXop3dAioZjlQBAAAYgFAFAABgAEIVAACAAQhVAAAABiBUAQAAGIBQBQAAYABCFQAAgAEIVQAAAAYgVAEAABiAUAUAAGAAQhUAAIABCFUAAAAGIFQBAAAYgFAFAABgAEIVAACAAQhVAAAABiBUAQAAGIBQBQAAYABCFQAAgAEIVQAAAAYgVAEAABiAUAUAAGAAQhUAAIABCFUAAAAGqNShaurUqTKZTHaPli1b2rZfvHhRsbGxql+/vmrXrq0BAwYoOzvbbo7MzExFR0erZs2a8vPz0/jx41VUVGRXs3HjRnXo0EEeHh5q1qyZEhMTy/SyYMECNWnSRJ6engoPD9f27dsr5D0DAADXVKlDlSS1bt1ax48ftz2+/vpr27Zx48bp888/14oVK7Rp0yYdO3ZMDzzwgG17cXGxoqOjVVhYqK1bt2rJkiVKTEzU5MmTbTVHjhxRdHS07rrrLqWnp2vs2LF67LHHtG7dOlvNsmXLFB8frylTpmjXrl1q166doqKilJOT8+d8CAAAoNIzWa1Wq7ObuJqpU6dq1apVSk9PL7MtLy9Pvr6+Wrp0qR588EFJ0v79+9WqVSulpqaqS5cuWrt2rfr166djx47J399fkrR48WIlJCToxIkTMpvNSkhI0Jo1a5SRkWGbe9CgQcrNzVVSUpIkKTw8XJ06ddL8+fMlSSUlJQoKCtKYMWM0YcKEcr8fi8Uib29v5eXlycvL63o/lmtqMmFNhc39Zzn6WrSzWwBQQW6Gf0dJN8+/p26G76Oiv4vy/v2u9EeqDh48qMDAQN1222165JFHlJmZKUlKS0vTpUuXFBkZaatt2bKlbr31VqWmpkqSUlNT1bZtW1ugkqSoqChZLBbt3bvXVnP5HKU1pXMUFhYqLS3NrsbNzU2RkZG2mqspKCiQxWKxewAAgJtTpQ5V4eHhSkxMVFJSkhYtWqQjR46oW7duOnv2rLKysmQ2m+Xj42P3Gn9/f2VlZUmSsrKy7AJV6fbSbX9UY7FYdOHCBZ08eVLFxcVXrCmd42qmT58ub29v2yMoKMjhzwAAALiGas5u4I/06dPH9s+hoaEKDw9X48aNtXz5ctWoUcOJnZXPxIkTFR8fb3tusVgIVgAA3KQq9ZGq3/Px8dHtt9+uQ4cOKSAgQIWFhcrNzbWryc7OVkBAgCQpICCgzN2Apc+vVePl5aUaNWqoQYMGcnd3v2JN6RxX4+HhIS8vL7sHAAC4OblUqDp37pwOHz6shg0bKiwsTNWrV1dKSopt+4EDB5SZmamIiAhJUkREhPbs2WN3l15ycrK8vLwUEhJiq7l8jtKa0jnMZrPCwsLsakpKSpSSkmKrAQAAqNSh6plnntGmTZt09OhRbd26Vffff7/c3d01ePBgeXt7a8SIEYqPj9dXX32ltLQ0DR8+XBEREerSpYskqVevXgoJCdGQIUP03Xffad26dZo0aZJiY2Pl4eEhSRo1apR+/PFHPfvss9q/f78WLlyo5cuXa9y4cbY+4uPj9Y9//ENLlizRvn37NHr0aOXn52v48OFO+VwAAEDlU6mvqfrll180ePBgnTp1Sr6+vrrzzjv1zTffyNfXV5I0e/Zsubm5acCAASooKFBUVJQWLlxoe727u7tWr16t0aNHKyIiQrVq1VJMTIymTZtmqwkODtaaNWs0btw4zZ07V40aNdK7776rqKgoW83AgQN14sQJTZ48WVlZWWrfvr2SkpLKXLwOAACqrkq9TtXNhnWqyu9mWf8FQFk3w7+jpJvn31M3w/dRWdapqtRHqgDAKDfDHw7p5vlDDtyMKvU1VQAAAK6CUAUAAGAAQhUAAIABCFUAAAAGIFQBAAAYgFAFAABgAEIVAACAAQhVAAAABiBUAQAAGIBQBQAAYABCFQAAgAEIVQAAAAbgB5WBCsSP+AJA1cGRKgAAAAMQqgAAAAxAqAIAADAAoQoAAMAAhCoAAAADEKoAAAAMQKgCAAAwAKEKAADAAIQqAAAAAxCqAAAADECoAgAAMAChCgAAwACEKgAAAAMQqgAAAAxAqAIAADAAoQoAAMAAhCoAAAADEKoAAAAMQKgCAAAwAKEKAADAAIQqAAAAAxCqAAAADECoAgAAMAChykELFixQkyZN5OnpqfDwcG3fvt3ZLQEAgEqAUOWAZcuWKT4+XlOmTNGuXbvUrl07RUVFKScnx9mtAQAAJyNUOeDNN9/UyJEjNXz4cIWEhGjx4sWqWbOm3n//fWe3BgAAnIxQVU6FhYVKS0tTZGSkbczNzU2RkZFKTU11YmcAAKAyqObsBlzFyZMnVVxcLH9/f7txf39/7d+//4qvKSgoUEFBge15Xl6eJMlisVRco5JKCs5X6Px/hor+jP4sN8N3Id0c3wffReXBd1G53AzfR0V/F6XzW63WP6wjVFWg6dOn68UXXywzHhQU5IRuXIv3HGd3gMvxfVQefBeVB99F5fFnfRdnz56Vt7f3VbcTqsqpQYMGcnd3V3Z2tt14dna2AgICrviaiRMnKj4+3va8pKREp0+fVv369WUymSq034pksVgUFBSkn3/+WV5eXs5up0rju6g8+C4qD76LyuNm+S6sVqvOnj2rwMDAP6wjVJWT2WxWWFiYUlJS1L9/f0m/haSUlBTFxcVd8TUeHh7y8PCwG/Px8angTv88Xl5eLv0/kpsJ30XlwXdRefBdVB43w3fxR0eoShGqHBAfH6+YmBh17NhRnTt31pw5c5Sfn6/hw4c7uzUAAOBkhCoHDBw4UCdOnNDkyZOVlZWl9u3bKykpqczF6wAAoOohVDkoLi7uqqf7qgoPDw9NmTKlzKlN/Pn4LioPvovKg++i8qhq34XJeq37AwEAAHBNLP4JAABgAEIVAACAAQhVAAAABiBUAQAAGIBQhXLbvHmz7r33XgUGBspkMmnVqlXObqlKmj59ujp16qQ6derIz89P/fv314EDB5zdVpW1aNEihYaG2hY3jIiI0Nq1a53dVpX32muvyWQyaezYsc5upUqaOnWqTCaT3aNly5bObqvCEapQbvn5+WrXrp0WLFjg7FaqtE2bNik2NlbffPONkpOTdenSJfXq1Uv5+fnObq1KatSokV577TWlpaVp586duvvuu3Xfffdp7969zm6tytqxY4fefvtthYaGOruVKq1169Y6fvy47fH11187u6UKxzpVKLc+ffqoT58+zm6jyktKSrJ7npiYKD8/P6Wlpal79+5O6qrquvfee+2ev/LKK1q0aJG++eYbtW7d2kldVV3nzp3TI488on/84x96+eWXnd1OlVatWrWr/jbuzYojVYCLy8vLkyTVq1fPyZ2guLhYH330kfLz8xUREeHsdqqk2NhYRUdHKzIy0tmtVHkHDx5UYGCgbrvtNj3yyCPKzMx0dksVjiNVgAsrKSnR2LFj1bVrV7Vp08bZ7VRZe/bsUUREhC5evKjatWtr5cqVCgkJcXZbVc5HH32kXbt2aceOHc5upcoLDw9XYmKiWrRooePHj+vFF19Ut27dlJGRoTp16ji7vQpDqAJcWGxsrDIyMqrEtQqVWYsWLZSenq68vDx9/PHHiomJ0aZNmwhWf6Kff/5ZTz31lJKTk+Xp6ensdqq8yy8VCQ0NVXh4uBo3bqzly5drxIgRTuysYhGqABcVFxen1atXa/PmzWrUqJGz26nSzGazmjVrJkkKCwvTjh07NHfuXL399ttO7qzqSEtLU05Ojjp06GAbKy4u1ubNmzV//nwVFBTI3d3diR1WbT4+Prr99tt16NAhZ7dSoQhVgIuxWq0aM2aMVq5cqY0bNyo4ONjZLeF3SkpKVFBQ4Ow2qpSePXtqz549dmPDhw9Xy5YtlZCQQKBysnPnzunw4cMaMmSIs1upUIQqlNu5c+fs/ivjyJEjSk9PV7169XTrrbc6sbOqJTY2VkuXLtWnn36qOnXqKCsrS5Lk7e2tGjVqOLm7qmfixInq06ePbr31Vp09e1ZLly7Vxo0btW7dOme3VqXUqVOnzHWFtWrVUv369bne0AmeeeYZ3XvvvWrcuLGOHTumKVOmyN3dXYMHD3Z2axWKUIVy27lzp+666y7b8/j4eElSTEyMEhMTndRV1bNo0SJJUo8ePezGP/jgAw0bNuzPb6iKy8nJ0dChQ3X8+HF5e3srNDRU69at0z333OPs1gCn+eWXXzR48GCdOnVKvr6+uvPOO/XNN9/I19fX2a1VKJPVarU6uwkAAABXxzpVAAAABiBUAQAAGIBQBQAAYABCFQAAgAEIVQAAAAYgVAEAABiAUAUAAGAAQhUAGGjjxo0ymUzKzc11disA/mSEKgBV0rBhw2QymWQymVS9enUFBwfr2Wef1cWLF8s9R48ePTR27Fi7sTvuuMO2ujqAqoWfqQFQZfXu3VsffPCBLl26pLS0NMXExMhkMmnGjBnXPafZbFZAQICBXQJwFRypAlBleXh4KCAgQEFBQerfv78iIyOVnJwsSTp16pQGDx6sW265RTVr1lTbtm31n//8x/baYcOGadOmTZo7d67tiNfRo0fLnP5LTEyUj4+P1q1bp1atWql27drq3bu3jh8/bpurqKhITz75pHx8fFS/fn0lJCQoJiZG/fv3/zM/DgA3iFAFAJIyMjK0detWmc1mSdLFixcVFhamNWvWKCMjQ48//riGDBmi7du3S5Lmzp2riIgIjRw5UsePH9fx48cVFBR0xbnPnz+vN954Q//617+0efNmZWZm6plnnrFtnzFjhj788EN98MEH2rJliywWi1atWlXh7xmAsTj9B6DKWr16tWrXrq2ioiIVFBTIzc1N8+fPlyTdcsstdsFnzJgxWrdunZYvX67OnTvL29tbZrNZNWvWvObpvkuXLmnx4sVq2rSpJCkuLk7Tpk2zbX/rrbc0ceJE3X///ZKk+fPn64svvjD67QKoYIQqAFXWXXfdpUWLFik/P1+zZ89WtWrVNGDAAElScXGxXn31VS1fvly//vqrCgsLVVBQoJo1azq8n5o1a9oClSQ1bNhQOTk5kqS8vDxlZ2erc+fOtu3u7u4KCwtTSUnJDb5DAH8mTv8BqLJq1aqlZs2aqV27dnr//fe1bds2vffee5Kk119/XXPnzlVCQoK++uorpaenKyoqSoWFhQ7vp3r16nbPTSaTrFarIe8BQOVBqAIASW5ubnruuec0adIkXbhwQVu2bNF9992nv/3tb2rXrp1uu+02/fDDD3avMZvNKi4uvqH9ent7y9/fXzt27LCNFRcXa9euXTc0L4A/H6EKAP5///M//yN3d3ctWLBAzZs3V3JysrZu3ap9+/bpiSeeUHZ2tl19kyZNtG3bNh09elQnT5687tN1Y8aM0fTp0/Xpp5/qwIEDeuqpp3TmzBmZTCYj3haAPwmhCgD+f9WqVVNcXJxmzpypp59+Wh06dFBUVJR69OihgICAMkscPPPMM3J3d1dISIh8fX2VmZl5XftNSEjQ4MGDNXToUEVERKh27dqKioqSp6enAe8KwJ/FZOXEPgBUKiUlJWrVqpUeeughvfTSS85uB0A5cfcfADjZTz/9pC+//FJ//etfVVBQoPnz5+vIkSN6+OGHnd0aAAdw+g8AnMzNzU2JiYnq1KmTunbtqj179mj9+vVq1aqVs1sD4ABO/wEAABiAI1UAAAAGIFQBAAAYgFAFAABgAEIVAACAAQhVAAAABiBUAQAAGIBQBQAAYABCFQAAgAEIVQAAAAb4/wDRM5LNTXH8lAAAAABJRU5ErkJggg=="},"metadata":{}}]},{"cell_type":"markdown","source":"**The distribution is heavily skewed to the positive side, with 5 star reviews making up more than half of our dataset. While that's great for Amazon and its customers, it could bias our model and starve it of adequate negative and neutral reviews to train on.**\n\n**To work around this we balance the data. 29,769 reviewers gave products a 2, the fewest for any rating, so that is the maximum numbers of reviews we can use in each category.  Fret not, that is still a vast amount of data to work with, but we may need to reduce it even futher during development to reduce the processing load.**","metadata":{}},{"cell_type":"code","source":"balanced_data_size = 1000 #<< number of reviews in each rating category, tailored for CPU capacity\n# Specify the column for sorting and balancing\nsort_column = 'Score'  # This is one the rating column\n\n# Sort the data by the rating values\nsorted_data = data.sort_values(by = sort_column)\n\n# Create a balanced dataset with 25,000 samples from each class\n#balanced_data = sorted_data.groupby(sort_column).apply(lambda x: x.sample(n=25000))\n\n#>> DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. \n#>> This behavior is deprecated, and in a future version of pandas the grouping \n#>> columns will be excluded from the operation. \n#>> Either pass `include_groups=False` to exclude the groupings or \n#>> explicitly select the grouping columns after groupby to silence this warning.\n#\nbalanced_data = sorted_data.groupby(sort_column).apply(lambda x: x.sample(n = balanced_data_size))\n\n#>> Does this mean to reset the row numbers?? ##Columns Numbers\nbalanced_data.reset_index(drop = True, inplace = True)\n\nprintv(f\"The number of reviews equally distributed across all ratings is {len(balanced_data['Score'])}\")","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:08:20.885408Z","iopub.execute_input":"2024-03-30T05:08:20.886153Z","iopub.status.idle":"2024-03-30T05:08:21.240714Z","shell.execute_reply.started":"2024-03-30T05:08:20.886079Z","shell.execute_reply":"2024-03-30T05:08:21.239469Z"},"trusted":true},"execution_count":6,"outputs":[{"name":"stdout","text":"VERBOSE: The number of reviews equally distributed across all ratings is 5000\n","output_type":"stream"},{"name":"stderr","text":"/tmp/ipykernel_33/1260224495.py:17: DeprecationWarning: DataFrameGroupBy.apply operated on the grouping columns. This behavior is deprecated, and in a future version of pandas the grouping columns will be excluded from the operation. Either pass `include_groups=False` to exclude the groupings or explicitly select the grouping columns after groupby to silence this warning.\n  balanced_data = sorted_data.groupby(sort_column).apply(lambda x: x.sample(n = balanced_data_size))\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**We can use matplotlib to see that reviews are equally distributed across all rating categories in the balanced data.**","metadata":{}},{"cell_type":"code","source":"# Get count of ratings\nrating_counts = balanced_data['Score'].value_counts()\n\n# Create bar plot\nax = rating_counts.plot(kind='bar')\n\nax.set_title(\"Ratings Distribution After Balancing\")\nax.set_xlabel(\"Rating\")\nax.set_ylabel(\"Number of Samples\")\n\n# Fix x-axis ticks  \nax.set_xticklabels(ax.get_xticklabels(), rotation = 0)\n\n# Print number of reviews per rating\n\nif DEV:\n    for rating, count in rating_counts.items():\n        print(f\"{count:,} samples from balanced data with rating {rating}\\n\")\n\nplt.show()","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:08:21.242396Z","iopub.execute_input":"2024-03-30T05:08:21.242854Z","iopub.status.idle":"2024-03-30T05:08:21.529085Z","shell.execute_reply.started":"2024-03-30T05:08:21.242814Z","shell.execute_reply":"2024-03-30T05:08:21.527830Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"1,000 samples from balanced data with rating 1\n\n1,000 samples from balanced data with rating 2\n\n1,000 samples from balanced data with rating 3\n\n1,000 samples from balanced data with rating 4\n\n1,000 samples from balanced data with rating 5\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"**That looks much better. We see that each rating class is sufficiently represented, and we can expect to get a more well-rounded analyzer. While this is a good way to even things out, our model can still be biased due to the reviews themselves. People leave comments when they have stronger opinions about a product. This is why balancing the types of reviews we give our model is necessary, so that the model can get a complete representation of the range of opinions**\n\n**We will also encounter things like typos, improper punctuation and spacing, along with other grammatical issues. While we will leave the dataset as is for now, it is important to try other approaches to identify these issues and filter them out.**\n\n**Now that we have our dataset ready, let's get to work on preprocessing it. Our reviews contain things like punctuations that we don't need to work with. To get rid of these, we use regular expressions to filter them out, and convert every character to lowercase to achieve uniformity.**\n\n**Something else we can do is a process called Lemmatization. This is the process of replacing variants of a word by the base word itself. An example of this would be to change the words knew, knowing, and known to their base word: know. This will help us achieve better uniformity by avoiding the misplacement of a word's variants.** <span style=\"color:blue\">Do you actually use the lemmatizer?","metadata":{}},{"cell_type":"code","source":"stop = stopwords.words('english') # Imported from nltk.corpus\nlem = WordNetLemmatizer()         # Imported from nltk.stem","metadata":{"_kg_hide-input":true,"execution":{"iopub.status.busy":"2024-03-30T05:08:21.530685Z","iopub.execute_input":"2024-03-30T05:08:21.531120Z","iopub.status.idle":"2024-03-30T05:08:21.541614Z","shell.execute_reply.started":"2024-03-30T05:08:21.531079Z","shell.execute_reply":"2024-03-30T05:08:21.540372Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"stop = sorted(stop) #it's easier to use if it's sorted\nshowD (f'{stop}\\n')\n# No need printd (f'{lem}\\n')\n\n# test lemmatizer\nword = \"dogs\"\nlemmatized_word = lem.lemmatize(word)\nshowD(f'The lemmatized version of \"{word}\" is \"{lemmatized_word}\".')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:08:21.543355Z","iopub.execute_input":"2024-03-30T05:08:21.543844Z","iopub.status.idle":"2024-03-30T05:08:24.110338Z","shell.execute_reply.started":"2024-03-30T05:08:21.543802Z","shell.execute_reply":"2024-03-30T05:08:24.109120Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"VERBOSE: ['a', 'about', 'above', 'after', 'again', 'against', 'ain', 'all', 'am', 'an', 'and', 'any', 'are', 'aren', \"aren't\", 'as', 'at', 'be', 'because', 'been', 'before', 'being', 'below', 'between', 'both', 'but', 'by', 'can', 'couldn', \"couldn't\", 'd', 'did', 'didn', \"didn't\", 'do', 'does', 'doesn', \"doesn't\", 'doing', 'don', \"don't\", 'down', 'during', 'each', 'few', 'for', 'from', 'further', 'had', 'hadn', \"hadn't\", 'has', 'hasn', \"hasn't\", 'have', 'haven', \"haven't\", 'having', 'he', 'her', 'here', 'hers', 'herself', 'him', 'himself', 'his', 'how', 'i', 'if', 'in', 'into', 'is', 'isn', \"isn't\", 'it', \"it's\", 'its', 'itself', 'just', 'll', 'm', 'ma', 'me', 'mightn', \"mightn't\", 'more', 'most', 'mustn', \"mustn't\", 'my', 'myself', 'needn', \"needn't\", 'no', 'nor', 'not', 'now', 'o', 'of', 'off', 'on', 'once', 'only', 'or', 'other', 'our', 'ours', 'ourselves', 'out', 'over', 'own', 're', 's', 'same', 'shan', \"shan't\", 'she', \"she's\", 'should', \"should've\", 'shouldn', \"shouldn't\", 'so', 'some', 'such', 't', 'than', 'that', \"that'll\", 'the', 'their', 'theirs', 'them', 'themselves', 'then', 'there', 'these', 'they', 'this', 'those', 'through', 'to', 'too', 'under', 'until', 'up', 've', 'very', 'was', 'wasn', \"wasn't\", 'we', 'were', 'weren', \"weren't\", 'what', 'when', 'where', 'which', 'while', 'who', 'whom', 'why', 'will', 'with', 'won', \"won't\", 'wouldn', \"wouldn't\", 'y', 'you', \"you'd\", \"you'll\", \"you're\", \"you've\", 'your', 'yours', 'yourself', 'yourselves']\n\nVERBOSE: The lemmatized version of \"dogs\" is \"dog\".\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Let's create a function that takes our reviews and returns a lemmanized, lower-case, punctuation-free version of it.** **We can then store this new version in a new column called 'CleanedReview' for easy access.**\n\n***Heads up: This cell takes a little longer to execute.***","metadata":{}},{"cell_type":"code","source":"# Takes some time to run\n# >> 3/29/24 Took less than 15 seconds to run \n\ndef tokenizer(text):\n    \"\"\"\n    Tokenizes a text string and removes stop words.\n\n    Args:\n        text (str): The text string to tokenize.\n\n    Returns:\n        list: The tokenized text string.\n    \"\"\"\n    text = text.lower()  # Convert text to lowercase.\n    text = re.sub(\"<.*?>\", \"\", text)  # Remove HTML tags.\n    text = re.sub('[^\\w\\s\\']+', \"\", text)  # Remove punctuation and symbols.\n    # text = text.split('\\n')  # Split text on new lines.\n    \n    #>> Have we decided not to use stop words?\n    text = [lem.lemmatize(word) for word in text.split()]#if word not in stop]  # Remove stop words. \n\n    return text\n\n# Apply the function to the Text column and store it in a new column\nbalanced_data['CleanedReview'] = balanced_data['Text'].apply(tokenizer)\n\n# show that cell has finished executing\nshowC(f'{tokenizer} defined, and then used to create CleanedReview column')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:08:24.115589Z","iopub.execute_input":"2024-03-30T05:08:24.115946Z","iopub.status.idle":"2024-03-30T05:08:27.279588Z","shell.execute_reply.started":"2024-03-30T05:08:24.115918Z","shell.execute_reply":"2024-03-30T05:08:27.278158Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"Cell complete: <function tokenizer at 0x7b53c11c0ee0> defined, and then used to create CleanedReview column\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Another look at the data after the addition of the CleanedReview column.**","metadata":{}},{"cell_type":"code","source":"# Store the Rating column\nrating = balanced_data['Score']  \n\n# Store the CleanedReview column\ntokenized_review = balanced_data['CleanedReview']\nshowD(f'specify the columns that will be used to train the classifier')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:08:27.281569Z","iopub.execute_input":"2024-03-30T05:08:27.282016Z","iopub.status.idle":"2024-03-30T05:08:27.290311Z","shell.execute_reply.started":"2024-03-30T05:08:27.281977Z","shell.execute_reply":"2024-03-30T05:08:27.288740Z"},"trusted":true},"execution_count":11,"outputs":[{"name":"stdout","text":"VERBOSE: specify the columns that will be used to train the classifier\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**We can see that our data now has 11 columns, with the addition of CleanReview, and that the CleanedReview column is the product review mapped to a sequence of standardized words.**","metadata":{}},{"cell_type":"markdown","source":"**There are just a few more steps remaining before we can load the data. We have to tokenize the words from the reviews because neural networks, much like computers, don't really understand words. Instead, our tokenizer is going to associate every word with a number that can be used to look up the word's embeddings.**\n\n**Think of embeddings as vector representations of the word in space.**\n\n**There are many approaches we can take to vectorizing our reviews, so much so in fact that word embeddings are a big part of Natural Language Processing. Without getting too bogged down in details, some approaches use statistical approaches like bag-of-words to figure out context, and others can use neural network-based models that are trained to find features themselves.** \n\n**The quickest way would be to take an already trained tokenizer made for established transformer-based models. For example, the BertTokenizer is a tokenizer that was trained and used by BERT. BERT is a massive Transformer-based model created by Google in 2018. It was a significant achievement because it was able to perform up to 11 NLP tasks, including summarization, text-generation(think ChatGPT), and even sentiment analysis.**\n\n**Word2vec-google-news-300 is a pre-trained deep-learning word embedding model that was trained on a massive dataset of 100 billion words from the Google News corpus. The model contains 300-dimensional vectors for 3 million words and phrases. That is what we will be using for this project**\n\n**Word2Vec extracts both semantic and contextual representations of words. The semantic representation of a word captures the meaning of the word itself, while the contextual representation captures the meaning of the word in the context of the surrounding words.**\n\n**To explain what's happening in the Word2Vec embedding process:**\n\n1. **The tokenizer splits the raw text into tokens/words.**\n2. **Word2Vec has IDs that serve as indices into a lookup table that stores the vector representations, meaning that each ID corresponds to a unique vector representation in the table.**\n3. **For each token, we lookup the corresponding ID in the Word2Vec vocabulary using .key_to_index.**\n4. **This maps the tokens to existing Word2Vec IDs.**\n5. **We pass these IDs into the embedding layer.**\n6. **The embedding layer has a 300-dim vector for each ID.**\n7. **So each token gets replaced by its pre-trained 300-dim Word2Vec vector.**\n\n**To summarize:**\n\n* **Tokenizer splits text into words.**\n* **Word2Vec vocab provides ID for each word.**\n* **Embedding layer maps IDs to 300-dim vectors.**\n* **So tokens are replaced by 300-dim pretrained embeddings.**","metadata":{}},{"cell_type":"markdown","source":"**Let's start by downloading our word2vec model and set a variable we will use to limit the number of out tokens per review to 100 tokens. We will later zero-pad these reviews so we can have a uniform number of tokens per review.**\n\n\n***Heads up: This cell will take some time to execute.***","metadata":{}},{"cell_type":"code","source":"# >> 3/29/24 Took less than a minute to run without the accelerator.\n# Load Word2Vec model\n#w2v = api.load('word2vec-google-news-300')\nw2v = KeyedVectors.load_word2vec_format (w2v_file, binary=True)\n\n# Define the aimum sequence length (adjust as needed)\n#>> Will increasing max_sequence_length impact performance?\nmax_sequence_length = 100\n\nshowD(f'{w2v} can map words onto vectors with 300 dimensions')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:08:27.292328Z","iopub.execute_input":"2024-03-30T05:08:27.292746Z","iopub.status.idle":"2024-03-30T05:09:53.561492Z","shell.execute_reply.started":"2024-03-30T05:08:27.292718Z","shell.execute_reply":"2024-03-30T05:09:53.560131Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"VERBOSE: KeyedVectors<vector_size=300, 3000000 keys> can map words onto vectors with 300 dimensions\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Now that we have downloaded our model, let's use our CUDA-enabled GPU to take our token and look for its corresponding vector from our model. Once we find it, we swap it out with the new vector and if we don't, we pad that token with zeros.**","metadata":{}},{"cell_type":"code","source":"# Checks if a CUDA enabled GPU is available and prints out its information\nif torch.cuda.is_available():\n    print(\"CUDA is available!\")\n    for i in range(torch.cuda.device_count()):\n        print(f\"GPU {i}: {torch.cuda.get_device_name(i)}\")\n        \n    device = torch.device(\"cuda:0\")\n    accelerator = True\n\nelse:\n    accelerator = False\n    print(\"CUDA is not available.\")\n    device = torch.device(\"cpu\")\n    print(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:09:53.563241Z","iopub.execute_input":"2024-03-30T05:09:53.563627Z","iopub.status.idle":"2024-03-30T05:09:53.571069Z","shell.execute_reply.started":"2024-03-30T05:09:53.563598Z","shell.execute_reply":"2024-03-30T05:09:53.569832Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"CUDA is not available.\ncpu\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**After ensuring that we have our GPUs available, we can go onto the next step. The code continues even if a CUDA is not available.**\n\n**In the cell below, we will do the following:**\n\n* **Create a new tensor and populate it with zeros**\n* **Compare the length of our review to the maximum length we allow (100) and take the minimum of the two**\n* **We lookup the token against what's in the w2v model. If we find it, we replace it with the embedding.**\n* **If we can't find it, we leave it as is (zero vectors).**","metadata":{}},{"cell_type":"markdown","source":"***Heads Up: Cell below takes about 5 minutes to run***","metadata":{}},{"cell_type":"code","source":"#>> 3/29/24 Completed in less than 30 seconds using 1347 as max_sequence_length \n\n# Assume you have a list of tokenized review called tokenized_review\n# Each element in tokenized_review is a list of tokens for a single review\n\nlengths = []\nfor review_tokens in tokenized_review:\n   lengths.append(len(review_tokens))\n        \nlengths = sorted(lengths)\nlengths = lengths[-1:0:-1]\nshowD(f'Lengths of 100 longest reviews: {lengths[0:100]}')        \n\nmax_sequence_length = 1347 #<< 3/29/24 1347 was the longest review length in sample\n# Initialize an empty tensor for padded reviews on the GPU\npadded_reviews = torch.zeros((len(tokenized_review), max_sequence_length, 300))#, device = device\n\nout_words = {}\nwords_in = 0\nwords_out = 0\n# Pad shorter reviews and convert tokens to Word2Vec embeddings\nfor i, review_tokens in enumerate(tokenized_review):\n    review_length = min(len(review_tokens), max_sequence_length)\n    for j in range(review_length):\n        word = review_tokens[j]\n        if word in w2v:\n            words_in += 1\n            # Use Word2Vec vector if available and move to GPU\n            padded_reviews[i, j, :] = torch.tensor(w2v[word])#, device = device\n        else:\n            words_out += 1\n            try:\n                out_words[word] +=1\n            except:\n                 out_words[word] = 1\n                \n        # Otherwise, it remains as zeros (padding)\nprintv(f'{words_in} words found with vector representations, {words_out} without')\nprintv(f'Number of unique words without vector representations: {len(out_words)}')\nprintd('Sample of words without vector representations')\nkwords = list(out_words.keys())\nfor idx in range(0,len(kwords)-1,100):\n    kword = kwords[idx]\n    printd(f'{kword} - {out_words[kword]}')\n# Apply max pooling to aggregate embeddings along the sequence dimension\n# review_embeddings = torch.max(padded_reviews, dim=1)[0]\n\n# Now,review_embeddings contains the aggregated Word2Vec \n# embeddings for each review on the GPU\n\nshowC(f\"Created zero-padded, standard length reviews\")","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:09:53.573271Z","iopub.execute_input":"2024-03-30T05:09:53.573622Z","iopub.status.idle":"2024-03-30T05:10:18.925611Z","shell.execute_reply.started":"2024-03-30T05:09:53.573594Z","shell.execute_reply":"2024-03-30T05:10:18.923147Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"VERBOSE: Lengths of 100 longest reviews: [1029, 841, 841, 841, 841, 767, 727, 679, 654, 652, 632, 627, 594, 581, 561, 551, 538, 538, 537, 535, 532, 524, 499, 498, 497, 497, 491, 473, 472, 472, 469, 459, 453, 453, 452, 451, 444, 444, 444, 441, 435, 433, 432, 424, 424, 423, 415, 413, 412, 411, 409, 406, 401, 400, 396, 393, 392, 386, 379, 378, 376, 376, 376, 368, 368, 366, 362, 361, 360, 358, 356, 355, 354, 351, 349, 348, 348, 346, 344, 344, 343, 343, 341, 341, 340, 340, 339, 336, 335, 334, 334, 333, 333, 330, 326, 323, 322, 322, 322, 321]\nVERBOSE: 372964 words found with vector representations, 56924 without\nVERBOSE: Number of unique words without vector representations: 7905\nDEV: Sample of words without vector representations\nDEV: a - 13990\nDEV: 5ounce - 3\nDEV: 11 - 36\nDEV: 'excellent' - 1\nDEV: 19950is - 1\nDEV: progressi - 1\nDEV: sudsingi - 1\nDEV: 56 - 3\nDEV: draculaura - 1\nDEV: oswego - 1\nDEV: glutino - 5\nDEV: sawthey - 1\nDEV: kellog's - 1\nDEV: disappointedthank - 1\nDEV: fullbodied - 8\nDEV: 4000 - 2\nDEV: statespam - 1\nDEV: brandwe - 1\nDEV: fillersunfortunately - 1\nDEV: justwatery - 1\nDEV: packagesit's - 1\nDEV: eatretail - 1\nDEV: egbert - 1\nDEV: chun's - 2\nDEV: promisingit - 1\nDEV: thesewe - 2\nDEV: peppersour - 1\nDEV: chocolatelike - 2\nDEV: periodi'm - 1\nDEV: foodi've - 1\nDEV: kitchen's - 1\nDEV: allit - 1\nDEV: average' - 1\nDEV: customeralso - 1\nDEV: seedsoverall - 1\nDEV: quicklywhile - 1\nDEV: bitterthe - 1\nDEV: chemicaledge - 1\nDEV: dehydratedfreeze - 1\nDEV: highintaste - 1\nDEV: cupmy - 1\nDEV: mountainnot - 1\nDEV: evenflo - 1\nDEV: costbenefit - 1\nDEV: combinationthis - 1\nDEV: each2376 - 1\nDEV: 2500 - 2\nDEV: supplementvitamin - 1\nDEV: potato's - 1\nDEV: ig4u - 1\nDEV: greatnewman's - 1\nDEV: 845 - 4\nDEV: 18yearold - 1\nDEV: pkg's - 1\nDEV: balancedstrong - 1\nDEV: accentsi - 1\nDEV: bowlproscheapflavorfuldelishconsbottom - 1\nDEV: pamthere - 1\nDEV: chocolatesomewhat - 1\nDEV: lightfrench - 1\nDEV: sodalemon - 1\nDEV: organic's - 1\nDEV: carbonationthe - 1\nDEV: soupi - 1\nDEV: isfasteasy - 1\nDEV: emerald's - 1\nDEV: temperaturei - 1\nDEV: tasta - 1\nDEV: 1130i - 1\nDEV: focd - 1\nDEV: packthese - 1\nDEV: foodhave - 1\nDEV: pucker24 - 1\nDEV: 300mgsday - 1\nDEV: treatscouldnt - 1\nDEV: tooflavor - 1\nDEV: fdawhat - 1\nDEV: decafi'm - 1\nDEV: merwhile - 1\nDEV: cotswold - 2\nCell complete: Created zero-padded, standard length reviews\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Once we have our embeddings ready, we can prepare them as inputs for the model. The next step is to convert our inputs, now converted to embedding-rich vectors, to tensors. Tensors are a kind of data structure that store information in multidimensional space. They are a generalization of vectors and matrices, and can have any number of dimensions.**\n\n**Converting vectors to tensors is computationally expensive, which is one of the reasons why GPUs are the main processors used in AI. GPUs are specialized for performing parallel computations, which makes them ideal for tasks such as tensor conversion.**\n\n**But first, a quick introduction to PyTorch. PyTorch is a popular deep learning framework that provides a lot of resources for building deep learning architectures, including popular pretrained models. It has become prevalent in academia, research, and industry, being utilized by Tesla, Uber, Hugging Face, and many more.**\n\n**PyTorch will help us convert our vectors to tensors. It also support GPU acceleration. CUDA is a firmware developed by NVIDIA that allows GPUs to be used for general-purpose computing, such as tensor conversion.**\n\n**Once the embeddings have been converted to tensors, we can print out the dimensions of our new dataset. This will tell us how many data points we have and how many features each data point has. We can then load the dataset to our data loaders, which will prepare it for training the neural network.**","metadata":{}},{"cell_type":"markdown","source":"![Tensors](https://hkilter.com/images/7/7a/Tensors.png)\n\n* Source: [What is Tensor](https://hkilter.com/index.php?title=What_is_Tensor%3F)","metadata":{}},{"cell_type":"markdown","source":"**When we utilize tokenization and convert them to their embeddings, we are only doing this for one instance of them to avoid redundancy. So for example, if the word \"the\" appears 2000 times, it would only count once for unique tokens.**\n\n*For example, if  a total of 39,753 unique tokens were converted to vectors, then there could be, say, 9,373,966 total number of tokens, with duplicates converted into tensors and stored in our GPU.*\n\n**Since this Word2Vec model is trained on a huge corpus, it likely has vectors for the vast majority of tokens we extracted. The only ones missing would be very rare or irregular words.**\n\n***Note: It is imporant to remember that we are not just using this vocabulary as a look-up dictionary. That's just a small part of the step. What we are doing is far more advanced. The embeddings are rich contextual vectors that will highlight the relationships between words in different ways. For example, lexicographically speaking, the word 'car' is more similar to 'cat', but when viewed semantically, and/or in terms of its context, it is far more similar to 'dog'. Same goes for the word 'bank', which can be used to refer to a financial institution or the side of a river. These kinds of relationships are the foundation for our model and will serve as the basis for how it perceives them.***","metadata":{}},{"cell_type":"code","source":"#print(torch.cuda.memory_summary())\nprintM() # print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:10:18.928832Z","iopub.execute_input":"2024-03-30T05:10:18.930117Z","iopub.status.idle":"2024-03-30T05:10:18.939675Z","shell.execute_reply.started":"2024-03-30T05:10:18.930065Z","shell.execute_reply":"2024-03-30T05:10:18.938166Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"Total allocated memory: 0 bytes\n","output_type":"stream"}]},{"cell_type":"code","source":"#>> padded_reviews are 100 x 300 tensors, zero padded if necessary\n#>> to get the standard lenth\ntext_embeddings_tensors = padded_reviews.to(device)\n\n# Rating labels\nrating_labels_tensors = torch.tensor(rating.values).to(device)\n\n# Dataset\ndataset = TensorDataset(text_embeddings_tensors, rating_labels_tensors)\nshowC(f'{dataset} defined')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:10:18.941825Z","iopub.execute_input":"2024-03-30T05:10:18.942762Z","iopub.status.idle":"2024-03-30T05:10:18.960167Z","shell.execute_reply.started":"2024-03-30T05:10:18.942721Z","shell.execute_reply":"2024-03-30T05:10:18.959201Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"Cell complete: <torch.utils.data.dataset.TensorDataset object at 0x7b53c1209330> defined\n","output_type":"stream"}]},{"cell_type":"code","source":"printM() # print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\nprintNv() #!nvidia-smi\nprint('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\nif accelerator and showNv:\n    print(torch.cuda.memory_summary())","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:11:55.660470Z","iopub.execute_input":"2024-03-30T05:11:55.661071Z","iopub.status.idle":"2024-03-30T05:11:55.670264Z","shell.execute_reply.started":"2024-03-30T05:11:55.661030Z","shell.execute_reply":"2024-03-30T05:11:55.668724Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Total allocated memory: 0 bytes\n\n\n\n\n\n\n\n\n\n\n\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**Our output confirms that we have successfully converted our data to tensors and is now loaded on our GPU. The output shows that CUDA is available and the GPU name is Tesla P100-PCIE-16GB. The text_tensor and rating_tensor are both on the GPU (device='cuda:0'). The shape of the text_tensor is torch.Size([125000, 100, 300]), which means that it has 125000 rows, 100 columns, with 300 embeddings per column. The shape of the rating_tensor is torch.Size([125000]), which means that it has 125000 rows (ratings). The mean of the rating_tensor is 3 meaning that the we have perfectly divided all our ratings.**","metadata":{}},{"cell_type":"markdown","source":"![numeric_tensors](https://miro.medium.com/v2/resize:fit:1400/1*Shsgt3h9yxlQwjkfIptfYQ.png)\n\n* Source: [From Vectors to Tensors: Exploring the Mathematics of Tensor Algebra](https://towardsdatascience.com/what-are-tensors-in-machine-learning-5671814646ff)","metadata":{}},{"cell_type":"markdown","source":"**We can now split our dataset into training and validation sets. When working on machine learning or deep learning models, we want to train the model on a subset of the data, and then test the accuracy of the model's predictions on the remaining data. This is called data splitting. We typically split the data into an 80/20 split, where we train the model on 80% of the data and test it on the remaining 20%.**","metadata":{}},{"cell_type":"markdown","source":"**And there we have it! It looks like we have successfully split our data 80/20, and are now going to load the tensors in batches to our training and validation loaders. We will use these to load our data into the model once we have finished building it. We have also stored the data in batches of 32. This will make it easier to process the data instead of dealing with the whole thing at once. To confirm that it is all loaded, we can see that the number of batches, 3,125, multiplied by the batch size, 32, will indeed return 125,000**","metadata":{}},{"cell_type":"markdown","source":"**We have successfully completed the preprocessing, splitting, and loading of our data. This section may have felt overwhelming, but it is important to remember that preparing the data properly is just as important as building the model. In fact, it is often said that 80% of the work in machine learning is in data preparation. This is because the quality of the data will have a significant impact on the performance of the model.**","metadata":{}},{"cell_type":"markdown","source":"**And now for the really exciting part: the Transformer, the T in Chat-GPT. Arguably one of the most impactful architectures in recent history, the Transformer has been the state of the art in natural language processing (NLP) and other sequence-to-sequence tasks. In this section, we will break down and build on the individual components of this architecture, and use it to create our sentiment analyzer.**","metadata":{}},{"cell_type":"markdown","source":"# Section 2: The Sentiment Analyzer","metadata":{}},{"cell_type":"markdown","source":"![Detailed Architecture Diagram](https://lena-voita.github.io/resources/lectures/seq2seq/transformer/model-min.png)\n\n* Source: [Sequence to Sequence (seq2seq) and Attention](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html)","metadata":{}},{"cell_type":"markdown","source":"**Above is a diagram of what the Transformer architecture looks like. It might look complicated, but each cell will work on one component of the layer so we can isolate and understand the various sections of our model.**\n\n***Heads Up: Since we are building a sentiment analyzer, we will not be generating any outputs. Instead we will just use a simple classifier to make our classifications. Thus, we will not be using the decoder layer (the longer section on the right side of the diagram). But do note that, while most of the components are indeed similar, the two layers function somewhat differently.***\n\n## Here is a quick rundown of what our Transformer model will contain the following:\n\n## 1. Embedding Layer:\n\n### a. Word Embeddings: \n**These are the learned dense vectors that represent each word in \nyour vocabulary. These vectors capture the semantic meaning of words. Of course, for our use case, we are utilizing the embeddings from word2vec**\n\n### b. Positional Encodings: \n**These are vectors that encode the position of each word in the \nsequence. They help the attention mechanism also take the positoning of the words when factoring in the attention scores.**\n\n## 2. Encoder Layer:\n\n### a. Multi-Head Attention: \n**This mechanism allows the model to attend to different parts of the\ninput sequence while capturing various relationships between words.**\n\n### b. Addition (Residual) and Normalization Layer: \n**After multi-head attention, you typically have a residual connection \n(addition) followed by layer normalization. This helps with stable \ntraining and information flow.**\n\n### c. Feed-Forward Neural Network (Pointwise Feed-Forward Layer): \n**This network applies a simple feed-forward transformation to each \nposition separately, allowing the model to capture non-linear \nrelationships between words.**\n\n## 3. Classifier Layer:\n\n### a. Linear Layer: \n**This layer maps the output of the encoder to the number of classes \nyou have in your sentiment analysis task. For example, if you have \nthree sentiment classes (negative, neutral, positive), this layer\nwill output logits for each class.**\n\n### b. Softmax Activation: \n**This activation function is applied to the logits to convert them \ninto probabilities for each class. It makes the model's output \ninterpretable as class probabilities.**","metadata":{}},{"cell_type":"markdown","source":"**When following the diagram as a pipeline, we see that the first thing we do with the inputs is include the embedding. The embedding layer involves replacing the tokens from our reviews with their vectors. Since we have used Word2Vec to create the embeddings from our tokens, we just proceed to the next step.** **The next step in our diagram is the Positional Encoding. This is a clever approach that the creaters of the Transformer architecture utilized to include even more information into our input embeddings. While the first set of vectors helped give our tokens their contextual vectors, the positional encoder assigns a sin or cosine value to these vectors depending on whether they are located in odd or even position. This adds to our vectors by highlighting the location of the token on top of its meaning, thus further enriching the information it carries.**\n\n**We will wrap all this up in one function and call that Embeddings.**","metadata":{}},{"cell_type":"markdown","source":"**Now we delve into what truly makes the Transformer architecture exceptional: the Attention mechanism. This mechanism, often referred to as self-attention, has been a transformative development in NLP. It serves as a way to allocate \"focus\" or \"attention\" values to the different embedded vectors that pass through the model's embedding layer. This allocation is achieved by segmenting the input vectors into three key components: queries, keys, and values.**\n\n**The process begins with the transformation of the input embeddings into three distinct matrices: the Query matrix (Q), Key matrix (K), and Value matrix (V). These matrices are obtained through linear transformations of the original embeddings.**\n\n**The heart of the attention mechanism involves calculating dot products between the Query matrix and the Transposed Key matrix. The resulting dot products are then scaled by the square root of the dimension of the key vectors. This scaling factor plays a crucial role in maintaining stable gradients during training.**\n\n**The next step in the process employs a softmax operation on the scaled dot products. The softmax function normalizes the values, converting them into attention weights. These attention weights indicate the \"importance\" or \"weight\" assigned to each word in relation to the others. The summation of the attention weights for each query-key pair ensures that the model focuses on the most relevant information.**\n\n**The weighted sum of the Value matrix, determined by the attention weights, generates an attended representation. In essence, the attention mechanism enables the model to capture the contextual relationships between words, determining how much each word contributes to the overall understanding of the sequence.**\n\n**One innovation that distinguishes the Transformer architecture is multi-head attention. Instead of relying on a single attention mechanism, multiple parallel attention mechanisms, or \"heads,\" are employed. Each head attends to the input independently and learns different aspects of the relationships between words. The outputs of the different heads are concatenated and linearly transformed, resulting in a comprehensive representation that encompasses various perspectives on the input data.**\n\n**Example:**\n\n**Consider the sentence: \"Diana wanted to visit Seattle in the Winter, but was ill-prepared for the cold, Pacific Northwest weather.\"**\n\n**In this sentence, the attention mechanism discerns connections between words, prioritizing specific words when analyzing others. For instance, in the context of \"visit Seattle,\" the word \"Seattle\" would attract more attention when considering the word \"visit.\" Similarly, the words \"ill-prepared\" and \"cold\" would stand out in the presence of the term \"Winter.\"**","metadata":{}},{"cell_type":"markdown","source":"# Positional Encoding","metadata":{}},{"cell_type":"code","source":"# pytorch implementation\n\nclass PositionalEncoding(nn.Module):\n\n    def __init__(self, d_model: int, dropout: float, seq_len: int):\n        super().__init__()\n        self.dropout = nn.Dropout(p = dropout)\n\n        position = torch.arange(seq_len).unsqueeze(1)\n        div_term = torch.exp(torch.arange(0, d_model, 2) * (-math.log(10000.0) / d_model))\n        pe = torch.zeros(seq_len, 1, d_model)\n        pe[:, 0, 0::2] = torch.sin(position * div_term)\n        pe[:, 0, 1::2] = torch.cos(position * div_term)\n        self.register_buffer('pe', pe)\n\n    def forward(self, x: Tensor) -> Tensor:\n        \"\"\"\n        Arguments:\n            x: Tensor, shape ``[seq_len, batch_size, embedding_dim]``\n        \"\"\"\n        x = x + self.pe[:x.size(0)]\n        return self.dropout(x)\n\n#>> Show what happened\nshowC(f'{PositionalEncoding} defined')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:12:30.149192Z","iopub.execute_input":"2024-03-30T05:12:30.149716Z","iopub.status.idle":"2024-03-30T05:12:30.162181Z","shell.execute_reply.started":"2024-03-30T05:12:30.149680Z","shell.execute_reply":"2024-03-30T05:12:30.160842Z"},"trusted":true},"execution_count":19,"outputs":[{"name":"stdout","text":"Cell complete: <class '__main__.PositionalEncoding'> defined\n","output_type":"stream"}]},{"cell_type":"markdown","source":"![image.png](attachment:dcbbcd14-b671-403b-903f-86a9c94add2b.png)\n\n* Source: [Transformer Tutorial - Tensorflow](https://www.tensorflow.org/text/tutorials/transformer)","metadata":{},"attachments":{"dcbbcd14-b671-403b-903f-86a9c94add2b.png":{"image/png":"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"}}},{"cell_type":"code","source":"def scaled_dot_product_attention(query, key, value, attn_mask = None, dropout_p = float, is_causal = False, scale = None) -> torch.Tensor:\n    # Efficient implementation equivalent to the following:\n    L, S = query.size(-2), key.size(-2)\n    scale_factor = 1 / math.sqrt(query.size(-1)) if scale is None else scale\n    attn_bias = torch.zeros(L, S, dtype=query.dtype).to(device)\n    if is_causal:\n        assert attn_mask is None\n        temp_mask = torch.ones(L, S, dtype=torch.bool).tril(diagonal = 0)\n        attn_bias.masked_fill_(temp_mask.logical_not(), float(\"-inf\"))\n        attn_bias.to(query.dtype)\n\n    if attn_mask is not None:\n        if attn_mask.dtype == torch.bool:\n            attn_mask.masked_fill_(attn_mask.logical_not(), float(\"-inf\"))\n        else:\n            attn_bias += attn_mask\n    attn_weight = query @ key.transpose(-2, -1) * scale_factor\n    attn_weight += attn_bias\n    attn_weight = torch.softmax(attn_weight, dim =- 1)\n    attn_weight = torch.dropout(attn_weight, dropout_p, train = True)\n    return attn_weight @ value\n\n#>> Show what happened\nshowC(f'{scaled_dot_product_attention} defined')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:12:35.585165Z","iopub.execute_input":"2024-03-30T05:12:35.585706Z","iopub.status.idle":"2024-03-30T05:12:35.599164Z","shell.execute_reply.started":"2024-03-30T05:12:35.585669Z","shell.execute_reply":"2024-03-30T05:12:35.598242Z"},"trusted":true},"execution_count":20,"outputs":[{"name":"stdout","text":"Cell complete: <function scaled_dot_product_attention at 0x7b529af23370> defined\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Attention + Multi-head","metadata":{}},{"cell_type":"code","source":"class MultiHeadedAttention(nn.Module):\n    def __init__(self, h, d_model, dropout = 0.1):\n        super().__init__()\n\n        self.h = h\n        self.d_k = d_model // h\n        self.attention_heads = [nn.Linear(d_model, d_model // h).to(device) for _ in range(self.h)]\n\n        \n    def forward(self, query, key, value, attn_mask = None, dropout_p=0.0):\n        attention_outputs = []\n        for attention_head in self.attention_heads:\n            attention_output = scaled_dot_product_attention(\n                attention_head(query),\n                attention_head(key),\n                attention_head(value),\n                attn_mask = attn_mask,\n                dropout_p = dropout_p,\n            )\n            attention_outputs.append(attention_output)\n            \n        seq_len = query.size(1)\n        attention_output = torch.cat(attention_outputs, dim =- 1).view(query.size(0), seq_len, d_model)\n        return attention_output","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:12:41.232900Z","iopub.execute_input":"2024-03-30T05:12:41.233438Z","iopub.status.idle":"2024-03-30T05:12:41.244792Z","shell.execute_reply.started":"2024-03-30T05:12:41.233400Z","shell.execute_reply":"2024-03-30T05:12:41.243243Z"},"trusted":true},"execution_count":21,"outputs":[]},{"cell_type":"markdown","source":"![Self-Attention Diagram](https://lena-voita.github.io/resources/lectures/seq2seq/transformer/qkv_explained-min.png)\n\n![Components of Self-Attention](https://lena-voita.github.io/resources/lectures/seq2seq/transformer/qkv_attention_formula-min.png)\n\n* Source: [Sequence to Sequence (seq2seq) and Attention](https://lena-voita.github.io/nlp_course/seq2seq_and_attention.html)","metadata":{}},{"cell_type":"markdown","source":"# Add/Residual layer + Normalization Layer","metadata":{}},{"cell_type":"code","source":"def add_layer(x, y):\n    \"\"\"Adds two tensors together.\n\n    Args:\n    x: A torch.Tensor of shape (batch_size, seq_len, hidden_size).\n    y: A torch.Tensor of the same shape as x.\n\n    Returns:\n    A torch.Tensor of the same shape as x and y, containing the sum of the two tensors.\n    \"\"\"\n\n    return torch.add(x, y)\n\nshowC(f'{add_layer} defined')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:12:51.099000Z","iopub.execute_input":"2024-03-30T05:12:51.099499Z","iopub.status.idle":"2024-03-30T05:12:51.108549Z","shell.execute_reply.started":"2024-03-30T05:12:51.099464Z","shell.execute_reply":"2024-03-30T05:12:51.107135Z"},"trusted":true},"execution_count":22,"outputs":[{"name":"stdout","text":"Cell complete: <function add_layer at 0x7b529af22830> defined\n","output_type":"stream"}]},{"cell_type":"code","source":"class LayerNorm(nn.Module):\n    \"Construct a layernorm module (See citation for details).\"\n\n    def __init__(self, features, eps = float):\n        super(LayerNorm, self).__init__()\n        self.a_2 = nn.Parameter(torch.ones(features))\n        self.b_2 = nn.Parameter(torch.zeros(features))\n        self.eps = eps\n\n    def forward(self, x):\n        mean = x.mean(-1, keepdim = True)\n        std = x.std(-1, keepdim = True)\n        return self.a_2 * (x - mean) / (std + self.eps) + self.b_2\n\nshowC(f'{LayerNorm} defined')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:12:56.063508Z","iopub.execute_input":"2024-03-30T05:12:56.064098Z","iopub.status.idle":"2024-03-30T05:12:56.075494Z","shell.execute_reply.started":"2024-03-30T05:12:56.064061Z","shell.execute_reply":"2024-03-30T05:12:56.073987Z"},"trusted":true},"execution_count":23,"outputs":[{"name":"stdout","text":"Cell complete: <class '__main__.LayerNorm'> defined\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Position-wise Feed Forward Network","metadata":{}},{"cell_type":"code","source":"class PositionwiseFeedForward(nn.Module):\n    def __init__(self, d_model: int, d_ffn: int, dropout: float):\n        \"\"\"\n        Args:\n            d_model:      dimension of embeddings\n            d_ffn:        dimension of feed-forward network\n            dropout:      probability of dropout occurring\n        \"\"\"\n        super().__init__()\n\n        self.w_1 = nn.Linear(d_model, d_ffn)\n        self.w_2 = nn.Linear(d_ffn, d_model)\n        self.dropout = nn.Dropout(dropout)\n\n    def forward(self, x):\n        \"\"\"\n        Args:\n            x:            output from attention (batch_size, seq_length, d_model)\n\n        Returns:\n            expanded-and-contracted representation (batch_size, seq_length, d_model)\n        \"\"\"\n        \n        return self.w_2(self.dropout(self.w_1(x).relu()))\n    \nshowC(f'{PositionwiseFeedForward} defined')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:13:06.413583Z","iopub.execute_input":"2024-03-30T05:13:06.414110Z","iopub.status.idle":"2024-03-30T05:13:06.425498Z","shell.execute_reply.started":"2024-03-30T05:13:06.414076Z","shell.execute_reply":"2024-03-30T05:13:06.424253Z"},"trusted":true},"execution_count":24,"outputs":[{"name":"stdout","text":"Cell complete: <class '__main__.PositionwiseFeedForward'> defined\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Hyperparameters","metadata":{}},{"cell_type":"code","source":"# HyperParameters for the module\nd_model = 300  # Should match the embedding dimension of your word embeddings\nseq_len = 100  # Maximum sequence length\ndropout = 0.1  # Adjust the dropout if needed\n\nh       = 4    # number of attention head\nnum_heads = 4    # number of attention head\n\nd_ffn   = 1024 # dimension of the feedforward layer\neps     = 1e-6 # epsilon value to prevent the standard deviation from becoming zero\nnum_classes = 5  # Replace with your number of classes\nepochs = 100\nlearning_rate = 0.01\nnum_layers = 6\n\ninput_size = d_model  # Adjust this based on the output size of your feed-forward network\n# input_size = len(train_data[0])  # Adjust based on your input size (should match the output size of your model)\nshowC('Hyperparameters defined')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:13:31.855554Z","iopub.execute_input":"2024-03-30T05:13:31.856083Z","iopub.status.idle":"2024-03-30T05:13:31.866419Z","shell.execute_reply.started":"2024-03-30T05:13:31.856044Z","shell.execute_reply":"2024-03-30T05:13:31.864826Z"},"trusted":true},"execution_count":25,"outputs":[{"name":"stdout","text":"Cell complete: Hyperparameters defined\n","output_type":"stream"}]},{"cell_type":"code","source":"printNv()\n#print('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\n#print(torch.cuda.memory_summary())","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:13:36.917212Z","iopub.execute_input":"2024-03-30T05:13:36.917746Z","iopub.status.idle":"2024-03-30T05:13:36.923062Z","shell.execute_reply.started":"2024-03-30T05:13:36.917707Z","shell.execute_reply":"2024-03-30T05:13:36.921684Z"},"trusted":true},"execution_count":26,"outputs":[]},{"cell_type":"markdown","source":"# Encoder Layer","metadata":{}},{"cell_type":"code","source":"class StackedEncoder(nn.Module):\n    def __init__(self, num_layers, d_model, seq_len, dropout, num_heads, d_ffn):\n        super(StackedEncoder, self).__init__()\n\n        self.layers = nn.ModuleList([\n            EncoderLayer(d_model, seq_len, dropout, num_heads, d_ffn) for _ in range(num_layers)\n        ])\n\n    def forward(self, x):\n        for layer in self.layers:\n            x = layer(x)\n        return x\n\nclass EncoderLayer(nn.Module):\n    def __init__(self, d_model, seq_len, dropout, num_heads, d_ffn):\n        super().__init__()\n\n        self.positional_encoding = PositionalEncoding(d_model, dropout, seq_len)\n        self.multihead_attention = MultiHeadedAttention(num_heads, d_model, dropout)\n        self.norm1 = LayerNorm(d_model, eps)\n        self.feed_forward = PositionwiseFeedForward(d_model, d_ffn, dropout)\n        self.norm2 = LayerNorm(d_model, eps)\n\n    def forward(self, x):\n        x_pe = self.positional_encoding(x)\n        attn_output = self.multihead_attention(x_pe, x_pe, x_pe)\n        x_attn = x + attn_output # Residual connection from multi-head attention\n        x_norm1 = self.norm1(x_attn)\n        ff_output = self.feed_forward(x_norm1)\n        x_ff = x_attn + ff_output # Residual connection from feed-forward network\n        x_norm2 = self.norm2(x_ff)\n\n        return x_norm2 # Return the normalized output\n\nshowC(f'{StackedEncoder} and {EncoderLayer} defined')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:13:44.687982Z","iopub.execute_input":"2024-03-30T05:13:44.688492Z","iopub.status.idle":"2024-03-30T05:13:44.702341Z","shell.execute_reply.started":"2024-03-30T05:13:44.688456Z","shell.execute_reply":"2024-03-30T05:13:44.700931Z"},"trusted":true},"execution_count":27,"outputs":[{"name":"stdout","text":"Cell complete: <class '__main__.StackedEncoder'> and <class '__main__.EncoderLayer'> defined\n","output_type":"stream"}]},{"cell_type":"markdown","source":"# Encoder Test","metadata":{}},{"cell_type":"code","source":"###################################### TEST ##########################################\n###################################### TEST ##########################################\n###################################### TEST ##########################################\n\n##################################### hyperparam #####################################\n##################################### hyperparam #####################################\n##################################### hyperparam #####################################\n\n# HyperParameters for the module\nd_model = 300  # Should match the embedding dimension of your word embeddings\nseq_len = 100  # Maximum sequence length\\ndropout = 0.1  # You can adjust the dropout if needed\nh       = 4    # number of attention head\\nd_ffn   = 1024 # dimension of the feedforward layer\neps     = 1e-6 # epsilon value to prevent the standard deviation from becoming zero\nnum_classes = 3  # Replace with your number of classes\ninput_size = d_model  # Adjust this based on the output size of your feed-forward network\\n\\n\nepochs = 10\nlearning_rate = 0.01\n\n## Dropout - During training, randomly zeroes some of the elements of the input\n## tensor with probability p using samples from a Bernoulli distribution. Each\n## channel will be zeroed out independently on every forward call.\n\n###################################### embedding #####################################\n###################################### embedding #####################################\n###################################### embedding #####################################\n\n#>> Ideally device = torch.device(\"cuda:0\")\nword_embeddings = torch.randn(32, 100, 300).to(device)\n\nprint (f\"Word Embedding Shape: {word_embeddings.size}\")\nprint (f\"Word Embedding Shape: {word_embeddings.shape}\")\nprint(f\"The Word Embeddings are on: {word_embeddings.device}\")\nprint(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\nprintNv() # !nvidia-smi\n      \n####################################### p.e. #########################################\n####################################### p.e. #########################################\n####################################### p.e. #########################################\n\n# Instantiate the PositionalEncoding module\npositional_encoder = PositionalEncoding(d_model, dropout, seq_len).to(device)\n\n# Apply the positional encoding to your word embeddings\nencoded_embeddings = positional_encoder(word_embeddings)\n      \n# Print the dimensions of the encoded embeddings\nprint(f\"Encoded Embeddings Shape: {encoded_embeddings.shape}\")\nprint(f\"The Encoded Embeddings are on: {encoded_embeddings.device}\")\nprint(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\nprintNv() # !nvidia-smi\n####################################### attn ##########################################\n####################################### attn ##########################################\n####################################### attn ##########################################\n      \n# Create an instance of the MultiHeadedAttention class\nmulti_head_attention = MultiHeadedAttention(h, d_model, dropout).to(device)\n      \n# Define your query, key, and value tensors (they can be the same for self-attention)\nquery = encoded_embeddings.to(device)\nkey = encoded_embeddings.to(device)\nvalue = encoded_embeddings.to(device)\n\nprint(f\"The Query Tensor is on: {query.device}\")\nprint(f\"The Key Tensor is on: {key.device}\")\nprint(f\"The Value Tensor is on: {value.device}\")\n\n# Optional: Define an attention mask or use None if not needed\nattn_mask = None\n\n# Apply the MultiHeadedAttention\\n\nattention_output = multi_head_attention(query, key, value, attn_mask = attn_mask)\n\n# Print the dimensions of the attention output\\n\nprint(f\"Attention Output Shape: {attention_output.shape}\")\nprint(f\"The Attention Output is on: {attention_output.device}\")\nprint(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\nprintNv() # !nvidia-smi\n######################################## add ##########################################\n######################################## add ##########################################\n######################################## add ##########################################\n\nresidual_connection = add_layer(attention_output, encoded_embeddings)\n\nprint(f\"Residual Connection Shape: {residual_connection.shape}\")\nprint(f\"The Residual Connection is on: {residual_connection.device}\")\nprint(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\nprintNv() # !nvidia-smi\n\n######################################## norm #########################################\n######################################## norm #########################################\n######################################## norm #########################################\n\nnorm = LayerNorm(d_model, eps).to(device)\nnormalized_values = norm(residual_connection)\n      \nprint(f\"Normalized Values Shape: {normalized_values.shape}\")\nprint(f\"The Normalized Values are on: {normalized_values.device}\")\nprint(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\nprintNv() # !nvidia-smi() \n\n######################################## fc ##########################################\n######################################## fc ##########################################\n######################################## fc ##########################################\n      \nfeedforward = PositionwiseFeedForward(d_model, d_ffn, dropout).to(device)\nff_output = feedforward(normalized_values)\n\nprint(f\"FF Output Shape: {ff_output.shape}\")\nprint(f\"The Output is on: {ff_output.device}\")\nprint(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\nprintNv() #!nvidia-smi\nshowC('Encoder test')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:14:04.287309Z","iopub.execute_input":"2024-03-30T05:14:04.288175Z","iopub.status.idle":"2024-03-30T05:14:04.648946Z","shell.execute_reply.started":"2024-03-30T05:14:04.288138Z","shell.execute_reply":"2024-03-30T05:14:04.647700Z"},"trusted":true},"execution_count":28,"outputs":[{"name":"stdout","text":"Word Embedding Shape: <built-in method size of Tensor object at 0x7b529af26160>\nWord Embedding Shape: torch.Size([32, 100, 300])\nThe Word Embeddings are on: cpu\nTotal allocated memory: 0 bytes\nEncoded Embeddings Shape: torch.Size([32, 100, 300])\nThe Encoded Embeddings are on: cpu\nTotal allocated memory: 0 bytes\nThe Query Tensor is on: cpu\nThe Key Tensor is on: cpu\nThe Value Tensor is on: cpu\nAttention Output Shape: torch.Size([32, 100, 300])\nThe Attention Output is on: cpu\nTotal allocated memory: 0 bytes\nResidual Connection Shape: torch.Size([32, 100, 300])\nThe Residual Connection is on: cpu\nTotal allocated memory: 0 bytes\nNormalized Values Shape: torch.Size([32, 100, 300])\nThe Normalized Values are on: cpu\nTotal allocated memory: 0 bytes\nFF Output Shape: torch.Size([32, 100, 300])\nThe Output is on: cpu\nTotal allocated memory: 0 bytes\nCell complete: Encoder test\n","output_type":"stream"}]},{"cell_type":"markdown","source":"**We can now split our dataset into training and validation sets. When working on machine learning or deep learning models, we want to train the model on a subset of the data, and then test the accuracy of the model's predictions on the remaining data. This is called data splitting. We typically split the data into an 80/20 split, where we train the model on 80% of the data and test it on the remaining 20%.**","metadata":{}},{"cell_type":"code","source":"printNv() # #!nvidia-smi\nprintM()   #print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\n\n#print('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\n#print(torch.cuda.memory_summary())","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:14:21.422213Z","iopub.execute_input":"2024-03-30T05:14:21.423583Z","iopub.status.idle":"2024-03-30T05:14:21.430485Z","shell.execute_reply.started":"2024-03-30T05:14:21.423533Z","shell.execute_reply":"2024-03-30T05:14:21.429397Z"},"trusted":true},"execution_count":29,"outputs":[{"name":"stdout","text":"Total allocated memory: 0 bytes\n","output_type":"stream"}]},{"cell_type":"code","source":"stacked_encoder = StackedEncoder(num_layers, d_model, \n                                 seq_len, dropout, num_heads, d_ffn).to(device)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:14:25.658125Z","iopub.execute_input":"2024-03-30T05:14:25.658912Z","iopub.status.idle":"2024-03-30T05:14:25.720842Z","shell.execute_reply.started":"2024-03-30T05:14:25.658878Z","shell.execute_reply":"2024-03-30T05:14:25.719610Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"code","source":"printNv()#!nvidia-smi\n#print('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\n#print(torch.cuda.memory_summary())","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:14:29.441545Z","iopub.execute_input":"2024-03-30T05:14:29.441995Z","iopub.status.idle":"2024-03-30T05:14:29.448782Z","shell.execute_reply.started":"2024-03-30T05:14:29.441963Z","shell.execute_reply":"2024-03-30T05:14:29.446984Z"},"trusted":true},"execution_count":31,"outputs":[]},{"cell_type":"code","source":"# DataLoader\n#>> dataset = TensorDataset(text_embeddings_tensors, rating_labels_tensors)\ndata_loader = DataLoader(dataset, batch_size = 32, shuffle = True)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:14:34.321614Z","iopub.execute_input":"2024-03-30T05:14:34.322112Z","iopub.status.idle":"2024-03-30T05:14:34.328743Z","shell.execute_reply.started":"2024-03-30T05:14:34.322079Z","shell.execute_reply":"2024-03-30T05:14:34.327717Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"total_encoded_batches = []  # List to store encoded batches\ntotal_y_batches = []        # List to store corresponding y batches\ni = 0\n\nfor x_batch, y_batch in data_loader:\n    #>> regrouped for loop display logic\n    if i == 0:\n        printd(f'Size of x_batch: {x_batch.shape}')\n        printd(f'Size of y_batch: {y_batch.shape}')\n    if i % 20 == 0:\n        printv(f'{i} batches processed')\n        printM()\n    i += 1\n    \n    # Move the batch to the device\n    x_batch = x_batch.to(device)\n    y_batch = y_batch.to(device)\n    \n    # Encode the batch using the stacked_encoder\n    encoded_batch = stacked_encoder(x_batch)\n    \n    # Append the encoded batch to the list\n    #>> detach removes gradient computed by encoder\n    total_encoded_batches.append(encoded_batch.detach().cpu())\n    total_y_batches.append(y_batch.detach().cpu())\n    \n    if i % 20 == 1:\n        printd(f'Current Size of Reviews: {len(total_encoded_batches)} tensors')\n        printd(f'Current Size of Ratings: {len(total_y_batches)} tensors')\n\nprintv(f'{i} batches processed')\nprintM()\n\n# Concatenate all the encoded batches into a single tensor\ntotal_encoded_batch = torch.cat(total_encoded_batches, dim = 0)\n\n# Concatenate all the corresponding y batches into a single tensor\ntotal_y_batch = torch.cat(total_y_batches, dim = 0)\n\nprintv(f'Concatenated Reviews Size: {total_encoded_batch.shape}')\nprintv(f'Concatenated Ratings Size: {total_y_batch.shape}')\n\nshowC('Batch encodings')\n","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:14:44.355963Z","iopub.execute_input":"2024-03-30T05:14:44.356758Z"},"trusted":true},"execution_count":null,"outputs":[{"name":"stdout","text":"DEV: Size of x_batch: torch.Size([32, 1347, 300])\nDEV: Size of y_batch: torch.Size([32])\nVERBOSE: 0 batches processed\nTotal allocated memory: 0 bytes\nDEV: Current Size of Reviews: 1 tensors\nDEV: Current Size of Ratings: 1 tensors\n","output_type":"stream"}]},{"cell_type":"code","source":"'''\ntotal_encoded_batch = [] \ntotal_y_batch = [] \ni = 0\n\nfor x_batch, y_batch in data_loader:  # Iterate over the training batches\n     print(f'size of batch: {x_batch.shape}')\n     i = i + 1\n    \n     print(i)\n     print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\n    \n     !nvidia-smi\n     print('\\n\\n')\n    \n     x_batch_encoded = stacked_encoder(x_batch).to(device)  # Encode the reviews using the stacked encoder\n    \n     total_encoded_batch.append(x_batch_encoded)\n     total_y_batch.append(y_batch)\n\ntotal_encoded_batch = torch.cat(total_encoded_batch, dim = 0)  # Concatenate all the encoded batches into a single tensor\ntotal_y_batch = torch.cat(total_y_batch)\nshowC('Batch encodings')\n'''","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:10:20.219405Z","iopub.status.idle":"2024-03-30T05:10:20.219809Z","shell.execute_reply.started":"2024-03-30T05:10:20.219605Z","shell.execute_reply":"2024-03-30T05:10:20.219622Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(total_encoded_batch.shape)  # Check the shape of the combined encoded tensor\nprint(total_y_batch.shape)\nprint('\\n')\nprint(f\"The Encoded batch is on: {total_encoded_batch.device}\")\nprint(f\"The Y batch is on: {total_y_batch.device}\")\nprint('\\n')\n# print(stacked_encoder)\nprint('\\n')\n\n\n# size in MB\nprint(f'x_batch size: { total_encoded_batch.nelement() * total_encoded_batch.element_size() }')\nprint(f'y_batch size: { total_y_batch.nelement() * total_y_batch.element_size() }')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:10:20.221461Z","iopub.status.idle":"2024-03-30T05:10:20.221887Z","shell.execute_reply.started":"2024-03-30T05:10:20.221689Z","shell.execute_reply":"2024-03-30T05:10:20.221707Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#del dataset\n#torch.cuda.empty_cache()\n\n#!nvidia-smi\n#print(torch.cuda.memory_summary())\n\n#print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\n#print('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\n#print(torch.cuda.memory_summary())","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:10:20.223970Z","iopub.status.idle":"2024-03-30T05:10:20.224966Z","shell.execute_reply.started":"2024-03-30T05:10:20.224566Z","shell.execute_reply":"2024-03-30T05:10:20.224599Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Duplicates previous cell\n'''\nprint(total_encoded_batch.shape)  # Check the shape of the combined encoded tensor\nprint(total_y_batch.shape)\nprint('\\n')\nprint(f\"The Encoded batch is on: {total_encoded_batch.device}\")\nprint(f\"The Y batch is on: {total_y_batch.device}\")\n'''","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:10:20.226063Z","iopub.status.idle":"2024-03-30T05:10:20.226862Z","shell.execute_reply.started":"2024-03-30T05:10:20.226636Z","shell.execute_reply":"2024-03-30T05:10:20.226657Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Realized that I was spliting the data before encoding and thus the training data was only being encoded. Might also explain why the validation score was so low (along with how small the dataset is and how the large epochs are definitely overfitting)","metadata":{}},{"cell_type":"code","source":"# Lengths \ntrain_len = int(0.8 * len(dataset))\nval_len = len(dataset) - train_len\n\n# Random split\ntrain_data, val_data = random_split(dataset, [train_len, val_len])\n\nprintv(f\"The amount of data we have to train with is {len(train_data)} revieww\") \nprintv(f\"The amount of data we have to validate with is {len(val_data)} reviews\")\n#print(f\"The amount of data we have to validate with is on {train_data.device}\")\n#print(f\"The amount of data we have to validate with is on {val_data.device}\")\n\n# DataLoader for training data\ntrain_loader = DataLoader(train_data, batch_size = 32, shuffle = True)  # Use shuffle for training\n\n# DataLoader for validation data\nval_loader = DataLoader(val_data, batch_size = 32, shuffle = False)  # No need to shuffle for validation","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:10:20.231015Z","iopub.status.idle":"2024-03-30T05:10:20.231643Z","shell.execute_reply.started":"2024-03-30T05:10:20.231379Z","shell.execute_reply":"2024-03-30T05:10:20.231404Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Moved input_size here","metadata":{}},{"cell_type":"code","source":"# new dataset object post encoding\n#encoded_training_dataset = TensorDataset(total_encoded_batch, total_y_batch)\n\n# Print the sliced dataset\n#print(encoded_review_dataset[:5])\n\n# Should match the output size of your model\n#input_size = len(train_data[0])","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:10:20.235197Z","iopub.status.idle":"2024-03-30T05:10:20.236002Z","shell.execute_reply.started":"2024-03-30T05:10:20.235523Z","shell.execute_reply":"2024-03-30T05:10:20.235542Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"printM() # print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\nprintNv() #!nvidia-smi\n#print('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\n#print(torch.cuda.memory_summary())","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:10:20.237825Z","iopub.status.idle":"2024-03-30T05:10:20.238912Z","shell.execute_reply.started":"2024-03-30T05:10:20.238649Z","shell.execute_reply":"2024-03-30T05:10:20.238670Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Classifier","metadata":{}},{"cell_type":"code","source":"class Classifier(nn.Module):\n    def __init__(self, r_size,v_size, num_classes):\n        # r_size is the number of tokens in a review, 100.\n        # v_size is the number of values in an embedding vector, 300.\n        super(Classifier, self).__init__()\n        \n        # The input to fc will be a 2D tensor with with n rows and\n        # r_size * v_size columns, where n >= 1; and the output will be a 2D tensor\n        # with n rows and num_classes columns.\n        self.fc = nn.Linear(r_size * v_size, num_classes)\n\n    def forward(self, x1):\n        # Pass input through the linear layer\n        return self.fc(x1)\n    \nshowC(f'{Classifier} defined')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:10:20.240524Z","iopub.status.idle":"2024-03-30T05:10:20.241587Z","shell.execute_reply.started":"2024-03-30T05:10:20.241363Z","shell.execute_reply":"2024-03-30T05:10:20.241384Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"#>> why define classifier twice?\nclass Classifier(nn.Module):\n    def __init__(self, r_size,v_size, num_classes):\n        # r_size is the number of tokens in a review, 100.\n        # v_size is the number of values in an embedding vector, 300.\n        super(Classifier, self).__init__()\n        \n        # The input to fc will be a 2D tensor with with n rows and\n        # r_size * v_size columns, where n >= 1; and the output will be a 2D tensor\n        # with n rows and num_classes columns.\n        self.fc = nn.Linear(r_size * v_size, num_classes)\n\n    def forward(self, x1):\n        # Pass input through the linear layer\n        return self.fc(x1)\n\n# Create the classifier\nclassifier = Classifier(seq_len, d_model, num_classes + 1).to(device)\n\nshowC(f'{Classifier} defined')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:10:20.243115Z","iopub.status.idle":"2024-03-30T05:10:20.243610Z","shell.execute_reply.started":"2024-03-30T05:10:20.243386Z","shell.execute_reply":"2024-03-30T05:10:20.243423Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"printM() # print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\nprintNv() # !nvidia-smi\n#print('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\n#print(torch.cuda.memory_summary())","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:10:20.245044Z","iopub.status.idle":"2024-03-30T05:10:20.245539Z","shell.execute_reply.started":"2024-03-30T05:10:20.245327Z","shell.execute_reply":"2024-03-30T05:10:20.245347Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Changing reshaping format to check on the input size. Hardcoding the reshaping dimensions as 32 was breaking the classifier (presumably due to the data not being perfectly divisible by 32)\n### Moved the hyperparameters a few cells up where the encoder's hyperparameters were since they were similar","metadata":{}},{"cell_type":"code","source":"# Define Cross-Entropy loss\ncriterion = nn.CrossEntropyLoss() # nn.CategoricalCrossentropy() #nn.Softmax() \n\n# Define SGD optimizer\n# Is Adam better?\noptimizer = optim.SGD(classifier.parameters(), lr=learning_rate)\n\nDEV = True\n# Training loop (adjust this to match your data and DataLoader)\nfor epoch in range(epochs):\n    for inputs, targets in train_loader :  # Assuming you have a DataLoader\n        # for batch_data in train_loader:  # Assuming you have a DataLoader\n        # inputs, targets = batch_data  # Assuming your DataLoader provides input data and targets    \n    \n        #printd(f'inputs shape: {inputs.shape}')\n        #printd(f'targets shape: {targets.shape}')\n        #printd(f'targets: {targets}')\n\n        optimizer.zero_grad()\n    \n        # keep nn.linear happy by combining the last two dimensions of inputs.\n        inputs = torch.reshape(inputs, (inputs.size(0), -1)) # get current batch size\n        #inputs = torch.reshape(inputs, (32,30000))\n        \n        #printd(f'Reshaped inputs: {inputs.shape}')\n        \n        outputs = classifier(inputs)\n        #printd(f'outputs shape {outputs.shape}')\n        \n        # output is a 32 x 6 tensor of floats,\n        # targets will be a 32 x 1 tensor of ints\n        loss = criterion(outputs, targets)\n        # print(f'loss.item: {loss.item()}')\n        loss.backward(retain_graph=True)\n        optimizer.step()\n     \n    print(f'Epoch [{epoch+1}/{epochs}] Loss: {loss.item()}')\n    \nshowC(f'training complete')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:10:20.247659Z","iopub.status.idle":"2024-03-30T05:10:20.248073Z","shell.execute_reply.started":"2024-03-30T05:10:20.247879Z","shell.execute_reply":"2024-03-30T05:10:20.247896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"printM() #>> print(f\"Total allocated memory: {torch.cuda.memory_allocated()} bytes\")\nprint(Nv() #>> !nvidia-smi\n#print('\\n\\n\\n\\n\\n\\n\\n\\n\\n\\n')\nprint(torch.cuda.memory_summary())","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:10:20.251165Z","iopub.status.idle":"2024-03-30T05:10:20.251724Z","shell.execute_reply.started":"2024-03-30T05:10:20.251484Z","shell.execute_reply":"2024-03-30T05:10:20.251503Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Put model in evaluation mode\nclassifier.eval() \n\n# Tracking variables\npredictions = []\nactuals = []\n\n# Evaluate on validation set\nwith torch.no_grad():\n    for inputs, targets in val_loader:\n        inputs = inputs.reshape(inputs.shape[0], -1)\n        \n        outputs = classifier(inputs)\n        _, predicted = torch.max(outputs, 1)\n        \n        predictions.extend(predicted.tolist())\n        actuals.extend(targets.tolist())\n        \n# Print sample outputs        \nprint(\"Predicted | Actual\")\nfor i in range (60):\n    print(f\"{predictions[i]} | {actuals[i]}\")\n    \n# Calculate validation accuracy\nnum_correct = sum([p == a for p, a in zip(predictions, actuals)]) \nval_accuracy = num_correct / len(predictions)\nprint(f'Validation Accuracy: {val_accuracy:.2f}')\n\nshowC('validate')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:10:20.254060Z","iopub.status.idle":"2024-03-30T05:10:20.255092Z","shell.execute_reply.started":"2024-03-30T05:10:20.254863Z","shell.execute_reply":"2024-03-30T05:10:20.254884Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"print(total_encoded_batch.device)\nprint(total_y_batch.device)\n\nprint(stacked_encoder)\nprint(classifier)\n\nprint(f'x_batch: { total_encoded_batch.nelement() * total_encoded_batch.element_size() }')\nprint(f'y_batch: { total_y_batch.nelement() * total_y_batch.element_size() }')","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:10:20.256672Z","iopub.status.idle":"2024-03-30T05:10:20.257571Z","shell.execute_reply.started":"2024-03-30T05:10:20.257345Z","shell.execute_reply":"2024-03-30T05:10:20.257365Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import sys \n\n# Stacked Encoder \nfor name, param in stacked_encoder.named_parameters():\n    print(f\"{name}:\\t{sys.getsizeof(param.untyped_storage()) / 1e6:.2f} MB\")\n\n# Classifier \nfor name, param in classifier.named_parameters():\n    print(f\"{name}:\\t{sys.getsizeof(param.untyped_storage()) / 1e6:.2f} MB\")\n    \n\ndel dataset\ntorch.cuda.empty_cache()\n\nprintNv() # !nvidia-smi\nprintM() # print(torch.cuda.memory_summary())","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:10:20.259387Z","iopub.status.idle":"2024-03-30T05:10:20.259831Z","shell.execute_reply.started":"2024-03-30T05:10:20.259617Z","shell.execute_reply":"2024-03-30T05:10:20.259635Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Try and print every utilization of .to(device) to try and see what'son the gpu","metadata":{}},{"cell_type":"code","source":"# attention components\n#self.attention_heads\n#print(attn_bias.device)\n\n# pre-processed input tensors\nprint(text_embeddings_tensors.device)\nprint(f'text_embeddings: { text_embeddings_tensors.nelement() * text_embeddings_tensors.element_size() }')\nprint(rating_labels_tensors.device)\nprint(f'rating_labels: { rating_labels_tensors.nelement() * rating_labels_tensors.element_size() }')\n\n#tensor object\n#print(dataset)\n\n# processed input tensor\nprint(total_encoded_batch.device)\nprint(f'total_encoded_batch: { total_encoded_batch.nelement() * total_encoded_batch.element_size() }')\nprint(total_y_batch.device)\nprint(f'y_batch: { total_y_batch.nelement() * total_y_batch.element_size() }')\n\n# moedels\n#print(stacked_encoder.device)\n#print(classifier.device)","metadata":{"execution":{"iopub.status.busy":"2024-03-30T05:10:20.261378Z","iopub.status.idle":"2024-03-30T05:10:20.262090Z","shell.execute_reply.started":"2024-03-30T05:10:20.261864Z","shell.execute_reply":"2024-03-30T05:10:20.261891Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"class Classifier(nn.Module):\n    def __init__(self, r_size,v_size, num_classes):\n        # r_size is the number of tokens in a review, 100.\n        # v_size is the number of values in an embedding vector, 300.\n        super(Classifier, self).__init__()\n        \n        # The input to fc will be a 2D tensor with with n rows and\n        # r_size * v_size columns, where n >= 1; and the output will be a 2D tensor\n        # with n rows and num_classes columns.\n        self.fc = nn.Linear(r_size * v_size, num_classes)\n\n    def forward(self, x1):\n        # Pass input through the linear layer\n        return self.fc(x1)\n\n# The next two lines were an attempt to fix the obscure CUDA assert error --\n# didn't work. But there's a workaround, just run without the accelerator.\n# You can get away with that if you just have 5,000 reviews in each category.\n#\nCUDA_LAUNCH_BLOCKING=1 \nTORCH_USE_CUDA_DSA=1\n\n# Create the classifier\nclassifier = Classifier(seq_len, d_model, num_classes+1)#.to(device)\n\n# Define Cross-Entropy loss\ncriterion = nn.CrossEntropyLoss() # nn.CategoricalCrossentropy() #nn.Softmax() \n\n# Define SGD optimizer\n# Is Adam better?\noptimizer = optim.SGD(classifier.parameters(), lr=learning_rate)\n\n# DEV = True\n# Training loop (adjust this to match your data and DataLoader)\nfor epoch in range(epochs):\n    for x_batch, y_batch in encoded_review_dataset:  # Assuming you have a DataLoader\n        inputs, targets = x_batch, y_batch  # Assuming your DataLoader provides input data and targets\n       \n        printd(f'targets shape: {targets.shape}')\n        printd(f'targets: {targets}')\n        printd(f'inputs shape: {inputs.shape}')\n        printd(f'inputs: {inputs}')\n\n        optimizer.zero_grad()\n    \n        # keep nn.linear happy by combining the last two dimensions of inputs.\n        #\n        inputs = torch.reshape(inputs, (32,30000))\n        printd(f'Reshaped inputs: {inputs.shape}')\n        \n        outputs = classifier(inputs)\n        printd(f'outputs shape {outputs.shape}')\n        \n        #dummy_output = torch.randn(32, 5, requires_grad=True).to(device)\n        # printd(f'dummy_output shape {dummy_output.shape}')\n        # printd(f'dummy_output {dummy_output}')\n        # output should be a 32 x 5 tensor of floats,\n        # targets will be a 32 x 1 tensor of ints\n        loss = criterion(outputs, targets)\n        loss.backward()\n        optimizer.step()\n    \n    print(f'Epoch [{epoch+1}/{epochs}] Loss: {loss.item()}')\n    \nDEV = False\n\n# Define the Classifier class\nclass Classifier(nn.Module):\n    def __init__(self, input_size, num_classes):\n        super(Classifier, self).__init__()\n        \n        self.linear_1 = nn.Linear(input_size, num_classes)\n        self.linear_2 = nn.Linear(1, num_classes)\n        self.sigmoid = nn.Sigmoid()\n\n    def forward(self, x1):\n        \n        linear_1_output = self.linear_1(x_batch)\n        linear_2_output = self.linear_2(y_batch)\n        combined_output = linear_1_output + linear_2_output\n        output = self.sigmoid(combined_output)\n        \n        return output\n    \n# Create the classifier\nclassifier = Classifier(input_size, num_classes)#.to(device)\n\n# Define Cross-Entropy loss\ncriterion = nn.CrossEntropyLoss()\n\n# Define SGD optimizer for both classifier\noptimizer = optim.SGD(list(classifier.parameters()), lr = learning_rate)\n\n# Training loop (adjust this to match your data and DataLoader)\nfor epoch in range(epochs):\n    for batch_data in :  # Assuming you have a DataLoader\n        inputs, targets = x_batch, y_batch  # Assuming your DataLoader provides input data and targets\n        optimizer.zero_grad()\n        \n        outputs = classifier()  \n        loss = criterion(outputs, targets)\n        \n        loss.backward()\n        optimizer.step()\n\n    print(f'Epoch [{epoch + 1}/{epochs}] Loss: {loss.item()}')","metadata":{"execution":{"iopub.status.busy":"2023-12-18T04:38:14.013759Z","iopub.execute_input":"2023-12-18T04:38:14.014019Z","iopub.status.idle":"2023-12-18T04:38:14.553673Z","shell.execute_reply.started":"2023-12-18T04:38:14.013986Z","shell.execute_reply":"2023-12-18T04:38:14.552074Z"}}},{"cell_type":"markdown","source":"You can think of the loss function as the valley, with the steepest parts being where the loss is highest and the flatter parts being where the loss is lower. The hiker is the set of model parameters, which are being updated with each step (iteration). SGD is like the GPS for the hiker, helping it navigate toward the lowest point in the valley (i.e. the global minimum of the loss function) with each step. The key difference is that SGD is an iterative process that updates the parameters in small steps, rather than finding the global minimum in a single shot. The learning rate is essentially the \"speed limit\" for the hiker (the model parameters). The learning rate would be how far the GPS would tell the hiker to go before it iterates/updates. A higher learning rate means that the hiker can make larger updates to the parameters with each step, while a lower learning rate means that the updates are smaller. This is important because it determines not only how quickly the model can find the global minimum, but also how stable the descent is - if the learning rate is too high, the hiker could get lost in the valley, but if it's too low, it could take forever to reach the bottom. So, the learning rate controls the speed of the descent and helps the model find the optimal set of parameters without overshooting or taking too long.\n\nSome additional points to augment the analogy:\n\nThe terrain can be rugged with many hills, valleys, and obstacles - like the high-dimensional, non-convex loss function landscape.\n\nMomentum in SGD helps the hiker build up speed in consistently downhill directions, like momentum in GD.\n\nAdaptive LR is like the GPS dynamically recommending faster or slower speeds depending on terrain.\n\nRegularization is like constraining the hiker's path to stay on trails and avoid dangerous cliffs (to prevent overfitting).\n\nBatch size is like the number of hikers traversing together (to average gradient noise).\n\nEpochs are like hiking to the bottom, then restarting from the top to repeat the descent.\n\nEarly stopping is like stopping the hike once you reach a good enough point close to the valley floor.\n\nHyperparameter tuning is like tweaking the GPS settings for optimal navigation.\n\nVanishing gradients are like certain paths becoming too steep or hitting dead-ends.\n\nLocal minima: The terrain can be rugged with many local minima, which are small valleys that are not as deep as the global minimum. SGD can get stuck in local minima, but there are various techniques that can help to avoid this, such as momentum and adaptive learning rate.\n\nLearning rate schedule: The learning rate can be adjusted over time to improve the performance of SGD. This is known as a learning rate schedule. For example, the learning rate can be decreased as the model converges to the global minimum, in order to prevent overshooting.\n\nNoise: The gradient calculation can be noisy, especially when the batch size is small. This can cause SGD to take a more erratic path towards the global minimum. However, the noise can be averaged out by using a larger batch size.","metadata":{}}]}